{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25441506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 15:12:07.423199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from helper import series_to_supervised\n",
    "from model.mlp import mlp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2af1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eefef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714025946899135\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537a30dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:00:00</th>\n",
       "      <td>996.528000</td>\n",
       "      <td>-8.304000</td>\n",
       "      <td>265.118000</td>\n",
       "      <td>-9.120000</td>\n",
       "      <td>93.780000</td>\n",
       "      <td>3.260000</td>\n",
       "      <td>3.058000</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>3.068000</td>\n",
       "      <td>1309.196000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.002000</td>\n",
       "      <td>174.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 01:00:00</th>\n",
       "      <td>996.525000</td>\n",
       "      <td>-8.065000</td>\n",
       "      <td>265.361667</td>\n",
       "      <td>-8.861667</td>\n",
       "      <td>93.933333</td>\n",
       "      <td>3.323333</td>\n",
       "      <td>3.121667</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>1.951667</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>1307.981667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.711667</td>\n",
       "      <td>172.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 02:00:00</th>\n",
       "      <td>996.745000</td>\n",
       "      <td>-8.763333</td>\n",
       "      <td>264.645000</td>\n",
       "      <td>-9.610000</td>\n",
       "      <td>93.533333</td>\n",
       "      <td>3.145000</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>1.836667</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>1311.816667</td>\n",
       "      <td>0.248333</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>196.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 03:00:00</th>\n",
       "      <td>996.986667</td>\n",
       "      <td>-8.896667</td>\n",
       "      <td>264.491667</td>\n",
       "      <td>-9.786667</td>\n",
       "      <td>93.200000</td>\n",
       "      <td>3.111667</td>\n",
       "      <td>2.898333</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>1.811667</td>\n",
       "      <td>2.906667</td>\n",
       "      <td>1312.813333</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>157.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 04:00:00</th>\n",
       "      <td>997.158333</td>\n",
       "      <td>-9.348333</td>\n",
       "      <td>264.026667</td>\n",
       "      <td>-10.345000</td>\n",
       "      <td>92.383333</td>\n",
       "      <td>3.001667</td>\n",
       "      <td>2.775000</td>\n",
       "      <td>0.231667</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1315.355000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>150.093333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       p (mbar)  T (degC)    Tpot (K)  Tdew (degC)     rh (%)  \\\n",
       "Date Time                                                                       \n",
       "2009-01-01 00:00:00  996.528000 -8.304000  265.118000    -9.120000  93.780000   \n",
       "2009-01-01 01:00:00  996.525000 -8.065000  265.361667    -8.861667  93.933333   \n",
       "2009-01-01 02:00:00  996.745000 -8.763333  264.645000    -9.610000  93.533333   \n",
       "2009-01-01 03:00:00  996.986667 -8.896667  264.491667    -9.786667  93.200000   \n",
       "2009-01-01 04:00:00  997.158333 -9.348333  264.026667   -10.345000  92.383333   \n",
       "\n",
       "                     VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  \\\n",
       "Date Time                                                                  \n",
       "2009-01-01 00:00:00      3.260000      3.058000      0.202000   1.910000   \n",
       "2009-01-01 01:00:00      3.323333      3.121667      0.201667   1.951667   \n",
       "2009-01-01 02:00:00      3.145000      2.940000      0.201667   1.836667   \n",
       "2009-01-01 03:00:00      3.111667      2.898333      0.210000   1.811667   \n",
       "2009-01-01 04:00:00      3.001667      2.775000      0.231667   1.733333   \n",
       "\n",
       "                     H2OC (mmol/mol)  rho (g/m**3)  wv (m/s)  max. wv (m/s)  \\\n",
       "Date Time                                                                     \n",
       "2009-01-01 00:00:00         3.068000   1309.196000  0.520000       1.002000   \n",
       "2009-01-01 01:00:00         3.133333   1307.981667  0.316667       0.711667   \n",
       "2009-01-01 02:00:00         2.950000   1311.816667  0.248333       0.606667   \n",
       "2009-01-01 03:00:00         2.906667   1312.813333  0.176667       0.606667   \n",
       "2009-01-01 04:00:00         2.780000   1315.355000  0.290000       0.670000   \n",
       "\n",
       "                       wd (deg)  \n",
       "Date Time                        \n",
       "2009-01-01 00:00:00  174.460000  \n",
       "2009-01-01 01:00:00  172.416667  \n",
       "2009-01-01 02:00:00  196.816667  \n",
       "2009-01-01 03:00:00  157.083333  \n",
       "2009-01-01 04:00:00  150.093333  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://keras.io/examples/timeseries/timeseries_weather_forecasting/#climate-data-timeseries\n",
    "data = pd.read_csv(\"../../data/jena_climate_2009_2016_hourly.csv\", index_col=0)\n",
    "data.fillna(0, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f927e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p (mbar)', 'T (degC)', 'Tpot (K)', 'Tdew (degC)', 'rh (%)',\n",
       "       'VPmax (mbar)', 'VPact (mbar)', 'VPdef (mbar)', 'sh (g/kg)',\n",
       "       'H2OC (mmol/mol)', 'rho (g/m**3)', 'wv (m/s)', 'max. wv (m/s)',\n",
       "       'wd (deg)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52b1443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0110e+03, 9.2470e+03, 1.5193e+04, 1.2302e+04, 9.8740e+03,\n",
       "        7.9000e+03, 5.3950e+03, 3.5180e+03, 2.1770e+03, 1.3350e+03,\n",
       "        8.5000e+02, 5.1000e+02, 2.9700e+02, 2.1200e+02, 1.2200e+02,\n",
       "        9.7000e+01, 4.4000e+01, 2.8000e+01, 1.2000e+01, 5.0000e+00]),\n",
       " array([ 0.        ,  3.14716667,  6.29433333,  9.4415    , 12.58866667,\n",
       "        15.73583333, 18.883     , 22.03016667, 25.17733333, 28.3245    ,\n",
       "        31.47166667, 34.61883333, 37.766     , 40.91316667, 44.06033333,\n",
       "        47.2075    , 50.35466667, 53.50183333, 56.649     , 59.79616667,\n",
       "        62.94333333]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['VPmax (mbar)'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59979006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "62.94333333333333\n"
     ]
    }
   ],
   "source": [
    "print(data['VPmax (mbar)'].min())\n",
    "print(data['VPmax (mbar)'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf49194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.333666666666637"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data['VPmax (mbar)'], 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee4ab3",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75f7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reframed.shape: (70046, 1176)\n"
     ]
    }
   ],
   "source": [
    "values = data.values\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_hours = 24*3\n",
    "n_features = data.shape[-1]\n",
    "k = 12\n",
    "split1 = 0.7\n",
    "split2 = 0.85\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(values, n_hours, k)\n",
    "print(\"reframed.shape:\", reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f94f6e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (49032, 1008) (49032, 12) (10507, 1008) (10507, 12) (10507, 1008) (10507, 12)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "reframed_values = reframed.values\n",
    "n_train_hours = int(len(reframed_values)*split1)\n",
    "n_valid_hours = int(len(reframed_values)*split2)\n",
    "\n",
    "train = reframed_values[:n_train_hours, :]\n",
    "val = reframed_values[n_train_hours:n_valid_hours, :]\n",
    "test = reframed_values[n_valid_hours:, :]\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "feature_idx = 5\n",
    "train_X, train_y = train[:, :n_obs], train[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "val_X, val_y = val[:, :n_obs], val[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "test_X, test_y = test[:, :n_obs], test[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de0c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (49032, 72, 14) (49032, 12) (10507, 72, 14) (10507, 12) (10507, 72, 14) (10507, 12)\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "train_y = scaler.fit_transform(train_y)\n",
    "\n",
    "val_X = scaler.fit_transform(val_X)\n",
    "val_y = scaler.fit_transform(val_y)\n",
    "\n",
    "test_X = scaler.fit_transform(test_X)\n",
    "test_y = scaler.fit_transform(test_y)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12854d82",
   "metadata": {},
   "source": [
    "### Pressure threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c026af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49032,)\n",
      "(10507,)\n",
      "(10507,)\n"
     ]
    }
   ],
   "source": [
    "train_X_pm = train_X[:, 0, feature_idx]\n",
    "print(train_X_pm.shape)\n",
    "\n",
    "val_X_pm = val_X[:, 0, feature_idx]\n",
    "print(val_X_pm.shape)\n",
    "\n",
    "test_X_pm = test_X[:, 0, feature_idx]\n",
    "print(test_X_pm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c84115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95th Percentile of Daily Rain: 0.48441203148316114\n"
     ]
    }
   ],
   "source": [
    "percentile = 95\n",
    "\n",
    "merged_array = np.concatenate((train_X_pm, val_X_pm, test_X_pm))\n",
    "\n",
    "percentile_pm = np.percentile(merged_array, percentile)\n",
    "\n",
    "print(\"{}th Percentile of Daily Rain:\".format(percentile), percentile_pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c78a17b",
   "metadata": {},
   "source": [
    "### train_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b07e5c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206, 72, 14)\n",
      "(2206, 12)\n"
     ]
    }
   ],
   "source": [
    "train_X_extreme = train_X[train_X_pm > percentile_pm]\n",
    "print(train_X_extreme.shape)\n",
    "\n",
    "train_y_extreme = train_y[train_X_pm > percentile_pm]\n",
    "print(train_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f6a185b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46826, 72, 14)\n",
      "(46826, 12)\n"
     ]
    }
   ],
   "source": [
    "train_X_normal = train_X[train_X_pm <= percentile_pm]\n",
    "print(train_X_normal.shape)\n",
    "\n",
    "train_y_normal = train_y[train_X_pm <= percentile_pm]\n",
    "print(train_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae983c",
   "metadata": {},
   "source": [
    "### val_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d57ac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486, 72, 14)\n",
      "(486, 12)\n"
     ]
    }
   ],
   "source": [
    "val_X_extreme = val_X[val_X_pm > percentile_pm]\n",
    "print(val_X_extreme.shape)\n",
    "\n",
    "val_y_extreme = val_y[val_X_pm > percentile_pm]\n",
    "print(val_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6735f652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10021, 72, 14)\n",
      "(10021, 12)\n"
     ]
    }
   ],
   "source": [
    "val_X_normal = val_X[val_X_pm <= percentile_pm]\n",
    "print(val_X_normal.shape)\n",
    "\n",
    "val_y_normal = val_y[val_X_pm <= percentile_pm]\n",
    "print(val_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d2ed7b",
   "metadata": {},
   "source": [
    "### test_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01296e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(811, 72, 14)\n",
      "(811, 12)\n"
     ]
    }
   ],
   "source": [
    "test_X_extreme = test_X[test_X_pm > percentile_pm]\n",
    "print(test_X_extreme.shape)\n",
    "\n",
    "test_y_extreme = test_y[test_X_pm > percentile_pm]\n",
    "print(test_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf5b8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9696, 72, 14)\n",
      "(9696, 12)\n"
     ]
    }
   ],
   "source": [
    "test_X_normal = test_X[test_X_pm <= percentile_pm]\n",
    "print(test_X_normal.shape)\n",
    "\n",
    "test_y_normal = test_y[test_X_pm <= percentile_pm]\n",
    "print(test_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c626353",
   "metadata": {},
   "source": [
    "### Model & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4d95d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== model parameters ======\n",
    "mlp_unit1 = 128\n",
    "mlp_unit2 = 128\n",
    "mlp_unit3 = 64\n",
    "mlp_unit4 = 64\n",
    "mlp_unit5 = 32\n",
    "mlp_unit6 = 32\n",
    "mlp_unit7 = 16\n",
    "mlp_unit8 = 16\n",
    "dropout = 0.0  # 0.1\n",
    "kernel_size = 2\n",
    "pool_size = 2\n",
    "learning_rate = 1e-4\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.95\n",
    "PATIENCE = 100\n",
    "EPOCHS = 1000\n",
    "BATCH = 512\n",
    "opt_num = k\n",
    "input_shape = train_X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71f96438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_layer(input_shape=input_shape,\n",
    "                   mlp_unit1=mlp_unit1,\n",
    "                   mlp_unit2=mlp_unit2,\n",
    "                   mlp_unit3=mlp_unit3,\n",
    "                   mlp_unit4=mlp_unit4,\n",
    "                   mlp_unit5=mlp_unit5,\n",
    "                   mlp_unit6=mlp_unit6,\n",
    "                   mlp_unit7=mlp_unit7,\n",
    "                   mlp_unit8=mlp_unit8,\n",
    "                   dropout=dropout,\n",
    "                   masked_value=-1,\n",
    "                   opt_num=opt_num\n",
    "                  )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f1e0318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 - 3s - loss: 0.1036 - mae: 0.2786 - val_loss: 0.0592 - val_mae: 0.2011\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.20115, saving model to ../../saved_models_mlp/pressure_E.h5\n",
      "Epoch 2/1000\n",
      "5/5 - 0s - loss: 0.0515 - mae: 0.1737 - val_loss: 0.0616 - val_mae: 0.2268\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 0.20115\n",
      "Epoch 3/1000\n",
      "5/5 - 0s - loss: 0.0240 - mae: 0.1249 - val_loss: 0.0167 - val_mae: 0.1038\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.20115 to 0.10378, saving model to ../../saved_models_mlp/pressure_E.h5\n",
      "Epoch 4/1000\n",
      "5/5 - 0s - loss: 0.0225 - mae: 0.1134 - val_loss: 0.0353 - val_mae: 0.1644\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 0.10378\n",
      "Epoch 5/1000\n",
      "5/5 - 0s - loss: 0.0201 - mae: 0.1119 - val_loss: 0.0141 - val_mae: 0.0956\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.10378 to 0.09558, saving model to ../../saved_models_mlp/pressure_E.h5\n",
      "Epoch 6/1000\n",
      "5/5 - 0s - loss: 0.0168 - mae: 0.0980 - val_loss: 0.0158 - val_mae: 0.1058\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 0.09558\n",
      "Epoch 7/1000\n",
      "5/5 - 0s - loss: 0.0144 - mae: 0.0893 - val_loss: 0.0110 - val_mae: 0.0818\n",
      "\n",
      "Epoch 00007: val_mae improved from 0.09558 to 0.08184, saving model to ../../saved_models_mlp/pressure_E.h5\n",
      "Epoch 8/1000\n",
      "5/5 - 0s - loss: 0.0126 - mae: 0.0841 - val_loss: 0.0096 - val_mae: 0.0699\n",
      "\n",
      "Epoch 00008: val_mae improved from 0.08184 to 0.06988, saving model to ../../saved_models_mlp/pressure_E.h5\n",
      "Epoch 9/1000\n",
      "5/5 - 0s - loss: 0.0116 - mae: 0.0802 - val_loss: 0.0131 - val_mae: 0.0840\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 0.06988\n",
      "Epoch 10/1000\n",
      "5/5 - 0s - loss: 0.0108 - mae: 0.0775 - val_loss: 0.0186 - val_mae: 0.1034\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 0.06988\n",
      "Epoch 11/1000\n",
      "5/5 - 0s - loss: 0.0101 - mae: 0.0743 - val_loss: 0.0159 - val_mae: 0.0930\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 0.06988\n",
      "Epoch 12/1000\n",
      "5/5 - 0s - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0128 - val_mae: 0.0823\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 0.06988\n",
      "Epoch 13/1000\n",
      "5/5 - 0s - loss: 0.0086 - mae: 0.0685 - val_loss: 0.0172 - val_mae: 0.0991\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 0.06988\n",
      "Epoch 14/1000\n",
      "5/5 - 0s - loss: 0.0077 - mae: 0.0646 - val_loss: 0.0198 - val_mae: 0.1069\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 0.06988\n",
      "Epoch 15/1000\n",
      "5/5 - 0s - loss: 0.0068 - mae: 0.0605 - val_loss: 0.0162 - val_mae: 0.0951\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.06988\n",
      "Epoch 16/1000\n",
      "5/5 - 0s - loss: 0.0064 - mae: 0.0591 - val_loss: 0.0139 - val_mae: 0.0877\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 0.06988\n",
      "Epoch 17/1000\n",
      "5/5 - 0s - loss: 0.0060 - mae: 0.0573 - val_loss: 0.0180 - val_mae: 0.1032\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.06988\n",
      "Epoch 18/1000\n",
      "5/5 - 0s - loss: 0.0056 - mae: 0.0553 - val_loss: 0.0163 - val_mae: 0.0979\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 0.06988\n",
      "Epoch 19/1000\n",
      "5/5 - 0s - loss: 0.0054 - mae: 0.0538 - val_loss: 0.0146 - val_mae: 0.0927\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 0.06988\n",
      "Epoch 20/1000\n",
      "5/5 - 0s - loss: 0.0052 - mae: 0.0528 - val_loss: 0.0129 - val_mae: 0.0859\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 0.06988\n",
      "Epoch 21/1000\n",
      "5/5 - 0s - loss: 0.0051 - mae: 0.0525 - val_loss: 0.0135 - val_mae: 0.0879\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.06988\n",
      "Epoch 22/1000\n",
      "5/5 - 0s - loss: 0.0049 - mae: 0.0512 - val_loss: 0.0123 - val_mae: 0.0832\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 0.06988\n",
      "Epoch 23/1000\n",
      "5/5 - 0s - loss: 0.0049 - mae: 0.0510 - val_loss: 0.0115 - val_mae: 0.0800\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.06988\n",
      "Epoch 24/1000\n",
      "5/5 - 0s - loss: 0.0047 - mae: 0.0505 - val_loss: 0.0111 - val_mae: 0.0785\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.06988\n",
      "Epoch 25/1000\n",
      "5/5 - 0s - loss: 0.0046 - mae: 0.0497 - val_loss: 0.0125 - val_mae: 0.0854\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.06988\n",
      "Epoch 26/1000\n",
      "5/5 - 0s - loss: 0.0045 - mae: 0.0491 - val_loss: 0.0134 - val_mae: 0.0884\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.06988\n",
      "Epoch 27/1000\n",
      "5/5 - 0s - loss: 0.0045 - mae: 0.0487 - val_loss: 0.0125 - val_mae: 0.0853\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 0.06988\n",
      "Epoch 28/1000\n",
      "5/5 - 0s - loss: 0.0045 - mae: 0.0487 - val_loss: 0.0137 - val_mae: 0.0910\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.06988\n",
      "Epoch 29/1000\n",
      "5/5 - 0s - loss: 0.0045 - mae: 0.0492 - val_loss: 0.0130 - val_mae: 0.0887\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.06988\n",
      "Epoch 30/1000\n",
      "5/5 - 0s - loss: 0.0043 - mae: 0.0474 - val_loss: 0.0102 - val_mae: 0.0761\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.06988\n",
      "Epoch 31/1000\n",
      "5/5 - 0s - loss: 0.0042 - mae: 0.0475 - val_loss: 0.0103 - val_mae: 0.0764\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.06988\n",
      "Epoch 32/1000\n",
      "5/5 - 0s - loss: 0.0042 - mae: 0.0473 - val_loss: 0.0084 - val_mae: 0.0686\n",
      "\n",
      "Epoch 00032: val_mae improved from 0.06988 to 0.06858, saving model to ../../saved_models_mlp/pressure_E.h5\n",
      "Epoch 33/1000\n",
      "5/5 - 0s - loss: 0.0044 - mae: 0.0490 - val_loss: 0.0094 - val_mae: 0.0735\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.06858\n",
      "Epoch 34/1000\n",
      "5/5 - 0s - loss: 0.0041 - mae: 0.0467 - val_loss: 0.0094 - val_mae: 0.0722\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.06858\n",
      "Epoch 35/1000\n",
      "5/5 - 0s - loss: 0.0041 - mae: 0.0463 - val_loss: 0.0101 - val_mae: 0.0769\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.06858\n",
      "Epoch 36/1000\n",
      "5/5 - 0s - loss: 0.0041 - mae: 0.0465 - val_loss: 0.0095 - val_mae: 0.0741\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.06858\n",
      "Epoch 37/1000\n",
      "5/5 - 0s - loss: 0.0040 - mae: 0.0457 - val_loss: 0.0086 - val_mae: 0.0701\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.06858\n",
      "Epoch 38/1000\n",
      "5/5 - 0s - loss: 0.0040 - mae: 0.0459 - val_loss: 0.0101 - val_mae: 0.0774\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.06858\n",
      "Epoch 39/1000\n",
      "5/5 - 0s - loss: 0.0039 - mae: 0.0451 - val_loss: 0.0096 - val_mae: 0.0735\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.06858\n",
      "Epoch 40/1000\n",
      "5/5 - 0s - loss: 0.0038 - mae: 0.0449 - val_loss: 0.0111 - val_mae: 0.0816\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.06858\n",
      "Epoch 41/1000\n",
      "5/5 - 0s - loss: 0.0038 - mae: 0.0445 - val_loss: 0.0103 - val_mae: 0.0780\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.06858\n",
      "Epoch 42/1000\n",
      "5/5 - 0s - loss: 0.0038 - mae: 0.0445 - val_loss: 0.0106 - val_mae: 0.0794\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 0.06858\n",
      "Epoch 43/1000\n",
      "5/5 - 0s - loss: 0.0038 - mae: 0.0449 - val_loss: 0.0092 - val_mae: 0.0738\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.06858\n",
      "Epoch 44/1000\n",
      "5/5 - 0s - loss: 0.0038 - mae: 0.0446 - val_loss: 0.0083 - val_mae: 0.0697\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.06858\n",
      "Epoch 45/1000\n",
      "5/5 - 0s - loss: 0.0038 - mae: 0.0446 - val_loss: 0.0083 - val_mae: 0.0694\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.06858\n",
      "Epoch 46/1000\n",
      "5/5 - 0s - loss: 0.0037 - mae: 0.0438 - val_loss: 0.0073 - val_mae: 0.0655\n",
      "\n",
      "Epoch 00046: val_mae improved from 0.06858 to 0.06551, saving model to ../../saved_models_mlp/pressure_E.h5\n",
      "Epoch 47/1000\n",
      "5/5 - 0s - loss: 0.0039 - mae: 0.0454 - val_loss: 0.0077 - val_mae: 0.0676\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.06551\n",
      "Epoch 48/1000\n",
      "5/5 - 0s - loss: 0.0037 - mae: 0.0443 - val_loss: 0.0079 - val_mae: 0.0678\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.06551\n",
      "Epoch 49/1000\n",
      "5/5 - 0s - loss: 0.0036 - mae: 0.0434 - val_loss: 0.0080 - val_mae: 0.0683\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.06551\n",
      "Epoch 50/1000\n",
      "5/5 - 0s - loss: 0.0036 - mae: 0.0431 - val_loss: 0.0082 - val_mae: 0.0689\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.06551\n",
      "Epoch 51/1000\n",
      "5/5 - 0s - loss: 0.0037 - mae: 0.0437 - val_loss: 0.0087 - val_mae: 0.0715\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.06551\n",
      "Epoch 52/1000\n",
      "5/5 - 0s - loss: 0.0037 - mae: 0.0444 - val_loss: 0.0083 - val_mae: 0.0700\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.06551\n",
      "Epoch 53/1000\n",
      "5/5 - 0s - loss: 0.0037 - mae: 0.0442 - val_loss: 0.0084 - val_mae: 0.0699\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.06551\n",
      "Epoch 54/1000\n",
      "5/5 - 0s - loss: 0.0036 - mae: 0.0436 - val_loss: 0.0077 - val_mae: 0.0672\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.06551\n",
      "Epoch 55/1000\n",
      "5/5 - 0s - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0073 - val_mae: 0.0660\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.06551\n",
      "Epoch 56/1000\n",
      "5/5 - 0s - loss: 0.0034 - mae: 0.0419 - val_loss: 0.0064 - val_mae: 0.0623\n",
      "\n",
      "Epoch 00056: val_mae improved from 0.06551 to 0.06231, saving model to ../../saved_models_mlp/pressure_E.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "5/5 - 0s - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0070 - val_mae: 0.0645\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.06231\n",
      "Epoch 58/1000\n",
      "5/5 - 0s - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0064 - val_mae: 0.0624\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.06231\n",
      "Epoch 59/1000\n",
      "5/5 - 0s - loss: 0.0033 - mae: 0.0416 - val_loss: 0.0070 - val_mae: 0.0651\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.06231\n",
      "Epoch 60/1000\n",
      "5/5 - 0s - loss: 0.0035 - mae: 0.0425 - val_loss: 0.0064 - val_mae: 0.0626\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.06231\n",
      "Epoch 61/1000\n",
      "5/5 - 0s - loss: 0.0035 - mae: 0.0428 - val_loss: 0.0064 - val_mae: 0.0634\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.06231\n",
      "Epoch 62/1000\n",
      "5/5 - 0s - loss: 0.0035 - mae: 0.0426 - val_loss: 0.0068 - val_mae: 0.0663\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.06231\n",
      "Epoch 63/1000\n",
      "5/5 - 0s - loss: 0.0035 - mae: 0.0428 - val_loss: 0.0064 - val_mae: 0.0629\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.06231\n",
      "Epoch 64/1000\n",
      "5/5 - 0s - loss: 0.0033 - mae: 0.0409 - val_loss: 0.0064 - val_mae: 0.0630\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.06231\n",
      "Epoch 65/1000\n",
      "5/5 - 0s - loss: 0.0032 - mae: 0.0408 - val_loss: 0.0069 - val_mae: 0.0652\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.06231\n",
      "Epoch 66/1000\n",
      "5/5 - 0s - loss: 0.0033 - mae: 0.0409 - val_loss: 0.0064 - val_mae: 0.0625\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.06231\n",
      "Epoch 67/1000\n",
      "5/5 - 0s - loss: 0.0032 - mae: 0.0408 - val_loss: 0.0065 - val_mae: 0.0639\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.06231\n",
      "Epoch 68/1000\n",
      "5/5 - 0s - loss: 0.0032 - mae: 0.0405 - val_loss: 0.0065 - val_mae: 0.0639\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.06231\n",
      "Epoch 69/1000\n",
      "5/5 - 0s - loss: 0.0032 - mae: 0.0406 - val_loss: 0.0065 - val_mae: 0.0643\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.06231\n",
      "Epoch 70/1000\n",
      "5/5 - 0s - loss: 0.0032 - mae: 0.0406 - val_loss: 0.0062 - val_mae: 0.0624\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.06231\n",
      "Epoch 71/1000\n",
      "5/5 - 0s - loss: 0.0032 - mae: 0.0403 - val_loss: 0.0062 - val_mae: 0.0624\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.06231\n",
      "Epoch 72/1000\n",
      "5/5 - 0s - loss: 0.0032 - mae: 0.0405 - val_loss: 0.0063 - val_mae: 0.0623\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.06231\n",
      "Epoch 73/1000\n",
      "5/5 - 0s - loss: 0.0031 - mae: 0.0399 - val_loss: 0.0066 - val_mae: 0.0648\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.06231\n",
      "Epoch 74/1000\n",
      "5/5 - 0s - loss: 0.0031 - mae: 0.0398 - val_loss: 0.0063 - val_mae: 0.0638\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.06231\n",
      "Epoch 75/1000\n",
      "5/5 - 0s - loss: 0.0031 - mae: 0.0398 - val_loss: 0.0066 - val_mae: 0.0641\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.06231\n",
      "Epoch 76/1000\n",
      "5/5 - 0s - loss: 0.0031 - mae: 0.0401 - val_loss: 0.0065 - val_mae: 0.0619\n",
      "\n",
      "Epoch 00076: val_mae improved from 0.06231 to 0.06189, saving model to ../../saved_models_mlp/pressure_E.h5\n",
      "Epoch 77/1000\n",
      "5/5 - 0s - loss: 0.0033 - mae: 0.0422 - val_loss: 0.0066 - val_mae: 0.0646\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.06189\n",
      "Epoch 78/1000\n",
      "5/5 - 0s - loss: 0.0031 - mae: 0.0404 - val_loss: 0.0062 - val_mae: 0.0623\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.06189\n",
      "Epoch 79/1000\n",
      "5/5 - 0s - loss: 0.0031 - mae: 0.0403 - val_loss: 0.0067 - val_mae: 0.0653\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.06189\n",
      "Epoch 80/1000\n",
      "5/5 - 0s - loss: 0.0031 - mae: 0.0403 - val_loss: 0.0061 - val_mae: 0.0618\n",
      "\n",
      "Epoch 00080: val_mae improved from 0.06189 to 0.06179, saving model to ../../saved_models_mlp/pressure_E.h5\n",
      "Epoch 81/1000\n",
      "5/5 - 0s - loss: 0.0030 - mae: 0.0399 - val_loss: 0.0065 - val_mae: 0.0645\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.06179\n",
      "Epoch 82/1000\n",
      "5/5 - 0s - loss: 0.0030 - mae: 0.0389 - val_loss: 0.0064 - val_mae: 0.0645\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.06179\n",
      "Epoch 83/1000\n",
      "5/5 - 0s - loss: 0.0030 - mae: 0.0390 - val_loss: 0.0068 - val_mae: 0.0667\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.06179\n",
      "Epoch 84/1000\n",
      "5/5 - 0s - loss: 0.0029 - mae: 0.0385 - val_loss: 0.0072 - val_mae: 0.0691\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.06179\n",
      "Epoch 85/1000\n",
      "5/5 - 0s - loss: 0.0029 - mae: 0.0389 - val_loss: 0.0068 - val_mae: 0.0663\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.06179\n",
      "Epoch 86/1000\n",
      "5/5 - 0s - loss: 0.0030 - mae: 0.0389 - val_loss: 0.0064 - val_mae: 0.0641\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.06179\n",
      "Epoch 87/1000\n",
      "5/5 - 0s - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0069 - val_mae: 0.0672\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.06179\n",
      "Epoch 88/1000\n",
      "5/5 - 0s - loss: 0.0029 - mae: 0.0383 - val_loss: 0.0070 - val_mae: 0.0676\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.06179\n",
      "Epoch 89/1000\n",
      "5/5 - 0s - loss: 0.0029 - mae: 0.0385 - val_loss: 0.0060 - val_mae: 0.0616\n",
      "\n",
      "Epoch 00089: val_mae improved from 0.06179 to 0.06156, saving model to ../../saved_models_mlp/pressure_E.h5\n",
      "Epoch 90/1000\n",
      "5/5 - 0s - loss: 0.0031 - mae: 0.0404 - val_loss: 0.0073 - val_mae: 0.0701\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.06156\n",
      "Epoch 91/1000\n",
      "5/5 - 0s - loss: 0.0029 - mae: 0.0391 - val_loss: 0.0072 - val_mae: 0.0691\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.06156\n",
      "Epoch 92/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0073 - val_mae: 0.0694\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.06156\n",
      "Epoch 93/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0379 - val_loss: 0.0079 - val_mae: 0.0731\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.06156\n",
      "Epoch 94/1000\n",
      "5/5 - 0s - loss: 0.0029 - mae: 0.0382 - val_loss: 0.0078 - val_mae: 0.0725\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.06156\n",
      "Epoch 95/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0378 - val_loss: 0.0076 - val_mae: 0.0714\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.06156\n",
      "Epoch 96/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0378 - val_loss: 0.0084 - val_mae: 0.0761\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.06156\n",
      "Epoch 97/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0080 - val_mae: 0.0734\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.06156\n",
      "Epoch 98/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0376 - val_loss: 0.0081 - val_mae: 0.0743\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.06156\n",
      "Epoch 99/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0373 - val_loss: 0.0079 - val_mae: 0.0728\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.06156\n",
      "Epoch 100/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0084 - val_mae: 0.0757\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.06156\n",
      "Epoch 101/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0376 - val_loss: 0.0089 - val_mae: 0.0783\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.06156\n",
      "Epoch 102/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0376 - val_loss: 0.0083 - val_mae: 0.0752\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.06156\n",
      "Epoch 103/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0094 - val_mae: 0.0804\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.06156\n",
      "Epoch 104/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0374 - val_loss: 0.0087 - val_mae: 0.0773\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.06156\n",
      "Epoch 105/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0374 - val_loss: 0.0087 - val_mae: 0.0768\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.06156\n",
      "Epoch 106/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0373 - val_loss: 0.0077 - val_mae: 0.0722\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.06156\n",
      "Epoch 107/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0371 - val_loss: 0.0082 - val_mae: 0.0743\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.06156\n",
      "Epoch 108/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0084 - val_mae: 0.0759\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.06156\n",
      "Epoch 109/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0377 - val_loss: 0.0091 - val_mae: 0.0790\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.06156\n",
      "Epoch 110/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0376 - val_loss: 0.0071 - val_mae: 0.0692\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.06156\n",
      "Epoch 111/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0382 - val_loss: 0.0075 - val_mae: 0.0707\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.06156\n",
      "Epoch 112/1000\n",
      "5/5 - 0s - loss: 0.0028 - mae: 0.0378 - val_loss: 0.0085 - val_mae: 0.0761\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.06156\n",
      "Epoch 113/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0370 - val_loss: 0.0096 - val_mae: 0.0813\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.06156\n",
      "Epoch 114/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0370 - val_loss: 0.0081 - val_mae: 0.0741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00114: val_mae did not improve from 0.06156\n",
      "Epoch 115/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0365 - val_loss: 0.0075 - val_mae: 0.0707\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.06156\n",
      "Epoch 116/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0369 - val_loss: 0.0088 - val_mae: 0.0772\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.06156\n",
      "Epoch 117/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0369 - val_loss: 0.0110 - val_mae: 0.0882\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.06156\n",
      "Epoch 118/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0377 - val_loss: 0.0109 - val_mae: 0.0871\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.06156\n",
      "Epoch 119/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0373 - val_loss: 0.0085 - val_mae: 0.0762\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.06156\n",
      "Epoch 120/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0369 - val_loss: 0.0072 - val_mae: 0.0688\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.06156\n",
      "Epoch 121/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0377 - val_loss: 0.0078 - val_mae: 0.0727\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.06156\n",
      "Epoch 122/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0369 - val_loss: 0.0111 - val_mae: 0.0885\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.06156\n",
      "Epoch 123/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0377 - val_loss: 0.0114 - val_mae: 0.0895\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.06156\n",
      "Epoch 124/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0375 - val_loss: 0.0090 - val_mae: 0.0789\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.06156\n",
      "Epoch 125/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0368 - val_loss: 0.0079 - val_mae: 0.0730\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.06156\n",
      "Epoch 126/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0360 - val_loss: 0.0074 - val_mae: 0.0697\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.06156\n",
      "Epoch 127/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0360 - val_loss: 0.0086 - val_mae: 0.0765\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.06156\n",
      "Epoch 128/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0357 - val_loss: 0.0093 - val_mae: 0.0796\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.06156\n",
      "Epoch 129/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0357 - val_loss: 0.0073 - val_mae: 0.0698\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.06156\n",
      "Epoch 130/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0359 - val_loss: 0.0081 - val_mae: 0.0739\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.06156\n",
      "Epoch 131/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0361 - val_loss: 0.0084 - val_mae: 0.0759\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.06156\n",
      "Epoch 132/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0358 - val_loss: 0.0079 - val_mae: 0.0729\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.06156\n",
      "Epoch 133/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0359 - val_loss: 0.0092 - val_mae: 0.0787\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.06156\n",
      "Epoch 134/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0358 - val_loss: 0.0090 - val_mae: 0.0784\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.06156\n",
      "Epoch 135/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0096 - val_mae: 0.0810\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.06156\n",
      "Epoch 136/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0356 - val_loss: 0.0086 - val_mae: 0.0763\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.06156\n",
      "Epoch 137/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0089 - val_mae: 0.0778\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.06156\n",
      "Epoch 138/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0352 - val_loss: 0.0085 - val_mae: 0.0756\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.06156\n",
      "Epoch 139/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0093 - val_mae: 0.0793\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.06156\n",
      "Epoch 140/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0352 - val_loss: 0.0090 - val_mae: 0.0783\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.06156\n",
      "Epoch 141/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0355 - val_loss: 0.0098 - val_mae: 0.0824\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.06156\n",
      "Epoch 142/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0349 - val_loss: 0.0092 - val_mae: 0.0792\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.06156\n",
      "Epoch 143/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0349 - val_loss: 0.0103 - val_mae: 0.0841\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.06156\n",
      "Epoch 144/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0096 - val_mae: 0.0818\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.06156\n",
      "Epoch 145/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0355 - val_loss: 0.0090 - val_mae: 0.0777\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.06156\n",
      "Epoch 146/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0375 - val_loss: 0.0069 - val_mae: 0.0675\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.06156\n",
      "Epoch 147/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0363 - val_loss: 0.0078 - val_mae: 0.0725\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.06156\n",
      "Epoch 148/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0365 - val_loss: 0.0127 - val_mae: 0.0937\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.06156\n",
      "Epoch 149/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0364 - val_loss: 0.0095 - val_mae: 0.0808\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.06156\n",
      "Epoch 150/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0354 - val_loss: 0.0072 - val_mae: 0.0685\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.06156\n",
      "Epoch 151/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0372 - val_loss: 0.0066 - val_mae: 0.0659\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.06156\n",
      "Epoch 152/1000\n",
      "5/5 - 0s - loss: 0.0027 - mae: 0.0376 - val_loss: 0.0091 - val_mae: 0.0790\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.06156\n",
      "Epoch 153/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0374 - val_loss: 0.0103 - val_mae: 0.0840\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.06156\n",
      "Epoch 154/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0367 - val_loss: 0.0107 - val_mae: 0.0860\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.06156\n",
      "Epoch 155/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0358 - val_loss: 0.0085 - val_mae: 0.0756\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.06156\n",
      "Epoch 156/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0348 - val_loss: 0.0080 - val_mae: 0.0730\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.06156\n",
      "Epoch 157/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0349 - val_loss: 0.0077 - val_mae: 0.0719\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.06156\n",
      "Epoch 158/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0364 - val_loss: 0.0077 - val_mae: 0.0716\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.06156\n",
      "Epoch 159/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0358 - val_loss: 0.0088 - val_mae: 0.0771\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.06156\n",
      "Epoch 160/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0348 - val_loss: 0.0091 - val_mae: 0.0782\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.06156\n",
      "Epoch 161/1000\n",
      "5/5 - 0s - loss: 0.0023 - mae: 0.0344 - val_loss: 0.0072 - val_mae: 0.0690\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.06156\n",
      "Epoch 162/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0358 - val_loss: 0.0077 - val_mae: 0.0718\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.06156\n",
      "Epoch 163/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0358 - val_loss: 0.0081 - val_mae: 0.0739\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.06156\n",
      "Epoch 164/1000\n",
      "5/5 - 0s - loss: 0.0023 - mae: 0.0343 - val_loss: 0.0086 - val_mae: 0.0761\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.06156\n",
      "Epoch 165/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0351 - val_loss: 0.0094 - val_mae: 0.0795\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.06156\n",
      "Epoch 166/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0349 - val_loss: 0.0083 - val_mae: 0.0748\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.06156\n",
      "Epoch 167/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0350 - val_loss: 0.0080 - val_mae: 0.0733\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.06156\n",
      "Epoch 168/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0348 - val_loss: 0.0070 - val_mae: 0.0679\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.06156\n",
      "Epoch 169/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0356 - val_loss: 0.0084 - val_mae: 0.0752\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.06156\n",
      "Epoch 170/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0352 - val_loss: 0.0109 - val_mae: 0.0871\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.06156\n",
      "Epoch 171/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0353 - val_loss: 0.0118 - val_mae: 0.0907\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.06156\n",
      "Epoch 172/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0353 - val_loss: 0.0116 - val_mae: 0.0898\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.06156\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 0.0025 - mae: 0.0357 - val_loss: 0.0087 - val_mae: 0.0767\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.06156\n",
      "Epoch 174/1000\n",
      "5/5 - 0s - loss: 0.0023 - mae: 0.0344 - val_loss: 0.0073 - val_mae: 0.0692\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.06156\n",
      "Epoch 175/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0076 - val_mae: 0.0709\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.06156\n",
      "Epoch 176/1000\n",
      "5/5 - 0s - loss: 0.0024 - mae: 0.0348 - val_loss: 0.0077 - val_mae: 0.0719\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.06156\n",
      "Epoch 177/1000\n",
      "5/5 - 0s - loss: 0.0023 - mae: 0.0340 - val_loss: 0.0076 - val_mae: 0.0711\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.06156\n",
      "Epoch 178/1000\n",
      "5/5 - 0s - loss: 0.0023 - mae: 0.0338 - val_loss: 0.0074 - val_mae: 0.0704\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.06156\n",
      "Epoch 179/1000\n",
      "5/5 - 0s - loss: 0.0023 - mae: 0.0344 - val_loss: 0.0097 - val_mae: 0.0812\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.06156\n",
      "Epoch 180/1000\n",
      "5/5 - 0s - loss: 0.0023 - mae: 0.0340 - val_loss: 0.0086 - val_mae: 0.0764\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.06156\n",
      "Epoch 181/1000\n",
      "5/5 - 0s - loss: 0.0023 - mae: 0.0341 - val_loss: 0.0103 - val_mae: 0.0849\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.06156\n",
      "Epoch 182/1000\n",
      "5/5 - 0s - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0113 - val_mae: 0.0888\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.06156\n",
      "Epoch 183/1000\n",
      "5/5 - 0s - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0111 - val_mae: 0.0875\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.06156\n",
      "Epoch 184/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0089 - val_mae: 0.0776\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.06156\n",
      "Epoch 185/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0380 - val_loss: 0.0080 - val_mae: 0.0731\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.06156\n",
      "Epoch 186/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0374 - val_loss: 0.0068 - val_mae: 0.0661\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.06156\n",
      "Epoch 187/1000\n",
      "5/5 - 0s - loss: 0.0026 - mae: 0.0366 - val_loss: 0.0066 - val_mae: 0.0650\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.06156\n",
      "Epoch 188/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0369 - val_loss: 0.0064 - val_mae: 0.0642\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.06156\n",
      "Epoch 189/1000\n",
      "5/5 - 0s - loss: 0.0025 - mae: 0.0365 - val_loss: 0.0071 - val_mae: 0.0684\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.06156\n",
      "Epoch 00189: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f03647132e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate, \n",
    "#                                                           decay_steps=decay_steps,\n",
    "#                                                           decay_rate=decay_rate)\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "#               loss='mse',\n",
    "#               metrics=['mae']\n",
    "#              )\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae']\n",
    "             )\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_mae', mode='min', verbose=2, patience=PATIENCE)\n",
    "mc = ModelCheckpoint('../../saved_models_mlp/pressure_E.h5', \n",
    "                     monitor='val_mae', \n",
    "                     mode='min', \n",
    "                     verbose=2, \n",
    "                     save_best_only=True\n",
    "                    )\n",
    "\n",
    "\n",
    "model.fit(train_X_extreme, train_y_extreme,\n",
    "          validation_data=(val_X_extreme, val_y_extreme),\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH,\n",
    "          verbose=2,\n",
    "          shuffle=True,\n",
    "          callbacks=[es, mc]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3c6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf5004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7c598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
