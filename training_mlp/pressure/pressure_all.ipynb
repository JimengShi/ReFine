{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25441506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 14:31:05.919366: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from helper import series_to_supervised\n",
    "from model.mlp import mlp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2af1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eefef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714025946899135\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537a30dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:00:00</th>\n",
       "      <td>996.528000</td>\n",
       "      <td>-8.304000</td>\n",
       "      <td>265.118000</td>\n",
       "      <td>-9.120000</td>\n",
       "      <td>93.780000</td>\n",
       "      <td>3.260000</td>\n",
       "      <td>3.058000</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>3.068000</td>\n",
       "      <td>1309.196000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.002000</td>\n",
       "      <td>174.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 01:00:00</th>\n",
       "      <td>996.525000</td>\n",
       "      <td>-8.065000</td>\n",
       "      <td>265.361667</td>\n",
       "      <td>-8.861667</td>\n",
       "      <td>93.933333</td>\n",
       "      <td>3.323333</td>\n",
       "      <td>3.121667</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>1.951667</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>1307.981667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.711667</td>\n",
       "      <td>172.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 02:00:00</th>\n",
       "      <td>996.745000</td>\n",
       "      <td>-8.763333</td>\n",
       "      <td>264.645000</td>\n",
       "      <td>-9.610000</td>\n",
       "      <td>93.533333</td>\n",
       "      <td>3.145000</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>1.836667</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>1311.816667</td>\n",
       "      <td>0.248333</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>196.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 03:00:00</th>\n",
       "      <td>996.986667</td>\n",
       "      <td>-8.896667</td>\n",
       "      <td>264.491667</td>\n",
       "      <td>-9.786667</td>\n",
       "      <td>93.200000</td>\n",
       "      <td>3.111667</td>\n",
       "      <td>2.898333</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>1.811667</td>\n",
       "      <td>2.906667</td>\n",
       "      <td>1312.813333</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>157.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 04:00:00</th>\n",
       "      <td>997.158333</td>\n",
       "      <td>-9.348333</td>\n",
       "      <td>264.026667</td>\n",
       "      <td>-10.345000</td>\n",
       "      <td>92.383333</td>\n",
       "      <td>3.001667</td>\n",
       "      <td>2.775000</td>\n",
       "      <td>0.231667</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1315.355000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>150.093333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       p (mbar)  T (degC)    Tpot (K)  Tdew (degC)     rh (%)  \\\n",
       "Date Time                                                                       \n",
       "2009-01-01 00:00:00  996.528000 -8.304000  265.118000    -9.120000  93.780000   \n",
       "2009-01-01 01:00:00  996.525000 -8.065000  265.361667    -8.861667  93.933333   \n",
       "2009-01-01 02:00:00  996.745000 -8.763333  264.645000    -9.610000  93.533333   \n",
       "2009-01-01 03:00:00  996.986667 -8.896667  264.491667    -9.786667  93.200000   \n",
       "2009-01-01 04:00:00  997.158333 -9.348333  264.026667   -10.345000  92.383333   \n",
       "\n",
       "                     VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  \\\n",
       "Date Time                                                                  \n",
       "2009-01-01 00:00:00      3.260000      3.058000      0.202000   1.910000   \n",
       "2009-01-01 01:00:00      3.323333      3.121667      0.201667   1.951667   \n",
       "2009-01-01 02:00:00      3.145000      2.940000      0.201667   1.836667   \n",
       "2009-01-01 03:00:00      3.111667      2.898333      0.210000   1.811667   \n",
       "2009-01-01 04:00:00      3.001667      2.775000      0.231667   1.733333   \n",
       "\n",
       "                     H2OC (mmol/mol)  rho (g/m**3)  wv (m/s)  max. wv (m/s)  \\\n",
       "Date Time                                                                     \n",
       "2009-01-01 00:00:00         3.068000   1309.196000  0.520000       1.002000   \n",
       "2009-01-01 01:00:00         3.133333   1307.981667  0.316667       0.711667   \n",
       "2009-01-01 02:00:00         2.950000   1311.816667  0.248333       0.606667   \n",
       "2009-01-01 03:00:00         2.906667   1312.813333  0.176667       0.606667   \n",
       "2009-01-01 04:00:00         2.780000   1315.355000  0.290000       0.670000   \n",
       "\n",
       "                       wd (deg)  \n",
       "Date Time                        \n",
       "2009-01-01 00:00:00  174.460000  \n",
       "2009-01-01 01:00:00  172.416667  \n",
       "2009-01-01 02:00:00  196.816667  \n",
       "2009-01-01 03:00:00  157.083333  \n",
       "2009-01-01 04:00:00  150.093333  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://keras.io/examples/timeseries/timeseries_weather_forecasting/#climate-data-timeseries\n",
    "data = pd.read_csv(\"../../data/jena_climate_2009_2016_hourly.csv\", index_col=0)\n",
    "data.fillna(0, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f927e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p (mbar)', 'T (degC)', 'Tpot (K)', 'Tdew (degC)', 'rh (%)',\n",
       "       'VPmax (mbar)', 'VPact (mbar)', 'VPdef (mbar)', 'sh (g/kg)',\n",
       "       'H2OC (mmol/mol)', 'rho (g/m**3)', 'wv (m/s)', 'max. wv (m/s)',\n",
       "       'wd (deg)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52b1443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0110e+03, 9.2470e+03, 1.5193e+04, 1.2302e+04, 9.8740e+03,\n",
       "        7.9000e+03, 5.3950e+03, 3.5180e+03, 2.1770e+03, 1.3350e+03,\n",
       "        8.5000e+02, 5.1000e+02, 2.9700e+02, 2.1200e+02, 1.2200e+02,\n",
       "        9.7000e+01, 4.4000e+01, 2.8000e+01, 1.2000e+01, 5.0000e+00]),\n",
       " array([ 0.        ,  3.14716667,  6.29433333,  9.4415    , 12.58866667,\n",
       "        15.73583333, 18.883     , 22.03016667, 25.17733333, 28.3245    ,\n",
       "        31.47166667, 34.61883333, 37.766     , 40.91316667, 44.06033333,\n",
       "        47.2075    , 50.35466667, 53.50183333, 56.649     , 59.79616667,\n",
       "        62.94333333]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['VPmax (mbar)'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59979006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "62.94333333333333\n"
     ]
    }
   ],
   "source": [
    "print(data['VPmax (mbar)'].min())\n",
    "print(data['VPmax (mbar)'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf49194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.333666666666637"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data['VPmax (mbar)'], 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee4ab3",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f75f7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reframed.shape: (70046, 1176)\n"
     ]
    }
   ],
   "source": [
    "values = data.values\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_hours = 24*3\n",
    "n_features = data.shape[-1]\n",
    "k = 12\n",
    "split1 = 0.7\n",
    "split2 = 0.85\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(values, n_hours, k)\n",
    "print(\"reframed.shape:\", reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f94f6e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (49032, 1008) (49032, 12) (10507, 1008) (10507, 12) (10507, 1008) (10507, 12)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "reframed_values = reframed.values\n",
    "n_train_hours = int(len(reframed_values)*split1)\n",
    "n_valid_hours = int(len(reframed_values)*split2)\n",
    "\n",
    "train = reframed_values[:n_train_hours, :]\n",
    "val = reframed_values[n_train_hours:n_valid_hours, :]\n",
    "test = reframed_values[n_valid_hours:, :]\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "feature_idx = 5\n",
    "train_X, train_y = train[:, :n_obs], train[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "val_X, val_y = val[:, :n_obs], val[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "test_X, test_y = test[:, :n_obs], test[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9de0c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (49032, 72, 14) (49032, 12) (10507, 72, 14) (10507, 12) (10507, 72, 14) (10507, 12)\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "train_y = scaler.fit_transform(train_y)\n",
    "\n",
    "val_X = scaler.fit_transform(val_X)\n",
    "val_y = scaler.fit_transform(val_y)\n",
    "\n",
    "test_X = scaler.fit_transform(test_X)\n",
    "test_y = scaler.fit_transform(test_y)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c626353",
   "metadata": {},
   "source": [
    "### Model & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4d95d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== model parameters ======\n",
    "mlp_unit1 = 128\n",
    "mlp_unit2 = 128\n",
    "mlp_unit3 = 64\n",
    "mlp_unit4 = 64\n",
    "mlp_unit5 = 32\n",
    "mlp_unit6 = 32\n",
    "mlp_unit7 = 16\n",
    "mlp_unit8 = 16\n",
    "dropout = 0.0  # 0.1\n",
    "kernel_size = 2\n",
    "pool_size = 2\n",
    "learning_rate = 1e-4\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.95\n",
    "PATIENCE = 100\n",
    "EPOCHS = 1000\n",
    "BATCH = 512\n",
    "opt_num = k\n",
    "input_shape = train_X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f96438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_layer(input_shape=input_shape,\n",
    "                   mlp_unit1=mlp_unit1,\n",
    "                   mlp_unit2=mlp_unit2,\n",
    "                   mlp_unit3=mlp_unit3,\n",
    "                   mlp_unit4=mlp_unit4,\n",
    "                   mlp_unit5=mlp_unit5,\n",
    "                   mlp_unit6=mlp_unit6,\n",
    "                   mlp_unit7=mlp_unit7,\n",
    "                   mlp_unit8=mlp_unit8,\n",
    "                   dropout=dropout,\n",
    "                   masked_value=-1,\n",
    "                   opt_num=opt_num\n",
    "                  )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f1e0318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 16:14:49.042499: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-01-10 16:14:49.043253: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1700105000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 16:14:50.174367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 - 4s - loss: 0.0125 - mae: 0.0768 - val_loss: 0.0062 - val_mae: 0.0525\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.05252, saving model to ../../saved_models/pressure_all.h5\n",
      "Epoch 2/1000\n",
      "96/96 - 1s - loss: 0.0047 - mae: 0.0471 - val_loss: 0.0053 - val_mae: 0.0500\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.05252 to 0.04998, saving model to ../../saved_models/pressure_all.h5\n",
      "Epoch 3/1000\n",
      "96/96 - 1s - loss: 0.0040 - mae: 0.0431 - val_loss: 0.0052 - val_mae: 0.0521\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 0.04998\n",
      "Epoch 4/1000\n",
      "96/96 - 1s - loss: 0.0036 - mae: 0.0407 - val_loss: 0.0050 - val_mae: 0.0464\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.04998 to 0.04643, saving model to ../../saved_models/pressure_all.h5\n",
      "Epoch 5/1000\n",
      "96/96 - 1s - loss: 0.0033 - mae: 0.0387 - val_loss: 0.0047 - val_mae: 0.0441\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.04643 to 0.04407, saving model to ../../saved_models/pressure_all.h5\n",
      "Epoch 6/1000\n",
      "96/96 - 1s - loss: 0.0031 - mae: 0.0379 - val_loss: 0.0047 - val_mae: 0.0444\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 0.04407\n",
      "Epoch 7/1000\n",
      "96/96 - 1s - loss: 0.0030 - mae: 0.0372 - val_loss: 0.0049 - val_mae: 0.0450\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 0.04407\n",
      "Epoch 8/1000\n",
      "96/96 - 1s - loss: 0.0029 - mae: 0.0368 - val_loss: 0.0048 - val_mae: 0.0484\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 0.04407\n",
      "Epoch 9/1000\n",
      "96/96 - 1s - loss: 0.0029 - mae: 0.0366 - val_loss: 0.0047 - val_mae: 0.0442\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 0.04407\n",
      "Epoch 10/1000\n",
      "96/96 - 1s - loss: 0.0029 - mae: 0.0363 - val_loss: 0.0053 - val_mae: 0.0486\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 0.04407\n",
      "Epoch 11/1000\n",
      "96/96 - 1s - loss: 0.0028 - mae: 0.0362 - val_loss: 0.0047 - val_mae: 0.0441\n",
      "\n",
      "Epoch 00011: val_mae improved from 0.04407 to 0.04406, saving model to ../../saved_models/pressure_all.h5\n",
      "Epoch 12/1000\n",
      "96/96 - 1s - loss: 0.0028 - mae: 0.0356 - val_loss: 0.0048 - val_mae: 0.0473\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 0.04406\n",
      "Epoch 13/1000\n",
      "96/96 - 1s - loss: 0.0028 - mae: 0.0357 - val_loss: 0.0048 - val_mae: 0.0478\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 0.04406\n",
      "Epoch 14/1000\n",
      "96/96 - 1s - loss: 0.0027 - mae: 0.0351 - val_loss: 0.0049 - val_mae: 0.0478\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 0.04406\n",
      "Epoch 15/1000\n",
      "96/96 - 1s - loss: 0.0027 - mae: 0.0355 - val_loss: 0.0052 - val_mae: 0.0476\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.04406\n",
      "Epoch 16/1000\n",
      "96/96 - 1s - loss: 0.0027 - mae: 0.0348 - val_loss: 0.0047 - val_mae: 0.0475\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 0.04406\n",
      "Epoch 17/1000\n",
      "96/96 - 1s - loss: 0.0027 - mae: 0.0352 - val_loss: 0.0050 - val_mae: 0.0468\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.04406\n",
      "Epoch 18/1000\n",
      "96/96 - 1s - loss: 0.0027 - mae: 0.0350 - val_loss: 0.0052 - val_mae: 0.0506\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 0.04406\n",
      "Epoch 19/1000\n",
      "96/96 - 1s - loss: 0.0026 - mae: 0.0344 - val_loss: 0.0053 - val_mae: 0.0516\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 0.04406\n",
      "Epoch 20/1000\n",
      "96/96 - 1s - loss: 0.0026 - mae: 0.0346 - val_loss: 0.0055 - val_mae: 0.0492\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 0.04406\n",
      "Epoch 21/1000\n",
      "96/96 - 1s - loss: 0.0026 - mae: 0.0342 - val_loss: 0.0054 - val_mae: 0.0508\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.04406\n",
      "Epoch 22/1000\n",
      "96/96 - 1s - loss: 0.0025 - mae: 0.0340 - val_loss: 0.0073 - val_mae: 0.0655\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 0.04406\n",
      "Epoch 23/1000\n",
      "96/96 - 1s - loss: 0.0025 - mae: 0.0342 - val_loss: 0.0059 - val_mae: 0.0545\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.04406\n",
      "Epoch 24/1000\n",
      "96/96 - 1s - loss: 0.0025 - mae: 0.0337 - val_loss: 0.0066 - val_mae: 0.0607\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.04406\n",
      "Epoch 25/1000\n",
      "96/96 - 1s - loss: 0.0025 - mae: 0.0340 - val_loss: 0.0062 - val_mae: 0.0570\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.04406\n",
      "Epoch 26/1000\n",
      "96/96 - 1s - loss: 0.0025 - mae: 0.0336 - val_loss: 0.0067 - val_mae: 0.0617\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.04406\n",
      "Epoch 27/1000\n",
      "96/96 - 1s - loss: 0.0024 - mae: 0.0331 - val_loss: 0.0063 - val_mae: 0.0558\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 0.04406\n",
      "Epoch 28/1000\n",
      "96/96 - 1s - loss: 0.0024 - mae: 0.0335 - val_loss: 0.0075 - val_mae: 0.0679\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.04406\n",
      "Epoch 29/1000\n",
      "96/96 - 1s - loss: 0.0024 - mae: 0.0335 - val_loss: 0.0069 - val_mae: 0.0625\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.04406\n",
      "Epoch 30/1000\n",
      "96/96 - 1s - loss: 0.0024 - mae: 0.0333 - val_loss: 0.0078 - val_mae: 0.0682\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.04406\n",
      "Epoch 31/1000\n",
      "96/96 - 1s - loss: 0.0024 - mae: 0.0335 - val_loss: 0.0079 - val_mae: 0.0677\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.04406\n",
      "Epoch 32/1000\n",
      "96/96 - 1s - loss: 0.0024 - mae: 0.0331 - val_loss: 0.0084 - val_mae: 0.0694\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 0.04406\n",
      "Epoch 33/1000\n",
      "96/96 - 1s - loss: 0.0024 - mae: 0.0337 - val_loss: 0.0082 - val_mae: 0.0624\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.04406\n",
      "Epoch 34/1000\n",
      "96/96 - 1s - loss: 0.0024 - mae: 0.0330 - val_loss: 0.0098 - val_mae: 0.0733\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.04406\n",
      "Epoch 35/1000\n",
      "96/96 - 1s - loss: 0.0023 - mae: 0.0328 - val_loss: 0.0086 - val_mae: 0.0693\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.04406\n",
      "Epoch 36/1000\n",
      "96/96 - 1s - loss: 0.0023 - mae: 0.0329 - val_loss: 0.0101 - val_mae: 0.0708\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.04406\n",
      "Epoch 37/1000\n",
      "96/96 - 1s - loss: 0.0023 - mae: 0.0327 - val_loss: 0.0086 - val_mae: 0.0635\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.04406\n",
      "Epoch 38/1000\n",
      "96/96 - 1s - loss: 0.0023 - mae: 0.0325 - val_loss: 0.0086 - val_mae: 0.0654\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.04406\n",
      "Epoch 39/1000\n",
      "96/96 - 1s - loss: 0.0023 - mae: 0.0324 - val_loss: 0.0091 - val_mae: 0.0676\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.04406\n",
      "Epoch 40/1000\n",
      "96/96 - 1s - loss: 0.0023 - mae: 0.0327 - val_loss: 0.0065 - val_mae: 0.0554\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.04406\n",
      "Epoch 41/1000\n",
      "96/96 - 1s - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0068 - val_mae: 0.0601\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.04406\n",
      "Epoch 42/1000\n",
      "96/96 - 1s - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0073 - val_mae: 0.0591\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 0.04406\n",
      "Epoch 43/1000\n",
      "96/96 - 1s - loss: 0.0023 - mae: 0.0333 - val_loss: 0.0070 - val_mae: 0.0593\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.04406\n",
      "Epoch 44/1000\n",
      "96/96 - 1s - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0094 - val_mae: 0.0720\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.04406\n",
      "Epoch 45/1000\n",
      "96/96 - 1s - loss: 0.0022 - mae: 0.0322 - val_loss: 0.0075 - val_mae: 0.0637\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.04406\n",
      "Epoch 46/1000\n",
      "96/96 - 1s - loss: 0.0022 - mae: 0.0320 - val_loss: 0.0101 - val_mae: 0.0757\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.04406\n",
      "Epoch 47/1000\n",
      "96/96 - 1s - loss: 0.0022 - mae: 0.0318 - val_loss: 0.0076 - val_mae: 0.0631\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.04406\n",
      "Epoch 48/1000\n",
      "96/96 - 1s - loss: 0.0022 - mae: 0.0319 - val_loss: 0.0121 - val_mae: 0.0811\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.04406\n",
      "Epoch 49/1000\n",
      "96/96 - 1s - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0091 - val_mae: 0.0690\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.04406\n",
      "Epoch 50/1000\n",
      "96/96 - 1s - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0125 - val_mae: 0.0831\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.04406\n",
      "Epoch 51/1000\n",
      "96/96 - 1s - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0127 - val_mae: 0.0840\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.04406\n",
      "Epoch 52/1000\n",
      "96/96 - 1s - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0111 - val_mae: 0.0789\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.04406\n",
      "Epoch 53/1000\n",
      "96/96 - 1s - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0137 - val_mae: 0.0872\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.04406\n",
      "Epoch 54/1000\n",
      "96/96 - 1s - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0113 - val_mae: 0.0771\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.04406\n",
      "Epoch 55/1000\n",
      "96/96 - 1s - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0132 - val_mae: 0.0846\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.04406\n",
      "Epoch 56/1000\n",
      "96/96 - 1s - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0139 - val_mae: 0.0851\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 0.04406\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 - 1s - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0125 - val_mae: 0.0849\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.04406\n",
      "Epoch 58/1000\n",
      "96/96 - 1s - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0118 - val_mae: 0.0807\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.04406\n",
      "Epoch 59/1000\n",
      "96/96 - 1s - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0142 - val_mae: 0.0879\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.04406\n",
      "Epoch 60/1000\n",
      "96/96 - 1s - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0226 - val_mae: 0.1107\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.04406\n",
      "Epoch 61/1000\n",
      "96/96 - 1s - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0202 - val_mae: 0.1077\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.04406\n",
      "Epoch 62/1000\n",
      "96/96 - 1s - loss: 0.0020 - mae: 0.0306 - val_loss: 0.0205 - val_mae: 0.1042\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.04406\n",
      "Epoch 63/1000\n",
      "96/96 - 1s - loss: 0.0019 - mae: 0.0304 - val_loss: 0.0156 - val_mae: 0.0942\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.04406\n",
      "Epoch 64/1000\n",
      "96/96 - 1s - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0190 - val_mae: 0.1031\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.04406\n",
      "Epoch 65/1000\n",
      "96/96 - 1s - loss: 0.0019 - mae: 0.0303 - val_loss: 0.0220 - val_mae: 0.1107\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.04406\n",
      "Epoch 66/1000\n",
      "96/96 - 1s - loss: 0.0019 - mae: 0.0304 - val_loss: 0.0289 - val_mae: 0.1217\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.04406\n",
      "Epoch 67/1000\n",
      "96/96 - 1s - loss: 0.0019 - mae: 0.0300 - val_loss: 0.0211 - val_mae: 0.1098\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.04406\n",
      "Epoch 68/1000\n",
      "96/96 - 1s - loss: 0.0019 - mae: 0.0303 - val_loss: 0.0260 - val_mae: 0.1201\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.04406\n",
      "Epoch 69/1000\n",
      "96/96 - 1s - loss: 0.0019 - mae: 0.0299 - val_loss: 0.0287 - val_mae: 0.1279\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.04406\n",
      "Epoch 70/1000\n",
      "96/96 - 1s - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0294 - val_mae: 0.1245\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.04406\n",
      "Epoch 71/1000\n",
      "96/96 - 1s - loss: 0.0018 - mae: 0.0299 - val_loss: 0.0254 - val_mae: 0.1171\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.04406\n",
      "Epoch 72/1000\n",
      "96/96 - 1s - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0309 - val_mae: 0.1307\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.04406\n",
      "Epoch 73/1000\n",
      "96/96 - 1s - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0465 - val_mae: 0.1591\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.04406\n",
      "Epoch 74/1000\n",
      "96/96 - 1s - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0319 - val_mae: 0.1338\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.04406\n",
      "Epoch 75/1000\n",
      "96/96 - 1s - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0413 - val_mae: 0.1516\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.04406\n",
      "Epoch 76/1000\n",
      "96/96 - 1s - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0358 - val_mae: 0.1415\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.04406\n",
      "Epoch 77/1000\n",
      "96/96 - 1s - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0399 - val_mae: 0.1515\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.04406\n",
      "Epoch 78/1000\n",
      "96/96 - 1s - loss: 0.0017 - mae: 0.0290 - val_loss: 0.0505 - val_mae: 0.1698\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.04406\n",
      "Epoch 79/1000\n",
      "96/96 - 1s - loss: 0.0017 - mae: 0.0290 - val_loss: 0.0548 - val_mae: 0.1706\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.04406\n",
      "Epoch 80/1000\n",
      "96/96 - 1s - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0518 - val_mae: 0.1701\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.04406\n",
      "Epoch 81/1000\n",
      "96/96 - 1s - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0501 - val_mae: 0.1702\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.04406\n",
      "Epoch 82/1000\n",
      "96/96 - 1s - loss: 0.0017 - mae: 0.0290 - val_loss: 0.0459 - val_mae: 0.1627\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.04406\n",
      "Epoch 83/1000\n",
      "96/96 - 1s - loss: 0.0017 - mae: 0.0286 - val_loss: 0.0575 - val_mae: 0.1819\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.04406\n",
      "Epoch 84/1000\n",
      "96/96 - 1s - loss: 0.0017 - mae: 0.0287 - val_loss: 0.0509 - val_mae: 0.1711\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.04406\n",
      "Epoch 85/1000\n",
      "96/96 - 1s - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0705 - val_mae: 0.1932\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.04406\n",
      "Epoch 86/1000\n",
      "96/96 - 1s - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0711 - val_mae: 0.1978\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.04406\n",
      "Epoch 87/1000\n",
      "96/96 - 1s - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0918 - val_mae: 0.2229\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.04406\n",
      "Epoch 88/1000\n",
      "96/96 - 1s - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0862 - val_mae: 0.2195\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.04406\n",
      "Epoch 89/1000\n",
      "96/96 - 1s - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0719 - val_mae: 0.2023\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.04406\n",
      "Epoch 90/1000\n",
      "96/96 - 1s - loss: 0.0015 - mae: 0.0277 - val_loss: 0.0736 - val_mae: 0.2021\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.04406\n",
      "Epoch 91/1000\n",
      "96/96 - 1s - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0428 - val_mae: 0.1543\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.04406\n",
      "Epoch 92/1000\n",
      "96/96 - 1s - loss: 0.0016 - mae: 0.0280 - val_loss: 0.0806 - val_mae: 0.2143\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.04406\n",
      "Epoch 93/1000\n",
      "96/96 - 1s - loss: 0.0015 - mae: 0.0277 - val_loss: 0.0911 - val_mae: 0.2260\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.04406\n",
      "Epoch 94/1000\n",
      "96/96 - 1s - loss: 0.0016 - mae: 0.0279 - val_loss: 0.1041 - val_mae: 0.2412\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.04406\n",
      "Epoch 95/1000\n",
      "96/96 - 1s - loss: 0.0015 - mae: 0.0273 - val_loss: 0.1192 - val_mae: 0.2599\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.04406\n",
      "Epoch 96/1000\n",
      "96/96 - 1s - loss: 0.0015 - mae: 0.0270 - val_loss: 0.1070 - val_mae: 0.2434\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.04406\n",
      "Epoch 97/1000\n",
      "96/96 - 1s - loss: 0.0015 - mae: 0.0270 - val_loss: 0.1491 - val_mae: 0.2913\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.04406\n",
      "Epoch 98/1000\n",
      "96/96 - 1s - loss: 0.0015 - mae: 0.0275 - val_loss: 0.1398 - val_mae: 0.2788\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.04406\n",
      "Epoch 99/1000\n",
      "96/96 - 1s - loss: 0.0014 - mae: 0.0269 - val_loss: 0.1034 - val_mae: 0.2406\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.04406\n",
      "Epoch 100/1000\n",
      "96/96 - 1s - loss: 0.0014 - mae: 0.0267 - val_loss: 0.1225 - val_mae: 0.2641\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.04406\n",
      "Epoch 101/1000\n",
      "96/96 - 1s - loss: 0.0014 - mae: 0.0270 - val_loss: 0.1624 - val_mae: 0.3042\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.04406\n",
      "Epoch 102/1000\n",
      "96/96 - 1s - loss: 0.0014 - mae: 0.0269 - val_loss: 0.1109 - val_mae: 0.2491\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.04406\n",
      "Epoch 103/1000\n",
      "96/96 - 1s - loss: 0.0014 - mae: 0.0266 - val_loss: 0.1586 - val_mae: 0.2989\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.04406\n",
      "Epoch 104/1000\n",
      "96/96 - 1s - loss: 0.0014 - mae: 0.0264 - val_loss: 0.1442 - val_mae: 0.2840\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.04406\n",
      "Epoch 105/1000\n",
      "96/96 - 1s - loss: 0.0014 - mae: 0.0268 - val_loss: 0.1888 - val_mae: 0.3215\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.04406\n",
      "Epoch 106/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0261 - val_loss: 0.2315 - val_mae: 0.3562\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.04406\n",
      "Epoch 107/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0261 - val_loss: 0.1524 - val_mae: 0.2959\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.04406\n",
      "Epoch 108/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0261 - val_loss: 0.1559 - val_mae: 0.2944\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.04406\n",
      "Epoch 109/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0261 - val_loss: 0.2032 - val_mae: 0.3341\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.04406\n",
      "Epoch 110/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0261 - val_loss: 0.1545 - val_mae: 0.2892\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.04406\n",
      "Epoch 111/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0258 - val_loss: 0.1811 - val_mae: 0.3146\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.04406\n",
      "Epoch 112/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0259 - val_loss: 0.2085 - val_mae: 0.3369\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.04406\n",
      "Epoch 113/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0255 - val_loss: 0.1617 - val_mae: 0.2987\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.04406\n",
      "Epoch 114/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0255 - val_loss: 0.2035 - val_mae: 0.3334\n",
      "\n",
      "Epoch 00114: val_mae did not improve from 0.04406\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 - 1s - loss: 0.0013 - mae: 0.0254 - val_loss: 0.2093 - val_mae: 0.3413\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.04406\n",
      "Epoch 116/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0254 - val_loss: 0.2510 - val_mae: 0.3740\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.04406\n",
      "Epoch 117/1000\n",
      "96/96 - 1s - loss: 0.0012 - mae: 0.0252 - val_loss: 0.1436 - val_mae: 0.2795\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.04406\n",
      "Epoch 118/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0254 - val_loss: 0.2271 - val_mae: 0.3569\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.04406\n",
      "Epoch 119/1000\n",
      "96/96 - 1s - loss: 0.0012 - mae: 0.0252 - val_loss: 0.2612 - val_mae: 0.3778\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.04406\n",
      "Epoch 120/1000\n",
      "96/96 - 1s - loss: 0.0012 - mae: 0.0252 - val_loss: 0.1582 - val_mae: 0.2942\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.04406\n",
      "Epoch 121/1000\n",
      "96/96 - 1s - loss: 0.0012 - mae: 0.0249 - val_loss: 0.2243 - val_mae: 0.3508\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.04406\n",
      "Epoch 122/1000\n",
      "96/96 - 1s - loss: 0.0012 - mae: 0.0246 - val_loss: 0.2515 - val_mae: 0.3721\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.04406\n",
      "Epoch 123/1000\n",
      "96/96 - 1s - loss: 0.0013 - mae: 0.0255 - val_loss: 0.1753 - val_mae: 0.3090\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.04406\n",
      "Epoch 124/1000\n",
      "96/96 - 1s - loss: 0.0012 - mae: 0.0247 - val_loss: 0.2498 - val_mae: 0.3680\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.04406\n",
      "Epoch 125/1000\n",
      "96/96 - 1s - loss: 0.0012 - mae: 0.0245 - val_loss: 0.2026 - val_mae: 0.3350\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.04406\n",
      "Epoch 126/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0243 - val_loss: 0.2829 - val_mae: 0.3956\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.04406\n",
      "Epoch 127/1000\n",
      "96/96 - 1s - loss: 0.0012 - mae: 0.0245 - val_loss: 0.2252 - val_mae: 0.3489\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.04406\n",
      "Epoch 128/1000\n",
      "96/96 - 1s - loss: 0.0012 - mae: 0.0245 - val_loss: 0.2921 - val_mae: 0.4100\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.04406\n",
      "Epoch 129/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0242 - val_loss: 0.2174 - val_mae: 0.3451\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.04406\n",
      "Epoch 130/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0238 - val_loss: 0.2933 - val_mae: 0.4101\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.04406\n",
      "Epoch 131/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0242 - val_loss: 0.2847 - val_mae: 0.4029\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.04406\n",
      "Epoch 132/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0238 - val_loss: 0.3563 - val_mae: 0.4589\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.04406\n",
      "Epoch 133/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0238 - val_loss: 0.2352 - val_mae: 0.3656\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.04406\n",
      "Epoch 134/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0238 - val_loss: 0.2558 - val_mae: 0.3864\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.04406\n",
      "Epoch 135/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0241 - val_loss: 0.2684 - val_mae: 0.3939\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.04406\n",
      "Epoch 136/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0237 - val_loss: 0.2121 - val_mae: 0.3445\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.04406\n",
      "Epoch 137/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0235 - val_loss: 0.2792 - val_mae: 0.4048\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.04406\n",
      "Epoch 138/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0238 - val_loss: 0.3762 - val_mae: 0.4672\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.04406\n",
      "Epoch 139/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0235 - val_loss: 0.2448 - val_mae: 0.3739\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.04406\n",
      "Epoch 140/1000\n",
      "96/96 - 1s - loss: 0.0010 - mae: 0.0233 - val_loss: 0.2819 - val_mae: 0.3962\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.04406\n",
      "Epoch 141/1000\n",
      "96/96 - 1s - loss: 0.0010 - mae: 0.0232 - val_loss: 0.2547 - val_mae: 0.3777\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.04406\n",
      "Epoch 142/1000\n",
      "96/96 - 1s - loss: 0.0010 - mae: 0.0232 - val_loss: 0.2587 - val_mae: 0.3891\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.04406\n",
      "Epoch 143/1000\n",
      "96/96 - 1s - loss: 0.0010 - mae: 0.0233 - val_loss: 0.3308 - val_mae: 0.4372\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.04406\n",
      "Epoch 144/1000\n",
      "96/96 - 1s - loss: 0.0011 - mae: 0.0236 - val_loss: 0.3182 - val_mae: 0.4284\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.04406\n",
      "Epoch 145/1000\n",
      "96/96 - 1s - loss: 0.0010 - mae: 0.0231 - val_loss: 0.2679 - val_mae: 0.3938\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.04406\n",
      "Epoch 146/1000\n",
      "96/96 - 1s - loss: 0.0010 - mae: 0.0228 - val_loss: 0.2710 - val_mae: 0.3880\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.04406\n",
      "Epoch 147/1000\n",
      "96/96 - 1s - loss: 0.0010 - mae: 0.0232 - val_loss: 0.2541 - val_mae: 0.3783\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.04406\n",
      "Epoch 148/1000\n",
      "96/96 - 1s - loss: 9.9824e-04 - mae: 0.0228 - val_loss: 0.2786 - val_mae: 0.4016\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.04406\n",
      "Epoch 149/1000\n",
      "96/96 - 1s - loss: 9.9790e-04 - mae: 0.0228 - val_loss: 0.2081 - val_mae: 0.3439\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.04406\n",
      "Epoch 150/1000\n",
      "96/96 - 1s - loss: 9.8225e-04 - mae: 0.0227 - val_loss: 0.2368 - val_mae: 0.3714\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.04406\n",
      "Epoch 151/1000\n",
      "96/96 - 1s - loss: 9.9571e-04 - mae: 0.0229 - val_loss: 0.3086 - val_mae: 0.4273\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.04406\n",
      "Epoch 152/1000\n",
      "96/96 - 1s - loss: 9.6726e-04 - mae: 0.0225 - val_loss: 0.2504 - val_mae: 0.3762\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.04406\n",
      "Epoch 153/1000\n",
      "96/96 - 1s - loss: 9.6510e-04 - mae: 0.0225 - val_loss: 0.2827 - val_mae: 0.4036\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.04406\n",
      "Epoch 154/1000\n",
      "96/96 - 1s - loss: 9.7797e-04 - mae: 0.0227 - val_loss: 0.2537 - val_mae: 0.3802\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.04406\n",
      "Epoch 155/1000\n",
      "96/96 - 1s - loss: 9.5263e-04 - mae: 0.0224 - val_loss: 0.2529 - val_mae: 0.3769\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.04406\n",
      "Epoch 156/1000\n",
      "96/96 - 1s - loss: 9.6822e-04 - mae: 0.0225 - val_loss: 0.2965 - val_mae: 0.4109\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.04406\n",
      "Epoch 157/1000\n",
      "96/96 - 1s - loss: 9.5158e-04 - mae: 0.0224 - val_loss: 0.3509 - val_mae: 0.4547\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.04406\n",
      "Epoch 158/1000\n",
      "96/96 - 1s - loss: 9.1040e-04 - mae: 0.0219 - val_loss: 0.2728 - val_mae: 0.3919\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.04406\n",
      "Epoch 159/1000\n",
      "96/96 - 1s - loss: 9.3087e-04 - mae: 0.0221 - val_loss: 0.2651 - val_mae: 0.3884\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.04406\n",
      "Epoch 160/1000\n",
      "96/96 - 1s - loss: 9.2263e-04 - mae: 0.0221 - val_loss: 0.2568 - val_mae: 0.3824\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.04406\n",
      "Epoch 161/1000\n",
      "96/96 - 1s - loss: 9.0986e-04 - mae: 0.0219 - val_loss: 0.2872 - val_mae: 0.4086\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.04406\n",
      "Epoch 162/1000\n",
      "96/96 - 1s - loss: 9.0679e-04 - mae: 0.0218 - val_loss: 0.2827 - val_mae: 0.4049\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.04406\n",
      "Epoch 163/1000\n",
      "96/96 - 1s - loss: 9.1677e-04 - mae: 0.0220 - val_loss: 0.2601 - val_mae: 0.3866\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.04406\n",
      "Epoch 164/1000\n",
      "96/96 - 1s - loss: 9.2939e-04 - mae: 0.0222 - val_loss: 0.2581 - val_mae: 0.3818\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.04406\n",
      "Epoch 165/1000\n",
      "96/96 - 1s - loss: 9.0870e-04 - mae: 0.0219 - val_loss: 0.2310 - val_mae: 0.3596\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.04406\n",
      "Epoch 166/1000\n",
      "96/96 - 1s - loss: 8.7833e-04 - mae: 0.0215 - val_loss: 0.2513 - val_mae: 0.3788\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.04406\n",
      "Epoch 167/1000\n",
      "96/96 - 1s - loss: 8.7291e-04 - mae: 0.0215 - val_loss: 0.2041 - val_mae: 0.3371\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.04406\n",
      "Epoch 168/1000\n",
      "96/96 - 1s - loss: 9.0142e-04 - mae: 0.0218 - val_loss: 0.2158 - val_mae: 0.3498\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.04406\n",
      "Epoch 169/1000\n",
      "96/96 - 1s - loss: 9.1180e-04 - mae: 0.0220 - val_loss: 0.2459 - val_mae: 0.3792\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.04406\n",
      "Epoch 170/1000\n",
      "96/96 - 1s - loss: 8.7989e-04 - mae: 0.0215 - val_loss: 0.2183 - val_mae: 0.3522\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.04406\n",
      "Epoch 171/1000\n",
      "96/96 - 1s - loss: 8.4720e-04 - mae: 0.0211 - val_loss: 0.2143 - val_mae: 0.3466\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.04406\n",
      "Epoch 172/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 - 1s - loss: 8.7345e-04 - mae: 0.0215 - val_loss: 0.2556 - val_mae: 0.3807\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.04406\n",
      "Epoch 173/1000\n",
      "96/96 - 1s - loss: 8.7990e-04 - mae: 0.0216 - val_loss: 0.1968 - val_mae: 0.3347\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.04406\n",
      "Epoch 174/1000\n",
      "96/96 - 1s - loss: 8.6365e-04 - mae: 0.0214 - val_loss: 0.2147 - val_mae: 0.3492\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.04406\n",
      "Epoch 175/1000\n",
      "96/96 - 1s - loss: 8.5468e-04 - mae: 0.0213 - val_loss: 0.2543 - val_mae: 0.3800\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.04406\n",
      "Epoch 176/1000\n",
      "96/96 - 1s - loss: 8.2546e-04 - mae: 0.0209 - val_loss: 0.2392 - val_mae: 0.3685\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.04406\n",
      "Epoch 177/1000\n",
      "96/96 - 1s - loss: 8.4592e-04 - mae: 0.0212 - val_loss: 0.2264 - val_mae: 0.3602\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.04406\n",
      "Epoch 178/1000\n",
      "96/96 - 1s - loss: 8.2313e-04 - mae: 0.0209 - val_loss: 0.2025 - val_mae: 0.3375\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.04406\n",
      "Epoch 179/1000\n",
      "96/96 - 1s - loss: 8.3068e-04 - mae: 0.0210 - val_loss: 0.2196 - val_mae: 0.3538\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.04406\n",
      "Epoch 180/1000\n",
      "96/96 - 1s - loss: 8.4094e-04 - mae: 0.0212 - val_loss: 0.1921 - val_mae: 0.3296\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.04406\n",
      "Epoch 181/1000\n",
      "96/96 - 1s - loss: 8.3334e-04 - mae: 0.0211 - val_loss: 0.2089 - val_mae: 0.3428\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.04406\n",
      "Epoch 182/1000\n",
      "96/96 - 1s - loss: 8.1796e-04 - mae: 0.0208 - val_loss: 0.1729 - val_mae: 0.3135\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.04406\n",
      "Epoch 183/1000\n",
      "96/96 - 1s - loss: 8.0811e-04 - mae: 0.0207 - val_loss: 0.2172 - val_mae: 0.3525\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.04406\n",
      "Epoch 184/1000\n",
      "96/96 - 1s - loss: 8.2608e-04 - mae: 0.0210 - val_loss: 0.2342 - val_mae: 0.3660\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.04406\n",
      "Epoch 185/1000\n",
      "96/96 - 1s - loss: 8.0984e-04 - mae: 0.0208 - val_loss: 0.2187 - val_mae: 0.3541\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.04406\n",
      "Epoch 186/1000\n",
      "96/96 - 1s - loss: 8.2134e-04 - mae: 0.0209 - val_loss: 0.2178 - val_mae: 0.3524\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.04406\n",
      "Epoch 187/1000\n",
      "96/96 - 1s - loss: 8.1424e-04 - mae: 0.0208 - val_loss: 0.1714 - val_mae: 0.3133\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.04406\n",
      "Epoch 188/1000\n",
      "96/96 - 1s - loss: 7.9818e-04 - mae: 0.0206 - val_loss: 0.2014 - val_mae: 0.3386\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.04406\n",
      "Epoch 189/1000\n",
      "96/96 - 1s - loss: 8.1676e-04 - mae: 0.0209 - val_loss: 0.2187 - val_mae: 0.3515\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.04406\n",
      "Epoch 190/1000\n",
      "96/96 - 1s - loss: 7.9400e-04 - mae: 0.0206 - val_loss: 0.1631 - val_mae: 0.2989\n",
      "\n",
      "Epoch 00190: val_mae did not improve from 0.04406\n",
      "Epoch 191/1000\n",
      "96/96 - 1s - loss: 7.6325e-04 - mae: 0.0201 - val_loss: 0.1702 - val_mae: 0.3132\n",
      "\n",
      "Epoch 00191: val_mae did not improve from 0.04406\n",
      "Epoch 192/1000\n",
      "96/96 - 1s - loss: 7.9158e-04 - mae: 0.0205 - val_loss: 0.2127 - val_mae: 0.3496\n",
      "\n",
      "Epoch 00192: val_mae did not improve from 0.04406\n",
      "Epoch 193/1000\n",
      "96/96 - 1s - loss: 8.0516e-04 - mae: 0.0207 - val_loss: 0.1606 - val_mae: 0.2998\n",
      "\n",
      "Epoch 00193: val_mae did not improve from 0.04406\n",
      "Epoch 194/1000\n",
      "96/96 - 1s - loss: 7.6398e-04 - mae: 0.0202 - val_loss: 0.2136 - val_mae: 0.3492\n",
      "\n",
      "Epoch 00194: val_mae did not improve from 0.04406\n",
      "Epoch 195/1000\n",
      "96/96 - 1s - loss: 7.6882e-04 - mae: 0.0202 - val_loss: 0.1734 - val_mae: 0.3136\n",
      "\n",
      "Epoch 00195: val_mae did not improve from 0.04406\n",
      "Epoch 196/1000\n",
      "96/96 - 1s - loss: 7.5744e-04 - mae: 0.0201 - val_loss: 0.1829 - val_mae: 0.3240\n",
      "\n",
      "Epoch 00196: val_mae did not improve from 0.04406\n",
      "Epoch 197/1000\n",
      "96/96 - 1s - loss: 7.6183e-04 - mae: 0.0202 - val_loss: 0.2009 - val_mae: 0.3385\n",
      "\n",
      "Epoch 00197: val_mae did not improve from 0.04406\n",
      "Epoch 198/1000\n",
      "96/96 - 1s - loss: 7.6374e-04 - mae: 0.0202 - val_loss: 0.1790 - val_mae: 0.3187\n",
      "\n",
      "Epoch 00198: val_mae did not improve from 0.04406\n",
      "Epoch 199/1000\n",
      "96/96 - 1s - loss: 7.6469e-04 - mae: 0.0202 - val_loss: 0.2342 - val_mae: 0.3662\n",
      "\n",
      "Epoch 00199: val_mae did not improve from 0.04406\n",
      "Epoch 200/1000\n",
      "96/96 - 1s - loss: 7.5262e-04 - mae: 0.0201 - val_loss: 0.1810 - val_mae: 0.3197\n",
      "\n",
      "Epoch 00200: val_mae did not improve from 0.04406\n",
      "Epoch 201/1000\n",
      "96/96 - 1s - loss: 7.4920e-04 - mae: 0.0200 - val_loss: 0.1753 - val_mae: 0.3139\n",
      "\n",
      "Epoch 00201: val_mae did not improve from 0.04406\n",
      "Epoch 202/1000\n",
      "96/96 - 1s - loss: 7.8831e-04 - mae: 0.0205 - val_loss: 0.1973 - val_mae: 0.3383\n",
      "\n",
      "Epoch 00202: val_mae did not improve from 0.04406\n",
      "Epoch 203/1000\n",
      "96/96 - 1s - loss: 7.1436e-04 - mae: 0.0195 - val_loss: 0.1699 - val_mae: 0.3090\n",
      "\n",
      "Epoch 00203: val_mae did not improve from 0.04406\n",
      "Epoch 204/1000\n",
      "96/96 - 1s - loss: 7.2275e-04 - mae: 0.0196 - val_loss: 0.1954 - val_mae: 0.3332\n",
      "\n",
      "Epoch 00204: val_mae did not improve from 0.04406\n",
      "Epoch 205/1000\n",
      "96/96 - 1s - loss: 7.5280e-04 - mae: 0.0200 - val_loss: 0.1863 - val_mae: 0.3250\n",
      "\n",
      "Epoch 00205: val_mae did not improve from 0.04406\n",
      "Epoch 206/1000\n",
      "96/96 - 1s - loss: 7.3882e-04 - mae: 0.0199 - val_loss: 0.1707 - val_mae: 0.3097\n",
      "\n",
      "Epoch 00206: val_mae did not improve from 0.04406\n",
      "Epoch 207/1000\n",
      "96/96 - 1s - loss: 7.1043e-04 - mae: 0.0195 - val_loss: 0.1624 - val_mae: 0.3013\n",
      "\n",
      "Epoch 00207: val_mae did not improve from 0.04406\n",
      "Epoch 208/1000\n",
      "96/96 - 1s - loss: 7.3050e-04 - mae: 0.0198 - val_loss: 0.1794 - val_mae: 0.3214\n",
      "\n",
      "Epoch 00208: val_mae did not improve from 0.04406\n",
      "Epoch 209/1000\n",
      "96/96 - 1s - loss: 7.2768e-04 - mae: 0.0197 - val_loss: 0.1641 - val_mae: 0.3053\n",
      "\n",
      "Epoch 00209: val_mae did not improve from 0.04406\n",
      "Epoch 210/1000\n",
      "96/96 - 1s - loss: 7.1557e-04 - mae: 0.0196 - val_loss: 0.1910 - val_mae: 0.3340\n",
      "\n",
      "Epoch 00210: val_mae did not improve from 0.04406\n",
      "Epoch 211/1000\n",
      "96/96 - 1s - loss: 7.1288e-04 - mae: 0.0195 - val_loss: 0.1748 - val_mae: 0.3164\n",
      "\n",
      "Epoch 00211: val_mae did not improve from 0.04406\n",
      "Epoch 00211: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f13e562d940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate, \n",
    "#                                                           decay_steps=decay_steps,\n",
    "#                                                           decay_rate=decay_rate)\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "#               loss='mse',\n",
    "#               metrics=['mae']\n",
    "#              )\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae']\n",
    "             )\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_mae', mode='min', verbose=2, patience=PATIENCE)\n",
    "mc = ModelCheckpoint('../../saved_models/pressure_all.h5', \n",
    "                     monitor='val_mae', \n",
    "                     mode='min', \n",
    "                     verbose=2, \n",
    "                     save_best_only=True\n",
    "                    )\n",
    "\n",
    "\n",
    "model.fit(train_X, train_y,\n",
    "          validation_data=(val_X, val_y),\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH,\n",
    "          verbose=2,\n",
    "          shuffle=True,\n",
    "          callbacks=[es, mc]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3c6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf5004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7c598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
