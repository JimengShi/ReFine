{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25441506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 14:57:17.138042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from helper import series_to_supervised\n",
    "from model.mlp import mlp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2af1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eefef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# random.seed(10)\n",
    "# print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537a30dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "      <th>NE</th>\n",
       "      <th>NW</th>\n",
       "      <th>SE</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press  wnd_spd  snow  rain  NE  \\\n",
       "date                                                                         \n",
       "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0     1.79     0     0   0   \n",
       "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0     2.68     0     0   0   \n",
       "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0     3.57     0     0   0   \n",
       "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0     5.36     1     0   0   \n",
       "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0     6.25     2     0   0   \n",
       "\n",
       "                     NW  SE  cv  \n",
       "date                             \n",
       "2010-01-02 00:00:00   0   1   0  \n",
       "2010-01-02 01:00:00   0   1   0  \n",
       "2010-01-02 02:00:00   0   1   0  \n",
       "2010-01-02 03:00:00   0   1   0  \n",
       "2010-01-02 04:00:00   0   1   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/pollution.csv\", index_col=0)\n",
    "data.fillna(0, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413bfd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "      <th>NE</th>\n",
       "      <th>NW</th>\n",
       "      <th>SE</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>231.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>237.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>242.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>246.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>249.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43800 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press  wnd_spd  snow  rain  NE  \\\n",
       "date                                                                         \n",
       "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0     1.79     0     0   0   \n",
       "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0     2.68     0     0   0   \n",
       "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0     3.57     0     0   0   \n",
       "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0     5.36     1     0   0   \n",
       "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0     6.25     2     0   0   \n",
       "...                        ...  ...   ...     ...      ...   ...   ...  ..   \n",
       "2014-12-31 19:00:00        8.0  -23  -2.0  1034.0   231.97     0     0   0   \n",
       "2014-12-31 20:00:00       10.0  -22  -3.0  1034.0   237.78     0     0   0   \n",
       "2014-12-31 21:00:00       10.0  -22  -3.0  1034.0   242.70     0     0   0   \n",
       "2014-12-31 22:00:00        8.0  -22  -4.0  1034.0   246.72     0     0   0   \n",
       "2014-12-31 23:00:00       12.0  -21  -3.0  1034.0   249.85     0     0   0   \n",
       "\n",
       "                     NW  SE  cv  \n",
       "date                             \n",
       "2010-01-02 00:00:00   0   1   0  \n",
       "2010-01-02 01:00:00   0   1   0  \n",
       "2010-01-02 02:00:00   0   1   0  \n",
       "2010-01-02 03:00:00   0   1   0  \n",
       "2010-01-02 04:00:00   0   1   0  \n",
       "...                  ..  ..  ..  \n",
       "2014-12-31 19:00:00   1   0   0  \n",
       "2014-12-31 20:00:00   1   0   0  \n",
       "2014-12-31 21:00:00   1   0   0  \n",
       "2014-12-31 22:00:00   1   0   0  \n",
       "2014-12-31 23:00:00   1   0   0  \n",
       "\n",
       "[43800 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f927e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pollution', 'dew', 'temp', 'press', 'wnd_spd', 'snow', 'rain', 'NE',\n",
       "       'NW', 'SE', 'cv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e52b1443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.7727e+04, 1.0511e+04, 6.4690e+03, 3.7450e+03, 2.2240e+03,\n",
       "        1.3270e+03, 7.5900e+02, 4.6700e+02, 2.8700e+02, 1.5400e+02,\n",
       "        7.2000e+01, 2.5000e+01, 7.0000e+00, 8.0000e+00, 4.0000e+00,\n",
       "        3.0000e+00, 4.0000e+00, 4.0000e+00, 0.0000e+00, 3.0000e+00]),\n",
       " array([  0. ,  49.7,  99.4, 149.1, 198.8, 248.5, 298.2, 347.9, 397.6,\n",
       "        447.3, 497. , 546.7, 596.4, 646.1, 695.8, 745.5, 795.2, 844.9,\n",
       "        894.6, 944.3, 994. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['pollution'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf49194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data['pollution'], 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee4ab3",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75f7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reframed.shape: (43717, 924)\n"
     ]
    }
   ],
   "source": [
    "values = data.values\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_hours = 24*3\n",
    "n_features = data.shape[-1]\n",
    "k = 12\n",
    "split1 = 0.7\n",
    "split2 = 0.85\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(values, n_hours, k)\n",
    "print(\"reframed.shape:\", reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f94f6e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (30601, 792) (30601, 12) (6558, 792) (6558, 12) (6558, 792) (6558, 12)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "reframed_values = reframed.values\n",
    "n_train_hours = int(len(reframed_values)*split1)\n",
    "n_valid_hours = int(len(reframed_values)*split2)\n",
    "\n",
    "train = reframed_values[:n_train_hours, :]\n",
    "val = reframed_values[n_train_hours:n_valid_hours, :]\n",
    "test = reframed_values[n_valid_hours:, :]\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "feature_idx = 0\n",
    "train_X, train_y = train[:, :n_obs], train[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "val_X, val_y = val[:, :n_obs], val[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "test_X, test_y = test[:, :n_obs], test[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de0c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (30601, 72, 11) (30601, 12) (6558, 72, 11) (6558, 12) (6558, 72, 11) (6558, 12)\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "train_y = scaler.fit_transform(train_y)\n",
    "\n",
    "val_X = scaler.fit_transform(val_X)\n",
    "val_y = scaler.fit_transform(val_y)\n",
    "\n",
    "test_X = scaler.fit_transform(test_X)\n",
    "test_y = scaler.fit_transform(test_y)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b223101b",
   "metadata": {},
   "source": [
    "### PM threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3717a351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30601,)\n",
      "(6558,)\n",
      "(6558,)\n"
     ]
    }
   ],
   "source": [
    "train_X_pm = train_X[:, 0, feature_idx]\n",
    "print(train_X_pm.shape)\n",
    "\n",
    "val_X_pm = val_X[:, 0, feature_idx]\n",
    "print(val_X_pm.shape)\n",
    "\n",
    "test_X_pm = test_X[:, 0, feature_idx]\n",
    "print(test_X_pm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c4a0ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95th Percentile of Daily Rain: 0.33400402414486924\n"
     ]
    }
   ],
   "source": [
    "percentile = 95\n",
    "\n",
    "merged_array = np.concatenate((train_X_pm, val_X_pm, test_X_pm))\n",
    "\n",
    "percentile_pm = np.percentile(merged_array, percentile)\n",
    "\n",
    "print(\"{}th Percentile of Daily Rain:\".format(percentile), percentile_pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d720217",
   "metadata": {},
   "source": [
    "### train_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94b31a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(848, 72, 11)\n",
      "(848, 12)\n"
     ]
    }
   ],
   "source": [
    "train_X_extreme = train_X[train_X_pm > percentile_pm]\n",
    "print(train_X_extreme.shape)\n",
    "\n",
    "train_y_extreme = train_y[train_X_pm > percentile_pm]\n",
    "print(train_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48bd19ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29753, 72, 11)\n",
      "(29753, 12)\n"
     ]
    }
   ],
   "source": [
    "train_X_normal = train_X[train_X_pm <= percentile_pm]\n",
    "print(train_X_normal.shape)\n",
    "\n",
    "train_y_normal = train_y[train_X_pm <= percentile_pm]\n",
    "print(train_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac76a6a",
   "metadata": {},
   "source": [
    "### val_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc41fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(752, 72, 11)\n",
      "(752, 12)\n"
     ]
    }
   ],
   "source": [
    "val_X_extreme = val_X[val_X_pm > percentile_pm]\n",
    "print(val_X_extreme.shape)\n",
    "\n",
    "val_y_extreme = val_y[val_X_pm > percentile_pm]\n",
    "print(val_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26a31e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5806, 72, 11)\n",
      "(5806, 12)\n"
     ]
    }
   ],
   "source": [
    "val_X_normal = val_X[val_X_pm <= percentile_pm]\n",
    "print(val_X_normal.shape)\n",
    "\n",
    "val_y_normal = val_y[val_X_pm <= percentile_pm]\n",
    "print(val_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7a678",
   "metadata": {},
   "source": [
    "### test_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63b22d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581, 72, 11)\n",
      "(581, 12)\n"
     ]
    }
   ],
   "source": [
    "test_X_extreme = test_X[test_X_pm > percentile_pm]\n",
    "print(test_X_extreme.shape)\n",
    "\n",
    "test_y_extreme = test_y[test_X_pm > percentile_pm]\n",
    "print(test_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5b82f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5977, 72, 11)\n",
      "(5977, 12)\n"
     ]
    }
   ],
   "source": [
    "test_X_normal = test_X[test_X_pm <= percentile_pm]\n",
    "print(test_X_normal.shape)\n",
    "\n",
    "test_y_normal = test_y[test_X_pm <= percentile_pm]\n",
    "print(test_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c626353",
   "metadata": {},
   "source": [
    "### Model & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4d95d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== model parameters ======\n",
    "mlp_unit1 = 128\n",
    "mlp_unit2 = 128\n",
    "mlp_unit3 = 64\n",
    "mlp_unit4 = 64\n",
    "mlp_unit5 = 32\n",
    "mlp_unit6 = 32\n",
    "mlp_unit7 = 16\n",
    "mlp_unit8 = 16\n",
    "dropout = 0.0\n",
    "kernel_size = 2\n",
    "pool_size = 2\n",
    "learning_rate = 1e-4\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.95\n",
    "PATIENCE = 100\n",
    "EPOCHS = 1000\n",
    "BATCH = 512\n",
    "opt_num = k\n",
    "input_shape = train_X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71f96438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_layer(input_shape=input_shape,\n",
    "                   mlp_unit1=mlp_unit1,\n",
    "                   mlp_unit2=mlp_unit2,\n",
    "                   mlp_unit3=mlp_unit3,\n",
    "                   mlp_unit4=mlp_unit4,\n",
    "                   mlp_unit5=mlp_unit5,\n",
    "                   mlp_unit6=mlp_unit6,\n",
    "                   mlp_unit7=mlp_unit7,\n",
    "                   mlp_unit8=mlp_unit8,\n",
    "                   dropout=dropout,\n",
    "                   masked_value=-1,\n",
    "                   opt_num=opt_num\n",
    "                  )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f1e0318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 14:59:41.259504: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-02-02 14:59:41.260390: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1700105000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 14:59:42.691132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 - 4s - loss: 0.0069 - mae: 0.0607 - val_loss: 0.0109 - val_mae: 0.0723\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.07229, saving model to ../../saved_models_mlp/pm_N.h5\n",
      "Epoch 2/1000\n",
      "59/59 - 1s - loss: 0.0044 - mae: 0.0459 - val_loss: 0.0096 - val_mae: 0.0667\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.07229 to 0.06672, saving model to ../../saved_models_mlp/pm_N.h5\n",
      "Epoch 3/1000\n",
      "59/59 - 1s - loss: 0.0039 - mae: 0.0423 - val_loss: 0.0089 - val_mae: 0.0637\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.06672 to 0.06366, saving model to ../../saved_models_mlp/pm_N.h5\n",
      "Epoch 4/1000\n",
      "59/59 - 1s - loss: 0.0037 - mae: 0.0412 - val_loss: 0.0089 - val_mae: 0.0668\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 0.06366\n",
      "Epoch 5/1000\n",
      "59/59 - 1s - loss: 0.0037 - mae: 0.0410 - val_loss: 0.0085 - val_mae: 0.0609\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.06366 to 0.06089, saving model to ../../saved_models_mlp/pm_N.h5\n",
      "Epoch 6/1000\n",
      "59/59 - 1s - loss: 0.0035 - mae: 0.0397 - val_loss: 0.0085 - val_mae: 0.0613\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 0.06089\n",
      "Epoch 7/1000\n",
      "59/59 - 1s - loss: 0.0034 - mae: 0.0390 - val_loss: 0.0082 - val_mae: 0.0631\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 0.06089\n",
      "Epoch 8/1000\n",
      "59/59 - 1s - loss: 0.0035 - mae: 0.0395 - val_loss: 0.0083 - val_mae: 0.0607\n",
      "\n",
      "Epoch 00008: val_mae improved from 0.06089 to 0.06074, saving model to ../../saved_models_mlp/pm_N.h5\n",
      "Epoch 9/1000\n",
      "59/59 - 1s - loss: 0.0034 - mae: 0.0387 - val_loss: 0.0081 - val_mae: 0.0605\n",
      "\n",
      "Epoch 00009: val_mae improved from 0.06074 to 0.06053, saving model to ../../saved_models_mlp/pm_N.h5\n",
      "Epoch 10/1000\n",
      "59/59 - 1s - loss: 0.0033 - mae: 0.0387 - val_loss: 0.0088 - val_mae: 0.0630\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 0.06053\n",
      "Epoch 11/1000\n",
      "59/59 - 1s - loss: 0.0033 - mae: 0.0382 - val_loss: 0.0086 - val_mae: 0.0632\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 0.06053\n",
      "Epoch 12/1000\n",
      "59/59 - 1s - loss: 0.0032 - mae: 0.0379 - val_loss: 0.0083 - val_mae: 0.0605\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 0.06053\n",
      "Epoch 13/1000\n",
      "59/59 - 1s - loss: 0.0032 - mae: 0.0377 - val_loss: 0.0081 - val_mae: 0.0598\n",
      "\n",
      "Epoch 00013: val_mae improved from 0.06053 to 0.05984, saving model to ../../saved_models_mlp/pm_N.h5\n",
      "Epoch 14/1000\n",
      "59/59 - 1s - loss: 0.0032 - mae: 0.0377 - val_loss: 0.0080 - val_mae: 0.0598\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 0.05984\n",
      "Epoch 15/1000\n",
      "59/59 - 1s - loss: 0.0032 - mae: 0.0375 - val_loss: 0.0083 - val_mae: 0.0613\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.05984\n",
      "Epoch 16/1000\n",
      "59/59 - 1s - loss: 0.0032 - mae: 0.0375 - val_loss: 0.0080 - val_mae: 0.0598\n",
      "\n",
      "Epoch 00016: val_mae improved from 0.05984 to 0.05977, saving model to ../../saved_models_mlp/pm_N.h5\n",
      "Epoch 17/1000\n",
      "59/59 - 1s - loss: 0.0032 - mae: 0.0376 - val_loss: 0.0080 - val_mae: 0.0598\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.05977\n",
      "Epoch 18/1000\n",
      "59/59 - 1s - loss: 0.0031 - mae: 0.0371 - val_loss: 0.0079 - val_mae: 0.0599\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 0.05977\n",
      "Epoch 19/1000\n",
      "59/59 - 1s - loss: 0.0031 - mae: 0.0370 - val_loss: 0.0078 - val_mae: 0.0608\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 0.05977\n",
      "Epoch 20/1000\n",
      "59/59 - 1s - loss: 0.0031 - mae: 0.0369 - val_loss: 0.0080 - val_mae: 0.0598\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 0.05977\n",
      "Epoch 21/1000\n",
      "59/59 - 1s - loss: 0.0030 - mae: 0.0368 - val_loss: 0.0080 - val_mae: 0.0601\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.05977\n",
      "Epoch 22/1000\n",
      "59/59 - 1s - loss: 0.0030 - mae: 0.0365 - val_loss: 0.0086 - val_mae: 0.0636\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 0.05977\n",
      "Epoch 23/1000\n",
      "59/59 - 1s - loss: 0.0030 - mae: 0.0368 - val_loss: 0.0081 - val_mae: 0.0607\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.05977\n",
      "Epoch 24/1000\n",
      "59/59 - 1s - loss: 0.0029 - mae: 0.0363 - val_loss: 0.0081 - val_mae: 0.0604\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.05977\n",
      "Epoch 25/1000\n",
      "59/59 - 1s - loss: 0.0029 - mae: 0.0362 - val_loss: 0.0080 - val_mae: 0.0606\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.05977\n",
      "Epoch 26/1000\n",
      "59/59 - 1s - loss: 0.0029 - mae: 0.0363 - val_loss: 0.0084 - val_mae: 0.0608\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.05977\n",
      "Epoch 27/1000\n",
      "59/59 - 1s - loss: 0.0029 - mae: 0.0361 - val_loss: 0.0084 - val_mae: 0.0613\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 0.05977\n",
      "Epoch 28/1000\n",
      "59/59 - 1s - loss: 0.0028 - mae: 0.0359 - val_loss: 0.0088 - val_mae: 0.0631\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.05977\n",
      "Epoch 29/1000\n",
      "59/59 - 1s - loss: 0.0028 - mae: 0.0357 - val_loss: 0.0085 - val_mae: 0.0631\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.05977\n",
      "Epoch 30/1000\n",
      "59/59 - 1s - loss: 0.0028 - mae: 0.0360 - val_loss: 0.0093 - val_mae: 0.0644\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.05977\n",
      "Epoch 31/1000\n",
      "59/59 - 1s - loss: 0.0027 - mae: 0.0354 - val_loss: 0.0086 - val_mae: 0.0621\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.05977\n",
      "Epoch 32/1000\n",
      "59/59 - 1s - loss: 0.0027 - mae: 0.0351 - val_loss: 0.0096 - val_mae: 0.0667\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 0.05977\n",
      "Epoch 33/1000\n",
      "59/59 - 1s - loss: 0.0026 - mae: 0.0349 - val_loss: 0.0098 - val_mae: 0.0661\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.05977\n",
      "Epoch 34/1000\n",
      "59/59 - 1s - loss: 0.0026 - mae: 0.0349 - val_loss: 0.0090 - val_mae: 0.0635\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.05977\n",
      "Epoch 35/1000\n",
      "59/59 - 1s - loss: 0.0026 - mae: 0.0352 - val_loss: 0.0095 - val_mae: 0.0671\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.05977\n",
      "Epoch 36/1000\n",
      "59/59 - 1s - loss: 0.0027 - mae: 0.0359 - val_loss: 0.0098 - val_mae: 0.0668\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.05977\n",
      "Epoch 37/1000\n",
      "59/59 - 1s - loss: 0.0025 - mae: 0.0345 - val_loss: 0.0097 - val_mae: 0.0655\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.05977\n",
      "Epoch 38/1000\n",
      "59/59 - 1s - loss: 0.0025 - mae: 0.0341 - val_loss: 0.0097 - val_mae: 0.0660\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.05977\n",
      "Epoch 39/1000\n",
      "59/59 - 1s - loss: 0.0024 - mae: 0.0336 - val_loss: 0.0099 - val_mae: 0.0659\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.05977\n",
      "Epoch 40/1000\n",
      "59/59 - 1s - loss: 0.0024 - mae: 0.0335 - val_loss: 0.0103 - val_mae: 0.0675\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.05977\n",
      "Epoch 41/1000\n",
      "59/59 - 1s - loss: 0.0023 - mae: 0.0335 - val_loss: 0.0106 - val_mae: 0.0696\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.05977\n",
      "Epoch 42/1000\n",
      "59/59 - 1s - loss: 0.0024 - mae: 0.0343 - val_loss: 0.0101 - val_mae: 0.0674\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 0.05977\n",
      "Epoch 43/1000\n",
      "59/59 - 1s - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0108 - val_mae: 0.0693\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.05977\n",
      "Epoch 44/1000\n",
      "59/59 - 1s - loss: 0.0023 - mae: 0.0329 - val_loss: 0.0103 - val_mae: 0.0682\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.05977\n",
      "Epoch 45/1000\n",
      "59/59 - 1s - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0111 - val_mae: 0.0715\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.05977\n",
      "Epoch 46/1000\n",
      "59/59 - 1s - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0106 - val_mae: 0.0689\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.05977\n",
      "Epoch 47/1000\n",
      "59/59 - 1s - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0107 - val_mae: 0.0687\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.05977\n",
      "Epoch 48/1000\n",
      "59/59 - 1s - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0115 - val_mae: 0.0717\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.05977\n",
      "Epoch 49/1000\n",
      "59/59 - 1s - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0111 - val_mae: 0.0712\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.05977\n",
      "Epoch 50/1000\n",
      "59/59 - 1s - loss: 0.0020 - mae: 0.0313 - val_loss: 0.0115 - val_mae: 0.0719\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.05977\n",
      "Epoch 51/1000\n",
      "59/59 - 1s - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0112 - val_mae: 0.0714\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.05977\n",
      "Epoch 52/1000\n",
      "59/59 - 1s - loss: 0.0020 - mae: 0.0316 - val_loss: 0.0122 - val_mae: 0.0733\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.05977\n",
      "Epoch 53/1000\n",
      "59/59 - 1s - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0118 - val_mae: 0.0725\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.05977\n",
      "Epoch 54/1000\n",
      "59/59 - 1s - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0122 - val_mae: 0.0729\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.05977\n",
      "Epoch 55/1000\n",
      "59/59 - 1s - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0121 - val_mae: 0.0738\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.05977\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 - 1s - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0114 - val_mae: 0.0716\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 0.05977\n",
      "Epoch 57/1000\n",
      "59/59 - 1s - loss: 0.0019 - mae: 0.0304 - val_loss: 0.0117 - val_mae: 0.0722\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.05977\n",
      "Epoch 58/1000\n",
      "59/59 - 1s - loss: 0.0018 - mae: 0.0300 - val_loss: 0.0123 - val_mae: 0.0741\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.05977\n",
      "Epoch 59/1000\n",
      "59/59 - 1s - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0131 - val_mae: 0.0769\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.05977\n",
      "Epoch 60/1000\n",
      "59/59 - 1s - loss: 0.0018 - mae: 0.0301 - val_loss: 0.0129 - val_mae: 0.0762\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.05977\n",
      "Epoch 61/1000\n",
      "59/59 - 1s - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0142 - val_mae: 0.0800\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.05977\n",
      "Epoch 62/1000\n",
      "59/59 - 1s - loss: 0.0018 - mae: 0.0302 - val_loss: 0.0132 - val_mae: 0.0771\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.05977\n",
      "Epoch 63/1000\n",
      "59/59 - 1s - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0130 - val_mae: 0.0765\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.05977\n",
      "Epoch 64/1000\n",
      "59/59 - 1s - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0129 - val_mae: 0.0762\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.05977\n",
      "Epoch 65/1000\n",
      "59/59 - 1s - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0138 - val_mae: 0.0791\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.05977\n",
      "Epoch 66/1000\n",
      "59/59 - 1s - loss: 0.0017 - mae: 0.0290 - val_loss: 0.0139 - val_mae: 0.0794\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.05977\n",
      "Epoch 67/1000\n",
      "59/59 - 1s - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0141 - val_mae: 0.0789\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.05977\n",
      "Epoch 68/1000\n",
      "59/59 - 1s - loss: 0.0017 - mae: 0.0290 - val_loss: 0.0133 - val_mae: 0.0770\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.05977\n",
      "Epoch 69/1000\n",
      "59/59 - 1s - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0139 - val_mae: 0.0800\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.05977\n",
      "Epoch 70/1000\n",
      "59/59 - 1s - loss: 0.0017 - mae: 0.0291 - val_loss: 0.0141 - val_mae: 0.0790\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.05977\n",
      "Epoch 71/1000\n",
      "59/59 - 1s - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0144 - val_mae: 0.0797\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.05977\n",
      "Epoch 72/1000\n",
      "59/59 - 1s - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0141 - val_mae: 0.0803\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.05977\n",
      "Epoch 73/1000\n",
      "59/59 - 1s - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0147 - val_mae: 0.0807\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.05977\n",
      "Epoch 74/1000\n",
      "59/59 - 1s - loss: 0.0015 - mae: 0.0277 - val_loss: 0.0148 - val_mae: 0.0807\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.05977\n",
      "Epoch 75/1000\n",
      "59/59 - 1s - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0142 - val_mae: 0.0794\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.05977\n",
      "Epoch 76/1000\n",
      "59/59 - 1s - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0144 - val_mae: 0.0803\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.05977\n",
      "Epoch 77/1000\n",
      "59/59 - 1s - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0149 - val_mae: 0.0810\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.05977\n",
      "Epoch 78/1000\n",
      "59/59 - 1s - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0156 - val_mae: 0.0837\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.05977\n",
      "Epoch 79/1000\n",
      "59/59 - 1s - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0146 - val_mae: 0.0808\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.05977\n",
      "Epoch 80/1000\n",
      "59/59 - 1s - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0152 - val_mae: 0.0819\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.05977\n",
      "Epoch 81/1000\n",
      "59/59 - 1s - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0147 - val_mae: 0.0809\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.05977\n",
      "Epoch 82/1000\n",
      "59/59 - 1s - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0157 - val_mae: 0.0839\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.05977\n",
      "Epoch 83/1000\n",
      "59/59 - 1s - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0162 - val_mae: 0.0853\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.05977\n",
      "Epoch 84/1000\n",
      "59/59 - 1s - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0161 - val_mae: 0.0851\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.05977\n",
      "Epoch 85/1000\n",
      "59/59 - 1s - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0166 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.05977\n",
      "Epoch 86/1000\n",
      "59/59 - 1s - loss: 0.0014 - mae: 0.0263 - val_loss: 0.0162 - val_mae: 0.0849\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.05977\n",
      "Epoch 87/1000\n",
      "59/59 - 1s - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0174 - val_mae: 0.0886\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.05977\n",
      "Epoch 88/1000\n",
      "59/59 - 1s - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0165 - val_mae: 0.0863\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.05977\n",
      "Epoch 89/1000\n",
      "59/59 - 1s - loss: 0.0013 - mae: 0.0258 - val_loss: 0.0181 - val_mae: 0.0907\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.05977\n",
      "Epoch 90/1000\n",
      "59/59 - 1s - loss: 0.0013 - mae: 0.0256 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.05977\n",
      "Epoch 91/1000\n",
      "59/59 - 1s - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0173 - val_mae: 0.0881\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.05977\n",
      "Epoch 92/1000\n",
      "59/59 - 1s - loss: 0.0013 - mae: 0.0252 - val_loss: 0.0172 - val_mae: 0.0876\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.05977\n",
      "Epoch 93/1000\n",
      "59/59 - 1s - loss: 0.0013 - mae: 0.0254 - val_loss: 0.0179 - val_mae: 0.0892\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.05977\n",
      "Epoch 94/1000\n",
      "59/59 - 1s - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0167 - val_mae: 0.0865\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.05977\n",
      "Epoch 95/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0180 - val_mae: 0.0899\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.05977\n",
      "Epoch 96/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0173 - val_mae: 0.0879\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.05977\n",
      "Epoch 97/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0186 - val_mae: 0.0910\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.05977\n",
      "Epoch 98/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0185 - val_mae: 0.0910\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.05977\n",
      "Epoch 99/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0179 - val_mae: 0.0910\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.05977\n",
      "Epoch 100/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0177 - val_mae: 0.0887\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.05977\n",
      "Epoch 101/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0188 - val_mae: 0.0919\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.05977\n",
      "Epoch 102/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0194 - val_mae: 0.0925\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.05977\n",
      "Epoch 103/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0182 - val_mae: 0.0907\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.05977\n",
      "Epoch 104/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0189 - val_mae: 0.0914\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.05977\n",
      "Epoch 105/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0193 - val_mae: 0.0929\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.05977\n",
      "Epoch 106/1000\n",
      "59/59 - 1s - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0184 - val_mae: 0.0912\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.05977\n",
      "Epoch 107/1000\n",
      "59/59 - 1s - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0186 - val_mae: 0.0911\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.05977\n",
      "Epoch 108/1000\n",
      "59/59 - 1s - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0188 - val_mae: 0.0914\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.05977\n",
      "Epoch 109/1000\n",
      "59/59 - 1s - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0196 - val_mae: 0.0938\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.05977\n",
      "Epoch 110/1000\n",
      "59/59 - 1s - loss: 0.0011 - mae: 0.0236 - val_loss: 0.0195 - val_mae: 0.0939\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.05977\n",
      "Epoch 111/1000\n",
      "59/59 - 1s - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0181 - val_mae: 0.0903\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.05977\n",
      "Epoch 112/1000\n",
      "59/59 - 1s - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0199 - val_mae: 0.0954\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.05977\n",
      "Epoch 113/1000\n",
      "59/59 - 1s - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0184 - val_mae: 0.0916\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.05977\n",
      "Epoch 114/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 - 1s - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0193 - val_mae: 0.0932\n",
      "\n",
      "Epoch 00114: val_mae did not improve from 0.05977\n",
      "Epoch 115/1000\n",
      "59/59 - 1s - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0203 - val_mae: 0.0960\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.05977\n",
      "Epoch 116/1000\n",
      "59/59 - 1s - loss: 0.0011 - mae: 0.0232 - val_loss: 0.0199 - val_mae: 0.0940\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.05977\n",
      "Epoch 00116: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a6071a760>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate, \n",
    "#                                                           decay_steps=decay_steps,\n",
    "#                                                           decay_rate=decay_rate)\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "#               loss='mse',\n",
    "#               metrics=['mae']\n",
    "#              )\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae']\n",
    "             )\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_mae', mode='min', verbose=2, patience=PATIENCE)\n",
    "mc = ModelCheckpoint('../../saved_models_mlp/pm_N.h5', \n",
    "                     monitor='val_mae', \n",
    "                     mode='min', \n",
    "                     verbose=2, \n",
    "                     save_best_only=True\n",
    "                    )\n",
    "\n",
    "\n",
    "model.fit(train_X_normal, train_y_normal,\n",
    "          validation_data=(val_X_normal, val_y_normal),\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH,\n",
    "          verbose=2,\n",
    "          shuffle=True,\n",
    "          callbacks=[es, mc]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3c6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf5004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7c598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
