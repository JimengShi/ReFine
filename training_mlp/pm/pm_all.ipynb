{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25441506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 14:33:51.487743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from helper import series_to_supervised\n",
    "from model.mlp import mlp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2af1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eefef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# random.seed(10)\n",
    "# print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537a30dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "      <th>NE</th>\n",
       "      <th>NW</th>\n",
       "      <th>SE</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press  wnd_spd  snow  rain  NE  \\\n",
       "date                                                                         \n",
       "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0     1.79     0     0   0   \n",
       "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0     2.68     0     0   0   \n",
       "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0     3.57     0     0   0   \n",
       "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0     5.36     1     0   0   \n",
       "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0     6.25     2     0   0   \n",
       "\n",
       "                     NW  SE  cv  \n",
       "date                             \n",
       "2010-01-02 00:00:00   0   1   0  \n",
       "2010-01-02 01:00:00   0   1   0  \n",
       "2010-01-02 02:00:00   0   1   0  \n",
       "2010-01-02 03:00:00   0   1   0  \n",
       "2010-01-02 04:00:00   0   1   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/pollution.csv\", index_col=0)\n",
    "data.fillna(0, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413bfd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "      <th>NE</th>\n",
       "      <th>NW</th>\n",
       "      <th>SE</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>231.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>237.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>242.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>246.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>249.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43800 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press  wnd_spd  snow  rain  NE  \\\n",
       "date                                                                         \n",
       "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0     1.79     0     0   0   \n",
       "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0     2.68     0     0   0   \n",
       "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0     3.57     0     0   0   \n",
       "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0     5.36     1     0   0   \n",
       "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0     6.25     2     0   0   \n",
       "...                        ...  ...   ...     ...      ...   ...   ...  ..   \n",
       "2014-12-31 19:00:00        8.0  -23  -2.0  1034.0   231.97     0     0   0   \n",
       "2014-12-31 20:00:00       10.0  -22  -3.0  1034.0   237.78     0     0   0   \n",
       "2014-12-31 21:00:00       10.0  -22  -3.0  1034.0   242.70     0     0   0   \n",
       "2014-12-31 22:00:00        8.0  -22  -4.0  1034.0   246.72     0     0   0   \n",
       "2014-12-31 23:00:00       12.0  -21  -3.0  1034.0   249.85     0     0   0   \n",
       "\n",
       "                     NW  SE  cv  \n",
       "date                             \n",
       "2010-01-02 00:00:00   0   1   0  \n",
       "2010-01-02 01:00:00   0   1   0  \n",
       "2010-01-02 02:00:00   0   1   0  \n",
       "2010-01-02 03:00:00   0   1   0  \n",
       "2010-01-02 04:00:00   0   1   0  \n",
       "...                  ..  ..  ..  \n",
       "2014-12-31 19:00:00   1   0   0  \n",
       "2014-12-31 20:00:00   1   0   0  \n",
       "2014-12-31 21:00:00   1   0   0  \n",
       "2014-12-31 22:00:00   1   0   0  \n",
       "2014-12-31 23:00:00   1   0   0  \n",
       "\n",
       "[43800 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f927e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pollution', 'dew', 'temp', 'press', 'wnd_spd', 'snow', 'rain', 'NE',\n",
       "       'NW', 'SE', 'cv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e52b1443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.7727e+04, 1.0511e+04, 6.4690e+03, 3.7450e+03, 2.2240e+03,\n",
       "        1.3270e+03, 7.5900e+02, 4.6700e+02, 2.8700e+02, 1.5400e+02,\n",
       "        7.2000e+01, 2.5000e+01, 7.0000e+00, 8.0000e+00, 4.0000e+00,\n",
       "        3.0000e+00, 4.0000e+00, 4.0000e+00, 0.0000e+00, 3.0000e+00]),\n",
       " array([  0. ,  49.7,  99.4, 149.1, 198.8, 248.5, 298.2, 347.9, 397.6,\n",
       "        447.3, 497. , 546.7, 596.4, 646.1, 695.8, 745.5, 795.2, 844.9,\n",
       "        894.6, 944.3, 994. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['pollution'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf49194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data['pollution'], 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee4ab3",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f75f7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reframed.shape: (43717, 924)\n"
     ]
    }
   ],
   "source": [
    "values = data.values\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_hours = 24*3\n",
    "n_features = data.shape[-1]\n",
    "k = 12\n",
    "split1 = 0.7\n",
    "split2 = 0.85\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(values, n_hours, k)\n",
    "print(\"reframed.shape:\", reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f94f6e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (30601, 792) (30601, 12) (6558, 792) (6558, 12) (6558, 792) (6558, 12)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "reframed_values = reframed.values\n",
    "n_train_hours = int(len(reframed_values)*split1)\n",
    "n_valid_hours = int(len(reframed_values)*split2)\n",
    "\n",
    "train = reframed_values[:n_train_hours, :]\n",
    "val = reframed_values[n_train_hours:n_valid_hours, :]\n",
    "test = reframed_values[n_valid_hours:, :]\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "feature_idx = 0\n",
    "train_X, train_y = train[:, :n_obs], train[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "val_X, val_y = val[:, :n_obs], val[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "test_X, test_y = test[:, :n_obs], test[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9de0c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (30601, 72, 11) (30601, 12) (6558, 72, 11) (6558, 12) (6558, 72, 11) (6558, 12)\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "train_y = scaler.fit_transform(train_y)\n",
    "\n",
    "val_X = scaler.fit_transform(val_X)\n",
    "val_y = scaler.fit_transform(val_y)\n",
    "\n",
    "test_X = scaler.fit_transform(test_X)\n",
    "test_y = scaler.fit_transform(test_y)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c626353",
   "metadata": {},
   "source": [
    "### Model & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4d95d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== model parameters ======\n",
    "mlp_unit1 = 128\n",
    "mlp_unit2 = 128\n",
    "mlp_unit3 = 64\n",
    "mlp_unit4 = 64\n",
    "mlp_unit5 = 32\n",
    "mlp_unit6 = 32\n",
    "mlp_unit7 = 16\n",
    "mlp_unit8 = 16\n",
    "dropout = 0.0\n",
    "kernel_size = 2\n",
    "pool_size = 2\n",
    "learning_rate = 1e-4\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.95\n",
    "PATIENCE = 100\n",
    "EPOCHS = 1000\n",
    "BATCH = 512\n",
    "opt_num = k\n",
    "input_shape = train_X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71f96438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_layer(input_shape=input_shape,\n",
    "                   mlp_unit1=mlp_unit1,\n",
    "                   mlp_unit2=mlp_unit2,\n",
    "                   mlp_unit3=mlp_unit3,\n",
    "                   mlp_unit4=mlp_unit4,\n",
    "                   mlp_unit5=mlp_unit5,\n",
    "                   mlp_unit6=mlp_unit6,\n",
    "                   mlp_unit7=mlp_unit7,\n",
    "                   mlp_unit8=mlp_unit8,\n",
    "                   dropout=dropout,\n",
    "                   masked_value=-1,\n",
    "                   opt_num=opt_num\n",
    "                  )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f1e0318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60/60 - 2s - loss: 0.0070 - mae: 0.0606 - val_loss: 0.0117 - val_mae: 0.0754\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.07539, saving model to ../../saved_models/pm_all.h5\n",
      "Epoch 2/1000\n",
      "60/60 - 1s - loss: 0.0044 - mae: 0.0456 - val_loss: 0.0100 - val_mae: 0.0672\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.07539 to 0.06723, saving model to ../../saved_models/pm_all.h5\n",
      "Epoch 3/1000\n",
      "60/60 - 1s - loss: 0.0040 - mae: 0.0429 - val_loss: 0.0092 - val_mae: 0.0640\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.06723 to 0.06399, saving model to ../../saved_models/pm_all.h5\n",
      "Epoch 4/1000\n",
      "60/60 - 1s - loss: 0.0038 - mae: 0.0413 - val_loss: 0.0086 - val_mae: 0.0616\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.06399 to 0.06157, saving model to ../../saved_models/pm_all.h5\n",
      "Epoch 5/1000\n",
      "60/60 - 1s - loss: 0.0036 - mae: 0.0403 - val_loss: 0.0085 - val_mae: 0.0610\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.06157 to 0.06104, saving model to ../../saved_models/pm_all.h5\n",
      "Epoch 6/1000\n",
      "60/60 - 1s - loss: 0.0036 - mae: 0.0402 - val_loss: 0.0083 - val_mae: 0.0601\n",
      "\n",
      "Epoch 00006: val_mae improved from 0.06104 to 0.06009, saving model to ../../saved_models/pm_all.h5\n",
      "Epoch 7/1000\n",
      "60/60 - 1s - loss: 0.0035 - mae: 0.0392 - val_loss: 0.0082 - val_mae: 0.0608\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 0.06009\n",
      "Epoch 8/1000\n",
      "60/60 - 1s - loss: 0.0034 - mae: 0.0387 - val_loss: 0.0083 - val_mae: 0.0604\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 0.06009\n",
      "Epoch 9/1000\n",
      "60/60 - 1s - loss: 0.0034 - mae: 0.0389 - val_loss: 0.0082 - val_mae: 0.0603\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 0.06009\n",
      "Epoch 10/1000\n",
      "60/60 - 1s - loss: 0.0033 - mae: 0.0381 - val_loss: 0.0084 - val_mae: 0.0615\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 0.06009\n",
      "Epoch 11/1000\n",
      "60/60 - 1s - loss: 0.0033 - mae: 0.0381 - val_loss: 0.0082 - val_mae: 0.0606\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 0.06009\n",
      "Epoch 12/1000\n",
      "60/60 - 1s - loss: 0.0033 - mae: 0.0380 - val_loss: 0.0084 - val_mae: 0.0608\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 0.06009\n",
      "Epoch 13/1000\n",
      "60/60 - 1s - loss: 0.0032 - mae: 0.0376 - val_loss: 0.0085 - val_mae: 0.0620\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 0.06009\n",
      "Epoch 14/1000\n",
      "60/60 - 1s - loss: 0.0032 - mae: 0.0375 - val_loss: 0.0083 - val_mae: 0.0599\n",
      "\n",
      "Epoch 00014: val_mae improved from 0.06009 to 0.05989, saving model to ../../saved_models/pm_all.h5\n",
      "Epoch 15/1000\n",
      "60/60 - 1s - loss: 0.0031 - mae: 0.0371 - val_loss: 0.0089 - val_mae: 0.0637\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.05989\n",
      "Epoch 16/1000\n",
      "60/60 - 1s - loss: 0.0031 - mae: 0.0373 - val_loss: 0.0090 - val_mae: 0.0632\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 0.05989\n",
      "Epoch 17/1000\n",
      "60/60 - 1s - loss: 0.0031 - mae: 0.0370 - val_loss: 0.0082 - val_mae: 0.0603\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.05989\n",
      "Epoch 18/1000\n",
      "60/60 - 1s - loss: 0.0030 - mae: 0.0366 - val_loss: 0.0088 - val_mae: 0.0629\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 0.05989\n",
      "Epoch 19/1000\n",
      "60/60 - 1s - loss: 0.0030 - mae: 0.0372 - val_loss: 0.0085 - val_mae: 0.0613\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 0.05989\n",
      "Epoch 20/1000\n",
      "60/60 - 1s - loss: 0.0029 - mae: 0.0365 - val_loss: 0.0088 - val_mae: 0.0627\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 0.05989\n",
      "Epoch 21/1000\n",
      "60/60 - 1s - loss: 0.0029 - mae: 0.0366 - val_loss: 0.0103 - val_mae: 0.0703\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.05989\n",
      "Epoch 22/1000\n",
      "60/60 - 1s - loss: 0.0029 - mae: 0.0366 - val_loss: 0.0086 - val_mae: 0.0619\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 0.05989\n",
      "Epoch 23/1000\n",
      "60/60 - 1s - loss: 0.0028 - mae: 0.0363 - val_loss: 0.0086 - val_mae: 0.0622\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.05989\n",
      "Epoch 24/1000\n",
      "60/60 - 1s - loss: 0.0027 - mae: 0.0355 - val_loss: 0.0094 - val_mae: 0.0656\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.05989\n",
      "Epoch 25/1000\n",
      "60/60 - 1s - loss: 0.0027 - mae: 0.0352 - val_loss: 0.0089 - val_mae: 0.0641\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.05989\n",
      "Epoch 26/1000\n",
      "60/60 - 1s - loss: 0.0027 - mae: 0.0354 - val_loss: 0.0093 - val_mae: 0.0662\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.05989\n",
      "Epoch 27/1000\n",
      "60/60 - 1s - loss: 0.0027 - mae: 0.0353 - val_loss: 0.0097 - val_mae: 0.0663\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 0.05989\n",
      "Epoch 28/1000\n",
      "60/60 - 1s - loss: 0.0026 - mae: 0.0345 - val_loss: 0.0091 - val_mae: 0.0646\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.05989\n",
      "Epoch 29/1000\n",
      "60/60 - 1s - loss: 0.0026 - mae: 0.0346 - val_loss: 0.0094 - val_mae: 0.0654\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.05989\n",
      "Epoch 30/1000\n",
      "60/60 - 1s - loss: 0.0025 - mae: 0.0342 - val_loss: 0.0101 - val_mae: 0.0679\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.05989\n",
      "Epoch 31/1000\n",
      "60/60 - 1s - loss: 0.0024 - mae: 0.0339 - val_loss: 0.0100 - val_mae: 0.0673\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.05989\n",
      "Epoch 32/1000\n",
      "60/60 - 1s - loss: 0.0024 - mae: 0.0340 - val_loss: 0.0101 - val_mae: 0.0678\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 0.05989\n",
      "Epoch 33/1000\n",
      "60/60 - 1s - loss: 0.0024 - mae: 0.0336 - val_loss: 0.0099 - val_mae: 0.0677\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.05989\n",
      "Epoch 34/1000\n",
      "60/60 - 1s - loss: 0.0024 - mae: 0.0334 - val_loss: 0.0101 - val_mae: 0.0681\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.05989\n",
      "Epoch 35/1000\n",
      "60/60 - 1s - loss: 0.0023 - mae: 0.0331 - val_loss: 0.0103 - val_mae: 0.0688\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.05989\n",
      "Epoch 36/1000\n",
      "60/60 - 1s - loss: 0.0023 - mae: 0.0332 - val_loss: 0.0098 - val_mae: 0.0680\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.05989\n",
      "Epoch 37/1000\n",
      "60/60 - 1s - loss: 0.0022 - mae: 0.0326 - val_loss: 0.0098 - val_mae: 0.0672\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.05989\n",
      "Epoch 38/1000\n",
      "60/60 - 1s - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0099 - val_mae: 0.0686\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.05989\n",
      "Epoch 39/1000\n",
      "60/60 - 1s - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0106 - val_mae: 0.0703\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.05989\n",
      "Epoch 40/1000\n",
      "60/60 - 1s - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0107 - val_mae: 0.0711\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.05989\n",
      "Epoch 41/1000\n",
      "60/60 - 1s - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0114 - val_mae: 0.0734\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.05989\n",
      "Epoch 42/1000\n",
      "60/60 - 1s - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0106 - val_mae: 0.0713\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 0.05989\n",
      "Epoch 43/1000\n",
      "60/60 - 1s - loss: 0.0020 - mae: 0.0314 - val_loss: 0.0112 - val_mae: 0.0721\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.05989\n",
      "Epoch 44/1000\n",
      "60/60 - 1s - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0111 - val_mae: 0.0729\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.05989\n",
      "Epoch 45/1000\n",
      "60/60 - 1s - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0121 - val_mae: 0.0751\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.05989\n",
      "Epoch 46/1000\n",
      "60/60 - 1s - loss: 0.0019 - mae: 0.0306 - val_loss: 0.0118 - val_mae: 0.0751\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.05989\n",
      "Epoch 47/1000\n",
      "60/60 - 1s - loss: 0.0019 - mae: 0.0306 - val_loss: 0.0119 - val_mae: 0.0756\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.05989\n",
      "Epoch 48/1000\n",
      "60/60 - 1s - loss: 0.0019 - mae: 0.0303 - val_loss: 0.0115 - val_mae: 0.0743\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.05989\n",
      "Epoch 49/1000\n",
      "60/60 - 1s - loss: 0.0019 - mae: 0.0304 - val_loss: 0.0121 - val_mae: 0.0761\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.05989\n",
      "Epoch 50/1000\n",
      "60/60 - 1s - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0122 - val_mae: 0.0758\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.05989\n",
      "Epoch 51/1000\n",
      "60/60 - 1s - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0125 - val_mae: 0.0769\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.05989\n",
      "Epoch 52/1000\n",
      "60/60 - 1s - loss: 0.0018 - mae: 0.0294 - val_loss: 0.0127 - val_mae: 0.0777\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.05989\n",
      "Epoch 53/1000\n",
      "60/60 - 1s - loss: 0.0018 - mae: 0.0294 - val_loss: 0.0131 - val_mae: 0.0784\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.05989\n",
      "Epoch 54/1000\n",
      "60/60 - 1s - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0124 - val_mae: 0.0773\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.05989\n",
      "Epoch 55/1000\n",
      "60/60 - 1s - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0130 - val_mae: 0.0785\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.05989\n",
      "Epoch 56/1000\n",
      "60/60 - 1s - loss: 0.0017 - mae: 0.0291 - val_loss: 0.0120 - val_mae: 0.0762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00056: val_mae did not improve from 0.05989\n",
      "Epoch 57/1000\n",
      "60/60 - 1s - loss: 0.0017 - mae: 0.0286 - val_loss: 0.0128 - val_mae: 0.0785\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.05989\n",
      "Epoch 58/1000\n",
      "60/60 - 1s - loss: 0.0017 - mae: 0.0289 - val_loss: 0.0135 - val_mae: 0.0801\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.05989\n",
      "Epoch 59/1000\n",
      "60/60 - 1s - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0138 - val_mae: 0.0816\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.05989\n",
      "Epoch 60/1000\n",
      "60/60 - 1s - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0130 - val_mae: 0.0795\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.05989\n",
      "Epoch 61/1000\n",
      "60/60 - 1s - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0133 - val_mae: 0.0801\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.05989\n",
      "Epoch 62/1000\n",
      "60/60 - 1s - loss: 0.0016 - mae: 0.0277 - val_loss: 0.0133 - val_mae: 0.0809\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.05989\n",
      "Epoch 63/1000\n",
      "60/60 - 1s - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0138 - val_mae: 0.0824\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.05989\n",
      "Epoch 64/1000\n",
      "60/60 - 1s - loss: 0.0015 - mae: 0.0276 - val_loss: 0.0129 - val_mae: 0.0798\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.05989\n",
      "Epoch 65/1000\n",
      "60/60 - 1s - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0138 - val_mae: 0.0818\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.05989\n",
      "Epoch 66/1000\n",
      "60/60 - 1s - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0140 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.05989\n",
      "Epoch 67/1000\n",
      "60/60 - 1s - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0135 - val_mae: 0.0818\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.05989\n",
      "Epoch 68/1000\n",
      "60/60 - 1s - loss: 0.0015 - mae: 0.0269 - val_loss: 0.0134 - val_mae: 0.0819\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.05989\n",
      "Epoch 69/1000\n",
      "60/60 - 1s - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0141 - val_mae: 0.0840\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.05989\n",
      "Epoch 70/1000\n",
      "60/60 - 1s - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0145 - val_mae: 0.0846\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.05989\n",
      "Epoch 71/1000\n",
      "60/60 - 1s - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0146 - val_mae: 0.0849\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.05989\n",
      "Epoch 72/1000\n",
      "60/60 - 1s - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0140 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.05989\n",
      "Epoch 73/1000\n",
      "60/60 - 1s - loss: 0.0013 - mae: 0.0258 - val_loss: 0.0146 - val_mae: 0.0851\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.05989\n",
      "Epoch 74/1000\n",
      "60/60 - 1s - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0138 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.05989\n",
      "Epoch 75/1000\n",
      "60/60 - 1s - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0148 - val_mae: 0.0854\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.05989\n",
      "Epoch 76/1000\n",
      "60/60 - 1s - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0152 - val_mae: 0.0872\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.05989\n",
      "Epoch 77/1000\n",
      "60/60 - 1s - loss: 0.0013 - mae: 0.0255 - val_loss: 0.0148 - val_mae: 0.0862\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.05989\n",
      "Epoch 78/1000\n",
      "60/60 - 1s - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0154 - val_mae: 0.0874\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.05989\n",
      "Epoch 79/1000\n",
      "60/60 - 1s - loss: 0.0013 - mae: 0.0254 - val_loss: 0.0154 - val_mae: 0.0879\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.05989\n",
      "Epoch 80/1000\n",
      "60/60 - 1s - loss: 0.0013 - mae: 0.0254 - val_loss: 0.0151 - val_mae: 0.0874\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.05989\n",
      "Epoch 81/1000\n",
      "60/60 - 1s - loss: 0.0013 - mae: 0.0251 - val_loss: 0.0151 - val_mae: 0.0868\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.05989\n",
      "Epoch 82/1000\n",
      "60/60 - 1s - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0150 - val_mae: 0.0864\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.05989\n",
      "Epoch 83/1000\n",
      "60/60 - 1s - loss: 0.0012 - mae: 0.0246 - val_loss: 0.0161 - val_mae: 0.0893\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.05989\n",
      "Epoch 84/1000\n",
      "60/60 - 1s - loss: 0.0012 - mae: 0.0246 - val_loss: 0.0152 - val_mae: 0.0870\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.05989\n",
      "Epoch 85/1000\n",
      "60/60 - 1s - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0148 - val_mae: 0.0865\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.05989\n",
      "Epoch 86/1000\n",
      "60/60 - 1s - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0152 - val_mae: 0.0870\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.05989\n",
      "Epoch 87/1000\n",
      "60/60 - 1s - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0156 - val_mae: 0.0888\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.05989\n",
      "Epoch 88/1000\n",
      "60/60 - 1s - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0156 - val_mae: 0.0885\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.05989\n",
      "Epoch 89/1000\n",
      "60/60 - 1s - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0155 - val_mae: 0.0886\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.05989\n",
      "Epoch 90/1000\n",
      "60/60 - 1s - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0153 - val_mae: 0.0878\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.05989\n",
      "Epoch 91/1000\n",
      "60/60 - 1s - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0155 - val_mae: 0.0882\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.05989\n",
      "Epoch 92/1000\n",
      "60/60 - 1s - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0157 - val_mae: 0.0889\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.05989\n",
      "Epoch 93/1000\n",
      "60/60 - 1s - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0156 - val_mae: 0.0893\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.05989\n",
      "Epoch 94/1000\n",
      "60/60 - 1s - loss: 0.0011 - mae: 0.0236 - val_loss: 0.0158 - val_mae: 0.0896\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.05989\n",
      "Epoch 95/1000\n",
      "60/60 - 1s - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0160 - val_mae: 0.0897\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.05989\n",
      "Epoch 96/1000\n",
      "60/60 - 1s - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0158 - val_mae: 0.0894\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.05989\n",
      "Epoch 97/1000\n",
      "60/60 - 1s - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0160 - val_mae: 0.0898\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.05989\n",
      "Epoch 98/1000\n",
      "60/60 - 1s - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0159 - val_mae: 0.0899\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.05989\n",
      "Epoch 99/1000\n",
      "60/60 - 1s - loss: 0.0010 - mae: 0.0229 - val_loss: 0.0163 - val_mae: 0.0907\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.05989\n",
      "Epoch 100/1000\n",
      "60/60 - 1s - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0164 - val_mae: 0.0904\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.05989\n",
      "Epoch 101/1000\n",
      "60/60 - 1s - loss: 0.0010 - mae: 0.0227 - val_loss: 0.0161 - val_mae: 0.0901\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.05989\n",
      "Epoch 102/1000\n",
      "60/60 - 1s - loss: 0.0010 - mae: 0.0225 - val_loss: 0.0163 - val_mae: 0.0906\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.05989\n",
      "Epoch 103/1000\n",
      "60/60 - 1s - loss: 0.0010 - mae: 0.0226 - val_loss: 0.0168 - val_mae: 0.0918\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.05989\n",
      "Epoch 104/1000\n",
      "60/60 - 1s - loss: 9.8770e-04 - mae: 0.0222 - val_loss: 0.0168 - val_mae: 0.0916\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.05989\n",
      "Epoch 105/1000\n",
      "60/60 - 1s - loss: 0.0010 - mae: 0.0225 - val_loss: 0.0165 - val_mae: 0.0906\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.05989\n",
      "Epoch 106/1000\n",
      "60/60 - 1s - loss: 9.6281e-04 - mae: 0.0219 - val_loss: 0.0169 - val_mae: 0.0922\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.05989\n",
      "Epoch 107/1000\n",
      "60/60 - 1s - loss: 9.9134e-04 - mae: 0.0223 - val_loss: 0.0171 - val_mae: 0.0932\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.05989\n",
      "Epoch 108/1000\n",
      "60/60 - 1s - loss: 9.3786e-04 - mae: 0.0216 - val_loss: 0.0177 - val_mae: 0.0946\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.05989\n",
      "Epoch 109/1000\n",
      "60/60 - 1s - loss: 9.7036e-04 - mae: 0.0221 - val_loss: 0.0175 - val_mae: 0.0945\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.05989\n",
      "Epoch 110/1000\n",
      "60/60 - 1s - loss: 9.6943e-04 - mae: 0.0221 - val_loss: 0.0173 - val_mae: 0.0934\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.05989\n",
      "Epoch 111/1000\n",
      "60/60 - 1s - loss: 9.4784e-04 - mae: 0.0218 - val_loss: 0.0174 - val_mae: 0.0936\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.05989\n",
      "Epoch 112/1000\n",
      "60/60 - 1s - loss: 0.0010 - mae: 0.0225 - val_loss: 0.0176 - val_mae: 0.0943\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.05989\n",
      "Epoch 113/1000\n",
      "60/60 - 1s - loss: 9.6438e-04 - mae: 0.0221 - val_loss: 0.0171 - val_mae: 0.0934\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.05989\n",
      "Epoch 114/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 - 1s - loss: 9.2506e-04 - mae: 0.0215 - val_loss: 0.0177 - val_mae: 0.0946\n",
      "\n",
      "Epoch 00114: val_mae did not improve from 0.05989\n",
      "Epoch 115/1000\n",
      "60/60 - 1s - loss: 9.1727e-04 - mae: 0.0214 - val_loss: 0.0179 - val_mae: 0.0953\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.05989\n",
      "Epoch 116/1000\n",
      "60/60 - 1s - loss: 9.0872e-04 - mae: 0.0213 - val_loss: 0.0179 - val_mae: 0.0958\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.05989\n",
      "Epoch 117/1000\n",
      "60/60 - 1s - loss: 8.9935e-04 - mae: 0.0212 - val_loss: 0.0179 - val_mae: 0.0952\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.05989\n",
      "Epoch 118/1000\n",
      "60/60 - 1s - loss: 8.9009e-04 - mae: 0.0211 - val_loss: 0.0178 - val_mae: 0.0952\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.05989\n",
      "Epoch 119/1000\n",
      "60/60 - 1s - loss: 8.9119e-04 - mae: 0.0212 - val_loss: 0.0185 - val_mae: 0.0967\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.05989\n",
      "Epoch 120/1000\n",
      "60/60 - 1s - loss: 8.6060e-04 - mae: 0.0207 - val_loss: 0.0178 - val_mae: 0.0952\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.05989\n",
      "Epoch 121/1000\n",
      "60/60 - 1s - loss: 8.9838e-04 - mae: 0.0213 - val_loss: 0.0185 - val_mae: 0.0963\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.05989\n",
      "Epoch 122/1000\n",
      "60/60 - 1s - loss: 8.5157e-04 - mae: 0.0206 - val_loss: 0.0186 - val_mae: 0.0974\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.05989\n",
      "Epoch 123/1000\n",
      "60/60 - 1s - loss: 8.6111e-04 - mae: 0.0208 - val_loss: 0.0182 - val_mae: 0.0958\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.05989\n",
      "Epoch 124/1000\n",
      "60/60 - 1s - loss: 8.9774e-04 - mae: 0.0213 - val_loss: 0.0186 - val_mae: 0.0964\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.05989\n",
      "Epoch 125/1000\n",
      "60/60 - 1s - loss: 8.9359e-04 - mae: 0.0213 - val_loss: 0.0191 - val_mae: 0.0981\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.05989\n",
      "Epoch 126/1000\n",
      "60/60 - 1s - loss: 8.5126e-04 - mae: 0.0207 - val_loss: 0.0185 - val_mae: 0.0968\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.05989\n",
      "Epoch 127/1000\n",
      "60/60 - 1s - loss: 8.2966e-04 - mae: 0.0204 - val_loss: 0.0194 - val_mae: 0.0991\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.05989\n",
      "Epoch 128/1000\n",
      "60/60 - 1s - loss: 8.2979e-04 - mae: 0.0204 - val_loss: 0.0183 - val_mae: 0.0964\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.05989\n",
      "Epoch 129/1000\n",
      "60/60 - 1s - loss: 8.4009e-04 - mae: 0.0205 - val_loss: 0.0187 - val_mae: 0.0977\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.05989\n",
      "Epoch 130/1000\n",
      "60/60 - 1s - loss: 8.0752e-04 - mae: 0.0201 - val_loss: 0.0192 - val_mae: 0.0988\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.05989\n",
      "Epoch 131/1000\n",
      "60/60 - 1s - loss: 8.1569e-04 - mae: 0.0202 - val_loss: 0.0191 - val_mae: 0.0986\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.05989\n",
      "Epoch 132/1000\n",
      "60/60 - 1s - loss: 8.1893e-04 - mae: 0.0203 - val_loss: 0.0187 - val_mae: 0.0976\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.05989\n",
      "Epoch 133/1000\n",
      "60/60 - 1s - loss: 7.8971e-04 - mae: 0.0198 - val_loss: 0.0192 - val_mae: 0.0985\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.05989\n",
      "Epoch 134/1000\n",
      "60/60 - 1s - loss: 8.0886e-04 - mae: 0.0202 - val_loss: 0.0195 - val_mae: 0.0991\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.05989\n",
      "Epoch 135/1000\n",
      "60/60 - 1s - loss: 7.8933e-04 - mae: 0.0199 - val_loss: 0.0194 - val_mae: 0.0996\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.05989\n",
      "Epoch 136/1000\n",
      "60/60 - 1s - loss: 7.8097e-04 - mae: 0.0197 - val_loss: 0.0194 - val_mae: 0.0992\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.05989\n",
      "Epoch 137/1000\n",
      "60/60 - 1s - loss: 7.9533e-04 - mae: 0.0200 - val_loss: 0.0191 - val_mae: 0.0991\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.05989\n",
      "Epoch 138/1000\n",
      "60/60 - 1s - loss: 7.8732e-04 - mae: 0.0199 - val_loss: 0.0203 - val_mae: 0.1020\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.05989\n",
      "Epoch 139/1000\n",
      "60/60 - 1s - loss: 8.0549e-04 - mae: 0.0202 - val_loss: 0.0195 - val_mae: 0.1000\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.05989\n",
      "Epoch 140/1000\n",
      "60/60 - 1s - loss: 7.7375e-04 - mae: 0.0197 - val_loss: 0.0199 - val_mae: 0.1007\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.05989\n",
      "Epoch 141/1000\n",
      "60/60 - 1s - loss: 7.5701e-04 - mae: 0.0195 - val_loss: 0.0196 - val_mae: 0.0997\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.05989\n",
      "Epoch 142/1000\n",
      "60/60 - 1s - loss: 7.7661e-04 - mae: 0.0197 - val_loss: 0.0196 - val_mae: 0.1002\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.05989\n",
      "Epoch 143/1000\n",
      "60/60 - 1s - loss: 7.3227e-04 - mae: 0.0191 - val_loss: 0.0200 - val_mae: 0.1010\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.05989\n",
      "Epoch 144/1000\n",
      "60/60 - 1s - loss: 7.4184e-04 - mae: 0.0192 - val_loss: 0.0202 - val_mae: 0.1016\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.05989\n",
      "Epoch 145/1000\n",
      "60/60 - 1s - loss: 7.4821e-04 - mae: 0.0194 - val_loss: 0.0201 - val_mae: 0.1017\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.05989\n",
      "Epoch 146/1000\n",
      "60/60 - 1s - loss: 7.3174e-04 - mae: 0.0191 - val_loss: 0.0204 - val_mae: 0.1025\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.05989\n",
      "Epoch 147/1000\n",
      "60/60 - 1s - loss: 7.3421e-04 - mae: 0.0191 - val_loss: 0.0198 - val_mae: 0.1010\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.05989\n",
      "Epoch 148/1000\n",
      "60/60 - 1s - loss: 7.1805e-04 - mae: 0.0189 - val_loss: 0.0203 - val_mae: 0.1024\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.05989\n",
      "Epoch 149/1000\n",
      "60/60 - 1s - loss: 7.2791e-04 - mae: 0.0190 - val_loss: 0.0202 - val_mae: 0.1016\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.05989\n",
      "Epoch 150/1000\n",
      "60/60 - 1s - loss: 7.2267e-04 - mae: 0.0190 - val_loss: 0.0206 - val_mae: 0.1024\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.05989\n",
      "Epoch 151/1000\n",
      "60/60 - 1s - loss: 7.2265e-04 - mae: 0.0190 - val_loss: 0.0202 - val_mae: 0.1021\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.05989\n",
      "Epoch 152/1000\n",
      "60/60 - 1s - loss: 6.9982e-04 - mae: 0.0186 - val_loss: 0.0207 - val_mae: 0.1030\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.05989\n",
      "Epoch 153/1000\n",
      "60/60 - 1s - loss: 7.4196e-04 - mae: 0.0193 - val_loss: 0.0202 - val_mae: 0.1020\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.05989\n",
      "Epoch 154/1000\n",
      "60/60 - 1s - loss: 7.1750e-04 - mae: 0.0189 - val_loss: 0.0199 - val_mae: 0.1014\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.05989\n",
      "Epoch 155/1000\n",
      "60/60 - 1s - loss: 7.1055e-04 - mae: 0.0189 - val_loss: 0.0208 - val_mae: 0.1036\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.05989\n",
      "Epoch 156/1000\n",
      "60/60 - 1s - loss: 6.8938e-04 - mae: 0.0185 - val_loss: 0.0204 - val_mae: 0.1027\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.05989\n",
      "Epoch 157/1000\n",
      "60/60 - 1s - loss: 7.3875e-04 - mae: 0.0193 - val_loss: 0.0199 - val_mae: 0.1014\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.05989\n",
      "Epoch 158/1000\n",
      "60/60 - 1s - loss: 7.1684e-04 - mae: 0.0190 - val_loss: 0.0203 - val_mae: 0.1023\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.05989\n",
      "Epoch 159/1000\n",
      "60/60 - 1s - loss: 6.9291e-04 - mae: 0.0186 - val_loss: 0.0205 - val_mae: 0.1028\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.05989\n",
      "Epoch 160/1000\n",
      "60/60 - 1s - loss: 6.9679e-04 - mae: 0.0186 - val_loss: 0.0207 - val_mae: 0.1040\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.05989\n",
      "Epoch 161/1000\n",
      "60/60 - 1s - loss: 6.9093e-04 - mae: 0.0186 - val_loss: 0.0210 - val_mae: 0.1043\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.05989\n",
      "Epoch 162/1000\n",
      "60/60 - 1s - loss: 6.9912e-04 - mae: 0.0187 - val_loss: 0.0210 - val_mae: 0.1041\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.05989\n",
      "Epoch 163/1000\n",
      "60/60 - 1s - loss: 7.0105e-04 - mae: 0.0187 - val_loss: 0.0208 - val_mae: 0.1036\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.05989\n",
      "Epoch 164/1000\n",
      "60/60 - 1s - loss: 6.5664e-04 - mae: 0.0180 - val_loss: 0.0209 - val_mae: 0.1038\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.05989\n",
      "Epoch 165/1000\n",
      "60/60 - 1s - loss: 6.6796e-04 - mae: 0.0182 - val_loss: 0.0212 - val_mae: 0.1041\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.05989\n",
      "Epoch 166/1000\n",
      "60/60 - 1s - loss: 7.0806e-04 - mae: 0.0189 - val_loss: 0.0209 - val_mae: 0.1039\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.05989\n",
      "Epoch 167/1000\n",
      "60/60 - 1s - loss: 6.6558e-04 - mae: 0.0182 - val_loss: 0.0206 - val_mae: 0.1030\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.05989\n",
      "Epoch 168/1000\n",
      "60/60 - 1s - loss: 6.5708e-04 - mae: 0.0181 - val_loss: 0.0213 - val_mae: 0.1047\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.05989\n",
      "Epoch 169/1000\n",
      "60/60 - 1s - loss: 6.5484e-04 - mae: 0.0180 - val_loss: 0.0213 - val_mae: 0.1050\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.05989\n",
      "Epoch 170/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 - 1s - loss: 6.7502e-04 - mae: 0.0184 - val_loss: 0.0208 - val_mae: 0.1037\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.05989\n",
      "Epoch 171/1000\n",
      "60/60 - 1s - loss: 6.6815e-04 - mae: 0.0182 - val_loss: 0.0207 - val_mae: 0.1034\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.05989\n",
      "Epoch 172/1000\n",
      "60/60 - 1s - loss: 6.3335e-04 - mae: 0.0177 - val_loss: 0.0208 - val_mae: 0.1034\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.05989\n",
      "Epoch 173/1000\n",
      "60/60 - 1s - loss: 6.4359e-04 - mae: 0.0178 - val_loss: 0.0214 - val_mae: 0.1049\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.05989\n",
      "Epoch 174/1000\n",
      "60/60 - 1s - loss: 6.3925e-04 - mae: 0.0178 - val_loss: 0.0210 - val_mae: 0.1042\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.05989\n",
      "Epoch 175/1000\n",
      "60/60 - 1s - loss: 6.5061e-04 - mae: 0.0180 - val_loss: 0.0217 - val_mae: 0.1059\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.05989\n",
      "Epoch 176/1000\n",
      "60/60 - 1s - loss: 6.3465e-04 - mae: 0.0177 - val_loss: 0.0212 - val_mae: 0.1047\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.05989\n",
      "Epoch 177/1000\n",
      "60/60 - 1s - loss: 6.2768e-04 - mae: 0.0176 - val_loss: 0.0217 - val_mae: 0.1058\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.05989\n",
      "Epoch 178/1000\n",
      "60/60 - 1s - loss: 6.1974e-04 - mae: 0.0175 - val_loss: 0.0212 - val_mae: 0.1050\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.05989\n",
      "Epoch 179/1000\n",
      "60/60 - 1s - loss: 6.3765e-04 - mae: 0.0178 - val_loss: 0.0213 - val_mae: 0.1051\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.05989\n",
      "Epoch 180/1000\n",
      "60/60 - 1s - loss: 6.4070e-04 - mae: 0.0179 - val_loss: 0.0218 - val_mae: 0.1063\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.05989\n",
      "Epoch 181/1000\n",
      "60/60 - 1s - loss: 6.3534e-04 - mae: 0.0178 - val_loss: 0.0216 - val_mae: 0.1058\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.05989\n",
      "Epoch 182/1000\n",
      "60/60 - 1s - loss: 6.4618e-04 - mae: 0.0180 - val_loss: 0.0214 - val_mae: 0.1052\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.05989\n",
      "Epoch 183/1000\n",
      "60/60 - 1s - loss: 6.1395e-04 - mae: 0.0174 - val_loss: 0.0217 - val_mae: 0.1059\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.05989\n",
      "Epoch 184/1000\n",
      "60/60 - 1s - loss: 6.1219e-04 - mae: 0.0174 - val_loss: 0.0215 - val_mae: 0.1058\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.05989\n",
      "Epoch 185/1000\n",
      "60/60 - 1s - loss: 6.2816e-04 - mae: 0.0177 - val_loss: 0.0218 - val_mae: 0.1062\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.05989\n",
      "Epoch 186/1000\n",
      "60/60 - 1s - loss: 6.1484e-04 - mae: 0.0175 - val_loss: 0.0223 - val_mae: 0.1077\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.05989\n",
      "Epoch 187/1000\n",
      "60/60 - 1s - loss: 6.0364e-04 - mae: 0.0173 - val_loss: 0.0218 - val_mae: 0.1067\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.05989\n",
      "Epoch 188/1000\n",
      "60/60 - 1s - loss: 6.0848e-04 - mae: 0.0174 - val_loss: 0.0220 - val_mae: 0.1065\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.05989\n",
      "Epoch 189/1000\n",
      "60/60 - 1s - loss: 5.9036e-04 - mae: 0.0170 - val_loss: 0.0222 - val_mae: 0.1074\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.05989\n",
      "Epoch 190/1000\n",
      "60/60 - 1s - loss: 5.9468e-04 - mae: 0.0171 - val_loss: 0.0220 - val_mae: 0.1066\n",
      "\n",
      "Epoch 00190: val_mae did not improve from 0.05989\n",
      "Epoch 191/1000\n",
      "60/60 - 1s - loss: 6.0476e-04 - mae: 0.0173 - val_loss: 0.0223 - val_mae: 0.1075\n",
      "\n",
      "Epoch 00191: val_mae did not improve from 0.05989\n",
      "Epoch 192/1000\n",
      "60/60 - 1s - loss: 6.1587e-04 - mae: 0.0175 - val_loss: 0.0221 - val_mae: 0.1075\n",
      "\n",
      "Epoch 00192: val_mae did not improve from 0.05989\n",
      "Epoch 193/1000\n",
      "60/60 - 1s - loss: 6.0654e-04 - mae: 0.0174 - val_loss: 0.0222 - val_mae: 0.1072\n",
      "\n",
      "Epoch 00193: val_mae did not improve from 0.05989\n",
      "Epoch 194/1000\n",
      "60/60 - 1s - loss: 6.1421e-04 - mae: 0.0175 - val_loss: 0.0219 - val_mae: 0.1070\n",
      "\n",
      "Epoch 00194: val_mae did not improve from 0.05989\n",
      "Epoch 195/1000\n",
      "60/60 - 1s - loss: 5.8954e-04 - mae: 0.0171 - val_loss: 0.0219 - val_mae: 0.1068\n",
      "\n",
      "Epoch 00195: val_mae did not improve from 0.05989\n",
      "Epoch 196/1000\n",
      "60/60 - 1s - loss: 5.8708e-04 - mae: 0.0170 - val_loss: 0.0224 - val_mae: 0.1081\n",
      "\n",
      "Epoch 00196: val_mae did not improve from 0.05989\n",
      "Epoch 197/1000\n",
      "60/60 - 1s - loss: 5.7395e-04 - mae: 0.0168 - val_loss: 0.0220 - val_mae: 0.1065\n",
      "\n",
      "Epoch 00197: val_mae did not improve from 0.05989\n",
      "Epoch 198/1000\n",
      "60/60 - 1s - loss: 5.8334e-04 - mae: 0.0170 - val_loss: 0.0227 - val_mae: 0.1084\n",
      "\n",
      "Epoch 00198: val_mae did not improve from 0.05989\n",
      "Epoch 199/1000\n",
      "60/60 - 1s - loss: 5.7249e-04 - mae: 0.0168 - val_loss: 0.0225 - val_mae: 0.1083\n",
      "\n",
      "Epoch 00199: val_mae did not improve from 0.05989\n",
      "Epoch 200/1000\n",
      "60/60 - 1s - loss: 5.7967e-04 - mae: 0.0169 - val_loss: 0.0225 - val_mae: 0.1075\n",
      "\n",
      "Epoch 00200: val_mae did not improve from 0.05989\n",
      "Epoch 201/1000\n",
      "60/60 - 1s - loss: 5.8038e-04 - mae: 0.0170 - val_loss: 0.0225 - val_mae: 0.1081\n",
      "\n",
      "Epoch 00201: val_mae did not improve from 0.05989\n",
      "Epoch 202/1000\n",
      "60/60 - 1s - loss: 5.9559e-04 - mae: 0.0173 - val_loss: 0.0222 - val_mae: 0.1077\n",
      "\n",
      "Epoch 00202: val_mae did not improve from 0.05989\n",
      "Epoch 203/1000\n",
      "60/60 - 1s - loss: 5.7806e-04 - mae: 0.0169 - val_loss: 0.0229 - val_mae: 0.1094\n",
      "\n",
      "Epoch 00203: val_mae did not improve from 0.05989\n",
      "Epoch 204/1000\n",
      "60/60 - 1s - loss: 5.8330e-04 - mae: 0.0170 - val_loss: 0.0221 - val_mae: 0.1074\n",
      "\n",
      "Epoch 00204: val_mae did not improve from 0.05989\n",
      "Epoch 205/1000\n",
      "60/60 - 1s - loss: 5.7326e-04 - mae: 0.0169 - val_loss: 0.0223 - val_mae: 0.1078\n",
      "\n",
      "Epoch 00205: val_mae did not improve from 0.05989\n",
      "Epoch 206/1000\n",
      "60/60 - 1s - loss: 5.5212e-04 - mae: 0.0164 - val_loss: 0.0225 - val_mae: 0.1084\n",
      "\n",
      "Epoch 00206: val_mae did not improve from 0.05989\n",
      "Epoch 207/1000\n",
      "60/60 - 1s - loss: 5.5853e-04 - mae: 0.0166 - val_loss: 0.0224 - val_mae: 0.1081\n",
      "\n",
      "Epoch 00207: val_mae did not improve from 0.05989\n",
      "Epoch 208/1000\n",
      "60/60 - 1s - loss: 5.8070e-04 - mae: 0.0170 - val_loss: 0.0224 - val_mae: 0.1080\n",
      "\n",
      "Epoch 00208: val_mae did not improve from 0.05989\n",
      "Epoch 209/1000\n",
      "60/60 - 1s - loss: 5.7398e-04 - mae: 0.0169 - val_loss: 0.0222 - val_mae: 0.1076\n",
      "\n",
      "Epoch 00209: val_mae did not improve from 0.05989\n",
      "Epoch 210/1000\n",
      "60/60 - 1s - loss: 5.8376e-04 - mae: 0.0171 - val_loss: 0.0229 - val_mae: 0.1093\n",
      "\n",
      "Epoch 00210: val_mae did not improve from 0.05989\n",
      "Epoch 211/1000\n",
      "60/60 - 1s - loss: 5.5524e-04 - mae: 0.0165 - val_loss: 0.0226 - val_mae: 0.1084\n",
      "\n",
      "Epoch 00211: val_mae did not improve from 0.05989\n",
      "Epoch 212/1000\n",
      "60/60 - 1s - loss: 5.5725e-04 - mae: 0.0166 - val_loss: 0.0227 - val_mae: 0.1091\n",
      "\n",
      "Epoch 00212: val_mae did not improve from 0.05989\n",
      "Epoch 213/1000\n",
      "60/60 - 1s - loss: 5.6547e-04 - mae: 0.0168 - val_loss: 0.0225 - val_mae: 0.1085\n",
      "\n",
      "Epoch 00213: val_mae did not improve from 0.05989\n",
      "Epoch 214/1000\n",
      "60/60 - 1s - loss: 5.4890e-04 - mae: 0.0165 - val_loss: 0.0230 - val_mae: 0.1098\n",
      "\n",
      "Epoch 00214: val_mae did not improve from 0.05989\n",
      "Epoch 00214: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd83869e580>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate, \n",
    "#                                                           decay_steps=decay_steps,\n",
    "#                                                           decay_rate=decay_rate)\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "#               loss='mse',\n",
    "#               metrics=['mae']\n",
    "#              )\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae']\n",
    "             )\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_mae', mode='min', verbose=2, patience=PATIENCE)\n",
    "mc = ModelCheckpoint('../../saved_models/pm_all.h5', \n",
    "                     monitor='val_mae', \n",
    "                     mode='min', \n",
    "                     verbose=2, \n",
    "                     save_best_only=True\n",
    "                    )\n",
    "\n",
    "\n",
    "model.fit(train_X, train_y,\n",
    "          validation_data=(val_X, val_y),\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH,\n",
    "          verbose=2,\n",
    "          shuffle=True,\n",
    "          callbacks=[es, mc]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3c6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf5004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7c598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
