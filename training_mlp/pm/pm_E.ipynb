{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25441506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 14:53:50.813948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from helper import series_to_supervised\n",
    "from model.mlp import mlp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2af1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eefef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# random.seed(10)\n",
    "# print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537a30dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "      <th>NE</th>\n",
       "      <th>NW</th>\n",
       "      <th>SE</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press  wnd_spd  snow  rain  NE  \\\n",
       "date                                                                         \n",
       "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0     1.79     0     0   0   \n",
       "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0     2.68     0     0   0   \n",
       "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0     3.57     0     0   0   \n",
       "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0     5.36     1     0   0   \n",
       "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0     6.25     2     0   0   \n",
       "\n",
       "                     NW  SE  cv  \n",
       "date                             \n",
       "2010-01-02 00:00:00   0   1   0  \n",
       "2010-01-02 01:00:00   0   1   0  \n",
       "2010-01-02 02:00:00   0   1   0  \n",
       "2010-01-02 03:00:00   0   1   0  \n",
       "2010-01-02 04:00:00   0   1   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/pollution.csv\", index_col=0)\n",
    "data.fillna(0, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413bfd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "      <th>NE</th>\n",
       "      <th>NW</th>\n",
       "      <th>SE</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>231.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>237.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>242.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>246.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>249.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43800 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press  wnd_spd  snow  rain  NE  \\\n",
       "date                                                                         \n",
       "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0     1.79     0     0   0   \n",
       "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0     2.68     0     0   0   \n",
       "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0     3.57     0     0   0   \n",
       "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0     5.36     1     0   0   \n",
       "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0     6.25     2     0   0   \n",
       "...                        ...  ...   ...     ...      ...   ...   ...  ..   \n",
       "2014-12-31 19:00:00        8.0  -23  -2.0  1034.0   231.97     0     0   0   \n",
       "2014-12-31 20:00:00       10.0  -22  -3.0  1034.0   237.78     0     0   0   \n",
       "2014-12-31 21:00:00       10.0  -22  -3.0  1034.0   242.70     0     0   0   \n",
       "2014-12-31 22:00:00        8.0  -22  -4.0  1034.0   246.72     0     0   0   \n",
       "2014-12-31 23:00:00       12.0  -21  -3.0  1034.0   249.85     0     0   0   \n",
       "\n",
       "                     NW  SE  cv  \n",
       "date                             \n",
       "2010-01-02 00:00:00   0   1   0  \n",
       "2010-01-02 01:00:00   0   1   0  \n",
       "2010-01-02 02:00:00   0   1   0  \n",
       "2010-01-02 03:00:00   0   1   0  \n",
       "2010-01-02 04:00:00   0   1   0  \n",
       "...                  ..  ..  ..  \n",
       "2014-12-31 19:00:00   1   0   0  \n",
       "2014-12-31 20:00:00   1   0   0  \n",
       "2014-12-31 21:00:00   1   0   0  \n",
       "2014-12-31 22:00:00   1   0   0  \n",
       "2014-12-31 23:00:00   1   0   0  \n",
       "\n",
       "[43800 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f927e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pollution', 'dew', 'temp', 'press', 'wnd_spd', 'snow', 'rain', 'NE',\n",
       "       'NW', 'SE', 'cv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e52b1443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.7727e+04, 1.0511e+04, 6.4690e+03, 3.7450e+03, 2.2240e+03,\n",
       "        1.3270e+03, 7.5900e+02, 4.6700e+02, 2.8700e+02, 1.5400e+02,\n",
       "        7.2000e+01, 2.5000e+01, 7.0000e+00, 8.0000e+00, 4.0000e+00,\n",
       "        3.0000e+00, 4.0000e+00, 4.0000e+00, 0.0000e+00, 3.0000e+00]),\n",
       " array([  0. ,  49.7,  99.4, 149.1, 198.8, 248.5, 298.2, 347.9, 397.6,\n",
       "        447.3, 497. , 546.7, 596.4, 646.1, 695.8, 745.5, 795.2, 844.9,\n",
       "        894.6, 944.3, 994. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['pollution'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf49194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data['pollution'], 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee4ab3",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75f7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reframed.shape: (43717, 924)\n"
     ]
    }
   ],
   "source": [
    "values = data.values\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_hours = 24*3\n",
    "n_features = data.shape[-1]\n",
    "k = 12\n",
    "split1 = 0.7\n",
    "split2 = 0.85\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(values, n_hours, k)\n",
    "print(\"reframed.shape:\", reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f94f6e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (30601, 792) (30601, 12) (6558, 792) (6558, 12) (6558, 792) (6558, 12)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "reframed_values = reframed.values\n",
    "n_train_hours = int(len(reframed_values)*split1)\n",
    "n_valid_hours = int(len(reframed_values)*split2)\n",
    "\n",
    "train = reframed_values[:n_train_hours, :]\n",
    "val = reframed_values[n_train_hours:n_valid_hours, :]\n",
    "test = reframed_values[n_valid_hours:, :]\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "feature_idx = 0\n",
    "train_X, train_y = train[:, :n_obs], train[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "val_X, val_y = val[:, :n_obs], val[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "test_X, test_y = test[:, :n_obs], test[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de0c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (30601, 72, 11) (30601, 12) (6558, 72, 11) (6558, 12) (6558, 72, 11) (6558, 12)\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "train_y = scaler.fit_transform(train_y)\n",
    "\n",
    "val_X = scaler.fit_transform(val_X)\n",
    "val_y = scaler.fit_transform(val_y)\n",
    "\n",
    "test_X = scaler.fit_transform(test_X)\n",
    "test_y = scaler.fit_transform(test_y)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75693b2e",
   "metadata": {},
   "source": [
    "### PM threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef975113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30601,)\n",
      "(6558,)\n",
      "(6558,)\n"
     ]
    }
   ],
   "source": [
    "train_X_pm = train_X[:, 0, feature_idx]\n",
    "print(train_X_pm.shape)\n",
    "\n",
    "val_X_pm = val_X[:, 0, feature_idx]\n",
    "print(val_X_pm.shape)\n",
    "\n",
    "test_X_pm = test_X[:, 0, feature_idx]\n",
    "print(test_X_pm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a49e1fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95th Percentile of Daily Rain: 0.33400402414486924\n"
     ]
    }
   ],
   "source": [
    "percentile = 95\n",
    "\n",
    "merged_array = np.concatenate((train_X_pm, val_X_pm, test_X_pm))\n",
    "\n",
    "percentile_pm = np.percentile(merged_array, percentile)\n",
    "\n",
    "print(\"{}th Percentile of Daily Rain:\".format(percentile), percentile_pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dff6bc",
   "metadata": {},
   "source": [
    "### train_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a091b9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(848, 72, 11)\n",
      "(848, 12)\n"
     ]
    }
   ],
   "source": [
    "train_X_extreme = train_X[train_X_pm > percentile_pm]\n",
    "print(train_X_extreme.shape)\n",
    "\n",
    "train_y_extreme = train_y[train_X_pm > percentile_pm]\n",
    "print(train_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce1b1b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29753, 72, 11)\n",
      "(29753, 12)\n"
     ]
    }
   ],
   "source": [
    "train_X_normal = train_X[train_X_pm <= percentile_pm]\n",
    "print(train_X_normal.shape)\n",
    "\n",
    "train_y_normal = train_y[train_X_pm <= percentile_pm]\n",
    "print(train_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fca8d1",
   "metadata": {},
   "source": [
    "### val_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca133604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(752, 72, 11)\n",
      "(752, 12)\n"
     ]
    }
   ],
   "source": [
    "val_X_extreme = val_X[val_X_pm > percentile_pm]\n",
    "print(val_X_extreme.shape)\n",
    "\n",
    "val_y_extreme = val_y[val_X_pm > percentile_pm]\n",
    "print(val_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82a6f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5806, 72, 11)\n",
      "(5806, 12)\n"
     ]
    }
   ],
   "source": [
    "val_X_normal = val_X[val_X_pm <= percentile_pm]\n",
    "print(val_X_normal.shape)\n",
    "\n",
    "val_y_normal = val_y[val_X_pm <= percentile_pm]\n",
    "print(val_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c0167",
   "metadata": {},
   "source": [
    "### test_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84c29d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581, 72, 11)\n",
      "(581, 12)\n"
     ]
    }
   ],
   "source": [
    "test_X_extreme = test_X[test_X_pm > percentile_pm]\n",
    "print(test_X_extreme.shape)\n",
    "\n",
    "test_y_extreme = test_y[test_X_pm > percentile_pm]\n",
    "print(test_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8faf927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5977, 72, 11)\n",
      "(5977, 12)\n"
     ]
    }
   ],
   "source": [
    "test_X_normal = test_X[test_X_pm <= percentile_pm]\n",
    "print(test_X_normal.shape)\n",
    "\n",
    "test_y_normal = test_y[test_X_pm <= percentile_pm]\n",
    "print(test_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c626353",
   "metadata": {},
   "source": [
    "### Model & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4d95d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== model parameters ======\n",
    "mlp_unit1 = 128\n",
    "mlp_unit2 = 128\n",
    "mlp_unit3 = 64\n",
    "mlp_unit4 = 64\n",
    "mlp_unit5 = 32\n",
    "mlp_unit6 = 32\n",
    "mlp_unit7 = 16\n",
    "mlp_unit8 = 16\n",
    "dropout = 0.0\n",
    "kernel_size = 2\n",
    "pool_size = 2\n",
    "learning_rate = 1e-4\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.95\n",
    "PATIENCE = 100\n",
    "EPOCHS = 1000\n",
    "BATCH = 512\n",
    "opt_num = k\n",
    "input_shape = train_X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71f96438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_layer(input_shape=input_shape,\n",
    "                   mlp_unit1=mlp_unit1,\n",
    "                   mlp_unit2=mlp_unit2,\n",
    "                   mlp_unit3=mlp_unit3,\n",
    "                   mlp_unit4=mlp_unit4,\n",
    "                   mlp_unit5=mlp_unit5,\n",
    "                   mlp_unit6=mlp_unit6,\n",
    "                   mlp_unit7=mlp_unit7,\n",
    "                   mlp_unit8=mlp_unit8,\n",
    "                   dropout=dropout,\n",
    "                   masked_value=-1,\n",
    "                   opt_num=opt_num\n",
    "                  )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f1e0318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 14:56:01.286872: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-02-02 14:56:01.287656: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1700105000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 14:56:02.733237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 3s - loss: 0.0328 - mae: 0.1261 - val_loss: 0.0643 - val_mae: 0.1678\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.16779, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 2/1000\n",
      "2/2 - 0s - loss: 0.0288 - mae: 0.1117 - val_loss: 0.0544 - val_mae: 0.1471\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.16779 to 0.14706, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 3/1000\n",
      "2/2 - 0s - loss: 0.0221 - mae: 0.0952 - val_loss: 0.0395 - val_mae: 0.1347\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.14706 to 0.13466, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 4/1000\n",
      "2/2 - 0s - loss: 0.0187 - mae: 0.1066 - val_loss: 0.0354 - val_mae: 0.1410\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 0.13466\n",
      "Epoch 5/1000\n",
      "2/2 - 0s - loss: 0.0186 - mae: 0.1134 - val_loss: 0.0356 - val_mae: 0.1315\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.13466 to 0.13147, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 6/1000\n",
      "2/2 - 0s - loss: 0.0163 - mae: 0.0973 - val_loss: 0.0383 - val_mae: 0.1298\n",
      "\n",
      "Epoch 00006: val_mae improved from 0.13147 to 0.12983, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 7/1000\n",
      "2/2 - 0s - loss: 0.0165 - mae: 0.0915 - val_loss: 0.0389 - val_mae: 0.1298\n",
      "\n",
      "Epoch 00007: val_mae improved from 0.12983 to 0.12979, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 8/1000\n",
      "2/2 - 0s - loss: 0.0166 - mae: 0.0917 - val_loss: 0.0371 - val_mae: 0.1300\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 0.12979\n",
      "Epoch 9/1000\n",
      "2/2 - 0s - loss: 0.0163 - mae: 0.0940 - val_loss: 0.0354 - val_mae: 0.1304\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 0.12979\n",
      "Epoch 10/1000\n",
      "2/2 - 0s - loss: 0.0159 - mae: 0.0951 - val_loss: 0.0344 - val_mae: 0.1289\n",
      "\n",
      "Epoch 00010: val_mae improved from 0.12979 to 0.12893, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 11/1000\n",
      "2/2 - 0s - loss: 0.0155 - mae: 0.0933 - val_loss: 0.0338 - val_mae: 0.1273\n",
      "\n",
      "Epoch 00011: val_mae improved from 0.12893 to 0.12727, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 12/1000\n",
      "2/2 - 0s - loss: 0.0151 - mae: 0.0913 - val_loss: 0.0326 - val_mae: 0.1261\n",
      "\n",
      "Epoch 00012: val_mae improved from 0.12727 to 0.12605, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 13/1000\n",
      "2/2 - 0s - loss: 0.0148 - mae: 0.0914 - val_loss: 0.0311 - val_mae: 0.1254\n",
      "\n",
      "Epoch 00013: val_mae improved from 0.12605 to 0.12536, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 14/1000\n",
      "2/2 - 0s - loss: 0.0145 - mae: 0.0914 - val_loss: 0.0303 - val_mae: 0.1241\n",
      "\n",
      "Epoch 00014: val_mae improved from 0.12536 to 0.12408, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 15/1000\n",
      "2/2 - 0s - loss: 0.0142 - mae: 0.0896 - val_loss: 0.0296 - val_mae: 0.1226\n",
      "\n",
      "Epoch 00015: val_mae improved from 0.12408 to 0.12260, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 16/1000\n",
      "2/2 - 0s - loss: 0.0139 - mae: 0.0877 - val_loss: 0.0285 - val_mae: 0.1212\n",
      "\n",
      "Epoch 00016: val_mae improved from 0.12260 to 0.12117, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 17/1000\n",
      "2/2 - 0s - loss: 0.0135 - mae: 0.0859 - val_loss: 0.0272 - val_mae: 0.1196\n",
      "\n",
      "Epoch 00017: val_mae improved from 0.12117 to 0.11957, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 18/1000\n",
      "2/2 - 0s - loss: 0.0131 - mae: 0.0848 - val_loss: 0.0259 - val_mae: 0.1179\n",
      "\n",
      "Epoch 00018: val_mae improved from 0.11957 to 0.11785, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 19/1000\n",
      "2/2 - 0s - loss: 0.0127 - mae: 0.0835 - val_loss: 0.0254 - val_mae: 0.1153\n",
      "\n",
      "Epoch 00019: val_mae improved from 0.11785 to 0.11527, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 20/1000\n",
      "2/2 - 0s - loss: 0.0123 - mae: 0.0794 - val_loss: 0.0247 - val_mae: 0.1130\n",
      "\n",
      "Epoch 00020: val_mae improved from 0.11527 to 0.11303, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 21/1000\n",
      "2/2 - 0s - loss: 0.0118 - mae: 0.0767 - val_loss: 0.0227 - val_mae: 0.1113\n",
      "\n",
      "Epoch 00021: val_mae improved from 0.11303 to 0.11133, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 22/1000\n",
      "2/2 - 0s - loss: 0.0115 - mae: 0.0783 - val_loss: 0.0222 - val_mae: 0.1082\n",
      "\n",
      "Epoch 00022: val_mae improved from 0.11133 to 0.10819, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 23/1000\n",
      "2/2 - 0s - loss: 0.0110 - mae: 0.0728 - val_loss: 0.0226 - val_mae: 0.1070\n",
      "\n",
      "Epoch 00023: val_mae improved from 0.10819 to 0.10696, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 24/1000\n",
      "2/2 - 0s - loss: 0.0106 - mae: 0.0700 - val_loss: 0.0199 - val_mae: 0.1035\n",
      "\n",
      "Epoch 00024: val_mae improved from 0.10696 to 0.10354, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 25/1000\n",
      "2/2 - 0s - loss: 0.0102 - mae: 0.0707 - val_loss: 0.0201 - val_mae: 0.1019\n",
      "\n",
      "Epoch 00025: val_mae improved from 0.10354 to 0.10187, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 26/1000\n",
      "2/2 - 0s - loss: 0.0097 - mae: 0.0662 - val_loss: 0.0200 - val_mae: 0.1016\n",
      "\n",
      "Epoch 00026: val_mae improved from 0.10187 to 0.10156, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 27/1000\n",
      "2/2 - 0s - loss: 0.0095 - mae: 0.0652 - val_loss: 0.0183 - val_mae: 0.0986\n",
      "\n",
      "Epoch 00027: val_mae improved from 0.10156 to 0.09859, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 28/1000\n",
      "2/2 - 0s - loss: 0.0093 - mae: 0.0665 - val_loss: 0.0187 - val_mae: 0.0992\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.09859\n",
      "Epoch 29/1000\n",
      "2/2 - 0s - loss: 0.0091 - mae: 0.0639 - val_loss: 0.0182 - val_mae: 0.0977\n",
      "\n",
      "Epoch 00029: val_mae improved from 0.09859 to 0.09770, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 30/1000\n",
      "2/2 - 0s - loss: 0.0087 - mae: 0.0631 - val_loss: 0.0169 - val_mae: 0.0945\n",
      "\n",
      "Epoch 00030: val_mae improved from 0.09770 to 0.09450, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 31/1000\n",
      "2/2 - 0s - loss: 0.0087 - mae: 0.0633 - val_loss: 0.0178 - val_mae: 0.0970\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.09450\n",
      "Epoch 32/1000\n",
      "2/2 - 0s - loss: 0.0084 - mae: 0.0610 - val_loss: 0.0163 - val_mae: 0.0922\n",
      "\n",
      "Epoch 00032: val_mae improved from 0.09450 to 0.09219, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 33/1000\n",
      "2/2 - 0s - loss: 0.0082 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0928\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.09219\n",
      "Epoch 34/1000\n",
      "2/2 - 0s - loss: 0.0079 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0923\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.09219\n",
      "Epoch 35/1000\n",
      "2/2 - 0s - loss: 0.0076 - mae: 0.0579 - val_loss: 0.0158 - val_mae: 0.0896\n",
      "\n",
      "Epoch 00035: val_mae improved from 0.09219 to 0.08959, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 36/1000\n",
      "2/2 - 0s - loss: 0.0075 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0925\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.08959\n",
      "Epoch 37/1000\n",
      "2/2 - 0s - loss: 0.0073 - mae: 0.0565 - val_loss: 0.0154 - val_mae: 0.0885\n",
      "\n",
      "Epoch 00037: val_mae improved from 0.08959 to 0.08853, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 38/1000\n",
      "2/2 - 0s - loss: 0.0071 - mae: 0.0557 - val_loss: 0.0165 - val_mae: 0.0915\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.08853\n",
      "Epoch 39/1000\n",
      "2/2 - 0s - loss: 0.0070 - mae: 0.0547 - val_loss: 0.0156 - val_mae: 0.0884\n",
      "\n",
      "Epoch 00039: val_mae improved from 0.08853 to 0.08841, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 40/1000\n",
      "2/2 - 0s - loss: 0.0067 - mae: 0.0536 - val_loss: 0.0152 - val_mae: 0.0869\n",
      "\n",
      "Epoch 00040: val_mae improved from 0.08841 to 0.08690, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 41/1000\n",
      "2/2 - 0s - loss: 0.0066 - mae: 0.0535 - val_loss: 0.0162 - val_mae: 0.0907\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.08690\n",
      "Epoch 42/1000\n",
      "2/2 - 0s - loss: 0.0065 - mae: 0.0526 - val_loss: 0.0145 - val_mae: 0.0849\n",
      "\n",
      "Epoch 00042: val_mae improved from 0.08690 to 0.08495, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 43/1000\n",
      "2/2 - 0s - loss: 0.0063 - mae: 0.0526 - val_loss: 0.0171 - val_mae: 0.0937\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.08495\n",
      "Epoch 44/1000\n",
      "2/2 - 0s - loss: 0.0065 - mae: 0.0529 - val_loss: 0.0139 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00044: val_mae improved from 0.08495 to 0.08332, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 45/1000\n",
      "2/2 - 0s - loss: 0.0064 - mae: 0.0539 - val_loss: 0.0166 - val_mae: 0.0921\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.08332\n",
      "Epoch 46/1000\n",
      "2/2 - 0s - loss: 0.0062 - mae: 0.0517 - val_loss: 0.0146 - val_mae: 0.0853\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.08332\n",
      "Epoch 47/1000\n",
      "2/2 - 0s - loss: 0.0061 - mae: 0.0517 - val_loss: 0.0158 - val_mae: 0.0897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: val_mae did not improve from 0.08332\n",
      "Epoch 48/1000\n",
      "2/2 - 0s - loss: 0.0058 - mae: 0.0498 - val_loss: 0.0157 - val_mae: 0.0894\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.08332\n",
      "Epoch 49/1000\n",
      "2/2 - 0s - loss: 0.0057 - mae: 0.0491 - val_loss: 0.0141 - val_mae: 0.0841\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.08332\n",
      "Epoch 50/1000\n",
      "2/2 - 0s - loss: 0.0056 - mae: 0.0492 - val_loss: 0.0170 - val_mae: 0.0933\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.08332\n",
      "Epoch 51/1000\n",
      "2/2 - 0s - loss: 0.0057 - mae: 0.0496 - val_loss: 0.0142 - val_mae: 0.0842\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.08332\n",
      "Epoch 52/1000\n",
      "2/2 - 0s - loss: 0.0056 - mae: 0.0490 - val_loss: 0.0160 - val_mae: 0.0907\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.08332\n",
      "Epoch 53/1000\n",
      "2/2 - 0s - loss: 0.0055 - mae: 0.0483 - val_loss: 0.0144 - val_mae: 0.0854\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.08332\n",
      "Epoch 54/1000\n",
      "2/2 - 0s - loss: 0.0055 - mae: 0.0490 - val_loss: 0.0153 - val_mae: 0.0884\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.08332\n",
      "Epoch 55/1000\n",
      "2/2 - 0s - loss: 0.0055 - mae: 0.0484 - val_loss: 0.0152 - val_mae: 0.0882\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.08332\n",
      "Epoch 56/1000\n",
      "2/2 - 0s - loss: 0.0052 - mae: 0.0477 - val_loss: 0.0141 - val_mae: 0.0842\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 0.08332\n",
      "Epoch 57/1000\n",
      "2/2 - 0s - loss: 0.0052 - mae: 0.0474 - val_loss: 0.0169 - val_mae: 0.0934\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.08332\n",
      "Epoch 58/1000\n",
      "2/2 - 0s - loss: 0.0053 - mae: 0.0470 - val_loss: 0.0137 - val_mae: 0.0831\n",
      "\n",
      "Epoch 00058: val_mae improved from 0.08332 to 0.08314, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 59/1000\n",
      "2/2 - 0s - loss: 0.0052 - mae: 0.0474 - val_loss: 0.0160 - val_mae: 0.0909\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.08314\n",
      "Epoch 60/1000\n",
      "2/2 - 0s - loss: 0.0051 - mae: 0.0467 - val_loss: 0.0141 - val_mae: 0.0846\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.08314\n",
      "Epoch 61/1000\n",
      "2/2 - 0s - loss: 0.0049 - mae: 0.0462 - val_loss: 0.0149 - val_mae: 0.0870\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.08314\n",
      "Epoch 62/1000\n",
      "2/2 - 0s - loss: 0.0048 - mae: 0.0447 - val_loss: 0.0153 - val_mae: 0.0884\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.08314\n",
      "Epoch 63/1000\n",
      "2/2 - 0s - loss: 0.0048 - mae: 0.0451 - val_loss: 0.0141 - val_mae: 0.0846\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.08314\n",
      "Epoch 64/1000\n",
      "2/2 - 0s - loss: 0.0047 - mae: 0.0449 - val_loss: 0.0156 - val_mae: 0.0894\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.08314\n",
      "Epoch 65/1000\n",
      "2/2 - 0s - loss: 0.0047 - mae: 0.0448 - val_loss: 0.0137 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.08314\n",
      "Epoch 66/1000\n",
      "2/2 - 0s - loss: 0.0046 - mae: 0.0445 - val_loss: 0.0154 - val_mae: 0.0889\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.08314\n",
      "Epoch 67/1000\n",
      "2/2 - 0s - loss: 0.0046 - mae: 0.0442 - val_loss: 0.0138 - val_mae: 0.0836\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.08314\n",
      "Epoch 68/1000\n",
      "2/2 - 0s - loss: 0.0045 - mae: 0.0440 - val_loss: 0.0148 - val_mae: 0.0870\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.08314\n",
      "Epoch 69/1000\n",
      "2/2 - 0s - loss: 0.0045 - mae: 0.0435 - val_loss: 0.0139 - val_mae: 0.0840\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.08314\n",
      "Epoch 70/1000\n",
      "2/2 - 0s - loss: 0.0044 - mae: 0.0436 - val_loss: 0.0146 - val_mae: 0.0864\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.08314\n",
      "Epoch 71/1000\n",
      "2/2 - 0s - loss: 0.0043 - mae: 0.0430 - val_loss: 0.0139 - val_mae: 0.0841\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.08314\n",
      "Epoch 72/1000\n",
      "2/2 - 0s - loss: 0.0043 - mae: 0.0428 - val_loss: 0.0146 - val_mae: 0.0867\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.08314\n",
      "Epoch 73/1000\n",
      "2/2 - 0s - loss: 0.0042 - mae: 0.0426 - val_loss: 0.0140 - val_mae: 0.0845\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.08314\n",
      "Epoch 74/1000\n",
      "2/2 - 0s - loss: 0.0042 - mae: 0.0423 - val_loss: 0.0149 - val_mae: 0.0872\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.08314\n",
      "Epoch 75/1000\n",
      "2/2 - 0s - loss: 0.0042 - mae: 0.0420 - val_loss: 0.0138 - val_mae: 0.0835\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.08314\n",
      "Epoch 76/1000\n",
      "2/2 - 0s - loss: 0.0041 - mae: 0.0421 - val_loss: 0.0146 - val_mae: 0.0867\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.08314\n",
      "Epoch 77/1000\n",
      "2/2 - 0s - loss: 0.0040 - mae: 0.0415 - val_loss: 0.0137 - val_mae: 0.0835\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.08314\n",
      "Epoch 78/1000\n",
      "2/2 - 0s - loss: 0.0040 - mae: 0.0415 - val_loss: 0.0151 - val_mae: 0.0881\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.08314\n",
      "Epoch 79/1000\n",
      "2/2 - 0s - loss: 0.0040 - mae: 0.0414 - val_loss: 0.0135 - val_mae: 0.0824\n",
      "\n",
      "Epoch 00079: val_mae improved from 0.08314 to 0.08238, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 80/1000\n",
      "2/2 - 0s - loss: 0.0039 - mae: 0.0411 - val_loss: 0.0151 - val_mae: 0.0883\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.08238\n",
      "Epoch 81/1000\n",
      "2/2 - 0s - loss: 0.0039 - mae: 0.0409 - val_loss: 0.0134 - val_mae: 0.0822\n",
      "\n",
      "Epoch 00081: val_mae improved from 0.08238 to 0.08219, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 82/1000\n",
      "2/2 - 0s - loss: 0.0039 - mae: 0.0412 - val_loss: 0.0149 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.08219\n",
      "Epoch 83/1000\n",
      "2/2 - 0s - loss: 0.0038 - mae: 0.0407 - val_loss: 0.0139 - val_mae: 0.0838\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.08219\n",
      "Epoch 84/1000\n",
      "2/2 - 0s - loss: 0.0038 - mae: 0.0402 - val_loss: 0.0142 - val_mae: 0.0850\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.08219\n",
      "Epoch 85/1000\n",
      "2/2 - 0s - loss: 0.0037 - mae: 0.0399 - val_loss: 0.0137 - val_mae: 0.0831\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.08219\n",
      "Epoch 86/1000\n",
      "2/2 - 0s - loss: 0.0037 - mae: 0.0397 - val_loss: 0.0150 - val_mae: 0.0874\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.08219\n",
      "Epoch 87/1000\n",
      "2/2 - 0s - loss: 0.0037 - mae: 0.0398 - val_loss: 0.0140 - val_mae: 0.0843\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.08219\n",
      "Epoch 88/1000\n",
      "2/2 - 0s - loss: 0.0037 - mae: 0.0397 - val_loss: 0.0141 - val_mae: 0.0847\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.08219\n",
      "Epoch 89/1000\n",
      "2/2 - 0s - loss: 0.0036 - mae: 0.0395 - val_loss: 0.0145 - val_mae: 0.0860\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.08219\n",
      "Epoch 90/1000\n",
      "2/2 - 0s - loss: 0.0036 - mae: 0.0391 - val_loss: 0.0138 - val_mae: 0.0835\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.08219\n",
      "Epoch 91/1000\n",
      "2/2 - 0s - loss: 0.0035 - mae: 0.0390 - val_loss: 0.0152 - val_mae: 0.0884\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.08219\n",
      "Epoch 92/1000\n",
      "2/2 - 0s - loss: 0.0037 - mae: 0.0400 - val_loss: 0.0146 - val_mae: 0.0865\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.08219\n",
      "Epoch 93/1000\n",
      "2/2 - 0s - loss: 0.0035 - mae: 0.0388 - val_loss: 0.0133 - val_mae: 0.0818\n",
      "\n",
      "Epoch 00093: val_mae improved from 0.08219 to 0.08185, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 94/1000\n",
      "2/2 - 0s - loss: 0.0035 - mae: 0.0391 - val_loss: 0.0149 - val_mae: 0.0874\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.08185\n",
      "Epoch 95/1000\n",
      "2/2 - 0s - loss: 0.0034 - mae: 0.0386 - val_loss: 0.0137 - val_mae: 0.0831\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.08185\n",
      "Epoch 96/1000\n",
      "2/2 - 0s - loss: 0.0034 - mae: 0.0386 - val_loss: 0.0142 - val_mae: 0.0850\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.08185\n",
      "Epoch 97/1000\n",
      "2/2 - 0s - loss: 0.0034 - mae: 0.0382 - val_loss: 0.0142 - val_mae: 0.0852\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.08185\n",
      "Epoch 98/1000\n",
      "2/2 - 0s - loss: 0.0033 - mae: 0.0381 - val_loss: 0.0141 - val_mae: 0.0846\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.08185\n",
      "Epoch 99/1000\n",
      "2/2 - 0s - loss: 0.0033 - mae: 0.0378 - val_loss: 0.0138 - val_mae: 0.0841\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.08185\n",
      "Epoch 100/1000\n",
      "2/2 - 0s - loss: 0.0033 - mae: 0.0379 - val_loss: 0.0139 - val_mae: 0.0842\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.08185\n",
      "Epoch 101/1000\n",
      "2/2 - 0s - loss: 0.0033 - mae: 0.0378 - val_loss: 0.0141 - val_mae: 0.0848\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.08185\n",
      "Epoch 102/1000\n",
      "2/2 - 0s - loss: 0.0032 - mae: 0.0374 - val_loss: 0.0152 - val_mae: 0.0890\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.08185\n",
      "Epoch 103/1000\n",
      "2/2 - 0s - loss: 0.0033 - mae: 0.0379 - val_loss: 0.0140 - val_mae: 0.0842\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.08185\n",
      "Epoch 104/1000\n",
      "2/2 - 0s - loss: 0.0032 - mae: 0.0375 - val_loss: 0.0143 - val_mae: 0.0855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00104: val_mae did not improve from 0.08185\n",
      "Epoch 105/1000\n",
      "2/2 - 0s - loss: 0.0032 - mae: 0.0373 - val_loss: 0.0146 - val_mae: 0.0868\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.08185\n",
      "Epoch 106/1000\n",
      "2/2 - 0s - loss: 0.0032 - mae: 0.0373 - val_loss: 0.0130 - val_mae: 0.0806\n",
      "\n",
      "Epoch 00106: val_mae improved from 0.08185 to 0.08058, saving model to ../../saved_models_mlp/pm_E.h5\n",
      "Epoch 107/1000\n",
      "2/2 - 0s - loss: 0.0034 - mae: 0.0395 - val_loss: 0.0159 - val_mae: 0.0914\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.08058\n",
      "Epoch 108/1000\n",
      "2/2 - 0s - loss: 0.0033 - mae: 0.0386 - val_loss: 0.0138 - val_mae: 0.0838\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.08058\n",
      "Epoch 109/1000\n",
      "2/2 - 0s - loss: 0.0031 - mae: 0.0372 - val_loss: 0.0148 - val_mae: 0.0872\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.08058\n",
      "Epoch 110/1000\n",
      "2/2 - 0s - loss: 0.0031 - mae: 0.0375 - val_loss: 0.0141 - val_mae: 0.0850\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.08058\n",
      "Epoch 111/1000\n",
      "2/2 - 0s - loss: 0.0030 - mae: 0.0368 - val_loss: 0.0141 - val_mae: 0.0844\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.08058\n",
      "Epoch 112/1000\n",
      "2/2 - 0s - loss: 0.0030 - mae: 0.0366 - val_loss: 0.0146 - val_mae: 0.0868\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.08058\n",
      "Epoch 113/1000\n",
      "2/2 - 0s - loss: 0.0029 - mae: 0.0367 - val_loss: 0.0134 - val_mae: 0.0824\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.08058\n",
      "Epoch 114/1000\n",
      "2/2 - 0s - loss: 0.0030 - mae: 0.0368 - val_loss: 0.0153 - val_mae: 0.0894\n",
      "\n",
      "Epoch 00114: val_mae did not improve from 0.08058\n",
      "Epoch 115/1000\n",
      "2/2 - 0s - loss: 0.0029 - mae: 0.0364 - val_loss: 0.0140 - val_mae: 0.0841\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.08058\n",
      "Epoch 116/1000\n",
      "2/2 - 0s - loss: 0.0029 - mae: 0.0362 - val_loss: 0.0142 - val_mae: 0.0852\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.08058\n",
      "Epoch 117/1000\n",
      "2/2 - 0s - loss: 0.0028 - mae: 0.0360 - val_loss: 0.0145 - val_mae: 0.0866\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.08058\n",
      "Epoch 118/1000\n",
      "2/2 - 0s - loss: 0.0028 - mae: 0.0356 - val_loss: 0.0137 - val_mae: 0.0835\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.08058\n",
      "Epoch 119/1000\n",
      "2/2 - 0s - loss: 0.0028 - mae: 0.0357 - val_loss: 0.0153 - val_mae: 0.0894\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.08058\n",
      "Epoch 120/1000\n",
      "2/2 - 0s - loss: 0.0028 - mae: 0.0358 - val_loss: 0.0139 - val_mae: 0.0844\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.08058\n",
      "Epoch 121/1000\n",
      "2/2 - 0s - loss: 0.0027 - mae: 0.0354 - val_loss: 0.0146 - val_mae: 0.0870\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.08058\n",
      "Epoch 122/1000\n",
      "2/2 - 0s - loss: 0.0026 - mae: 0.0350 - val_loss: 0.0139 - val_mae: 0.0843\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.08058\n",
      "Epoch 123/1000\n",
      "2/2 - 0s - loss: 0.0026 - mae: 0.0347 - val_loss: 0.0148 - val_mae: 0.0881\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.08058\n",
      "Epoch 124/1000\n",
      "2/2 - 0s - loss: 0.0026 - mae: 0.0351 - val_loss: 0.0139 - val_mae: 0.0845\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.08058\n",
      "Epoch 125/1000\n",
      "2/2 - 0s - loss: 0.0026 - mae: 0.0348 - val_loss: 0.0148 - val_mae: 0.0878\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.08058\n",
      "Epoch 126/1000\n",
      "2/2 - 0s - loss: 0.0026 - mae: 0.0346 - val_loss: 0.0141 - val_mae: 0.0851\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.08058\n",
      "Epoch 127/1000\n",
      "2/2 - 0s - loss: 0.0025 - mae: 0.0342 - val_loss: 0.0147 - val_mae: 0.0874\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.08058\n",
      "Epoch 128/1000\n",
      "2/2 - 0s - loss: 0.0025 - mae: 0.0343 - val_loss: 0.0142 - val_mae: 0.0859\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.08058\n",
      "Epoch 129/1000\n",
      "2/2 - 0s - loss: 0.0025 - mae: 0.0345 - val_loss: 0.0137 - val_mae: 0.0841\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.08058\n",
      "Epoch 130/1000\n",
      "2/2 - 0s - loss: 0.0025 - mae: 0.0348 - val_loss: 0.0148 - val_mae: 0.0882\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.08058\n",
      "Epoch 131/1000\n",
      "2/2 - 0s - loss: 0.0024 - mae: 0.0340 - val_loss: 0.0141 - val_mae: 0.0853\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.08058\n",
      "Epoch 132/1000\n",
      "2/2 - 0s - loss: 0.0024 - mae: 0.0341 - val_loss: 0.0136 - val_mae: 0.0836\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.08058\n",
      "Epoch 133/1000\n",
      "2/2 - 0s - loss: 0.0024 - mae: 0.0340 - val_loss: 0.0146 - val_mae: 0.0875\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.08058\n",
      "Epoch 134/1000\n",
      "2/2 - 0s - loss: 0.0024 - mae: 0.0338 - val_loss: 0.0146 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.08058\n",
      "Epoch 135/1000\n",
      "2/2 - 0s - loss: 0.0024 - mae: 0.0336 - val_loss: 0.0140 - val_mae: 0.0854\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.08058\n",
      "Epoch 136/1000\n",
      "2/2 - 0s - loss: 0.0023 - mae: 0.0333 - val_loss: 0.0142 - val_mae: 0.0864\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.08058\n",
      "Epoch 137/1000\n",
      "2/2 - 0s - loss: 0.0023 - mae: 0.0331 - val_loss: 0.0144 - val_mae: 0.0866\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.08058\n",
      "Epoch 138/1000\n",
      "2/2 - 0s - loss: 0.0023 - mae: 0.0330 - val_loss: 0.0143 - val_mae: 0.0864\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.08058\n",
      "Epoch 139/1000\n",
      "2/2 - 0s - loss: 0.0023 - mae: 0.0330 - val_loss: 0.0145 - val_mae: 0.0871\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.08058\n",
      "Epoch 140/1000\n",
      "2/2 - 0s - loss: 0.0023 - mae: 0.0331 - val_loss: 0.0146 - val_mae: 0.0877\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.08058\n",
      "Epoch 141/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0140 - val_mae: 0.0855\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.08058\n",
      "Epoch 142/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0148 - val_mae: 0.0883\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.08058\n",
      "Epoch 143/1000\n",
      "2/2 - 0s - loss: 0.0023 - mae: 0.0331 - val_loss: 0.0148 - val_mae: 0.0882\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.08058\n",
      "Epoch 144/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0326 - val_loss: 0.0137 - val_mae: 0.0840\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.08058\n",
      "Epoch 145/1000\n",
      "2/2 - 0s - loss: 0.0023 - mae: 0.0335 - val_loss: 0.0151 - val_mae: 0.0895\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.08058\n",
      "Epoch 146/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0332 - val_loss: 0.0147 - val_mae: 0.0882\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.08058\n",
      "Epoch 147/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0142 - val_mae: 0.0857\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.08058\n",
      "Epoch 148/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0146 - val_mae: 0.0879\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.08058\n",
      "Epoch 149/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0322 - val_loss: 0.0144 - val_mae: 0.0870\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.08058\n",
      "Epoch 150/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0144 - val_mae: 0.0868\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.08058\n",
      "Epoch 151/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0148 - val_mae: 0.0888\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.08058\n",
      "Epoch 152/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0150 - val_mae: 0.0891\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.08058\n",
      "Epoch 153/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0144 - val_mae: 0.0871\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.08058\n",
      "Epoch 154/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0316 - val_loss: 0.0146 - val_mae: 0.0877\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.08058\n",
      "Epoch 155/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0317 - val_loss: 0.0153 - val_mae: 0.0904\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.08058\n",
      "Epoch 156/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0317 - val_loss: 0.0141 - val_mae: 0.0860\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.08058\n",
      "Epoch 157/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0317 - val_loss: 0.0146 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.08058\n",
      "Epoch 158/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0314 - val_loss: 0.0150 - val_mae: 0.0893\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.08058\n",
      "Epoch 159/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0314 - val_loss: 0.0147 - val_mae: 0.0885\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.08058\n",
      "Epoch 160/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0146 - val_mae: 0.0878\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.08058\n",
      "Epoch 161/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0309 - val_loss: 0.0146 - val_mae: 0.0881\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.08058\n",
      "Epoch 162/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0308 - val_loss: 0.0146 - val_mae: 0.0875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00162: val_mae did not improve from 0.08058\n",
      "Epoch 163/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0306 - val_loss: 0.0142 - val_mae: 0.0865\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.08058\n",
      "Epoch 164/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0139 - val_mae: 0.0853\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.08058\n",
      "Epoch 165/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0315 - val_loss: 0.0149 - val_mae: 0.0890\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.08058\n",
      "Epoch 166/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0306 - val_loss: 0.0151 - val_mae: 0.0900\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.08058\n",
      "Epoch 167/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0145 - val_mae: 0.0876\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.08058\n",
      "Epoch 168/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0304 - val_loss: 0.0145 - val_mae: 0.0874\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.08058\n",
      "Epoch 169/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0145 - val_mae: 0.0877\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.08058\n",
      "Epoch 170/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0303 - val_loss: 0.0149 - val_mae: 0.0891\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.08058\n",
      "Epoch 171/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0299 - val_loss: 0.0144 - val_mae: 0.0872\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.08058\n",
      "Epoch 172/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0310 - val_loss: 0.0141 - val_mae: 0.0858\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.08058\n",
      "Epoch 173/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0313 - val_loss: 0.0144 - val_mae: 0.0869\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.08058\n",
      "Epoch 174/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0303 - val_loss: 0.0149 - val_mae: 0.0894\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.08058\n",
      "Epoch 175/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0299 - val_loss: 0.0148 - val_mae: 0.0893\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.08058\n",
      "Epoch 176/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0299 - val_loss: 0.0145 - val_mae: 0.0874\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.08058\n",
      "Epoch 177/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0146 - val_mae: 0.0882\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.08058\n",
      "Epoch 178/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0147 - val_mae: 0.0883\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.08058\n",
      "Epoch 179/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0145 - val_mae: 0.0876\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.08058\n",
      "Epoch 180/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0148 - val_mae: 0.0885\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.08058\n",
      "Epoch 181/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0151 - val_mae: 0.0902\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.08058\n",
      "Epoch 182/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0152 - val_mae: 0.0904\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.08058\n",
      "Epoch 183/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0300 - val_loss: 0.0148 - val_mae: 0.0888\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.08058\n",
      "Epoch 184/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0290 - val_loss: 0.0148 - val_mae: 0.0887\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.08058\n",
      "Epoch 185/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0146 - val_mae: 0.0880\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.08058\n",
      "Epoch 186/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0147 - val_mae: 0.0885\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.08058\n",
      "Epoch 187/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0144 - val_mae: 0.0869\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.08058\n",
      "Epoch 188/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0143 - val_mae: 0.0868\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.08058\n",
      "Epoch 189/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0146 - val_mae: 0.0879\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.08058\n",
      "Epoch 190/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0291 - val_loss: 0.0149 - val_mae: 0.0895\n",
      "\n",
      "Epoch 00190: val_mae did not improve from 0.08058\n",
      "Epoch 191/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0152 - val_mae: 0.0906\n",
      "\n",
      "Epoch 00191: val_mae did not improve from 0.08058\n",
      "Epoch 192/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0147 - val_mae: 0.0887\n",
      "\n",
      "Epoch 00192: val_mae did not improve from 0.08058\n",
      "Epoch 193/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0151 - val_mae: 0.0900\n",
      "\n",
      "Epoch 00193: val_mae did not improve from 0.08058\n",
      "Epoch 194/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0291 - val_loss: 0.0164 - val_mae: 0.0949\n",
      "\n",
      "Epoch 00194: val_mae did not improve from 0.08058\n",
      "Epoch 195/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0148 - val_mae: 0.0890\n",
      "\n",
      "Epoch 00195: val_mae did not improve from 0.08058\n",
      "Epoch 196/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0142 - val_mae: 0.0865\n",
      "\n",
      "Epoch 00196: val_mae did not improve from 0.08058\n",
      "Epoch 197/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0301 - val_loss: 0.0155 - val_mae: 0.0911\n",
      "\n",
      "Epoch 00197: val_mae did not improve from 0.08058\n",
      "Epoch 198/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0149 - val_mae: 0.0894\n",
      "\n",
      "Epoch 00198: val_mae did not improve from 0.08058\n",
      "Epoch 199/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0145 - val_mae: 0.0880\n",
      "\n",
      "Epoch 00199: val_mae did not improve from 0.08058\n",
      "Epoch 200/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0285 - val_loss: 0.0153 - val_mae: 0.0909\n",
      "\n",
      "Epoch 00200: val_mae did not improve from 0.08058\n",
      "Epoch 201/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0279 - val_loss: 0.0150 - val_mae: 0.0897\n",
      "\n",
      "Epoch 00201: val_mae did not improve from 0.08058\n",
      "Epoch 202/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0146 - val_mae: 0.0879\n",
      "\n",
      "Epoch 00202: val_mae did not improve from 0.08058\n",
      "Epoch 203/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0153 - val_mae: 0.0905\n",
      "\n",
      "Epoch 00203: val_mae did not improve from 0.08058\n",
      "Epoch 204/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0159 - val_mae: 0.0929\n",
      "\n",
      "Epoch 00204: val_mae did not improve from 0.08058\n",
      "Epoch 205/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0146 - val_mae: 0.0882\n",
      "\n",
      "Epoch 00205: val_mae did not improve from 0.08058\n",
      "Epoch 206/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0148 - val_mae: 0.0884\n",
      "\n",
      "Epoch 00206: val_mae did not improve from 0.08058\n",
      "Epoch 00206: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f942a991af0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate, \n",
    "#                                                           decay_steps=decay_steps,\n",
    "#                                                           decay_rate=decay_rate)\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "#               loss='mse',\n",
    "#               metrics=['mae']\n",
    "#              )\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae']\n",
    "             )\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_mae', mode='min', verbose=2, patience=PATIENCE)\n",
    "mc = ModelCheckpoint('../../saved_models_mlp/pm_E.h5', \n",
    "                     monitor='val_mae', \n",
    "                     mode='min', \n",
    "                     verbose=2, \n",
    "                     save_best_only=True\n",
    "                    )\n",
    "\n",
    "\n",
    "model.fit(train_X_extreme, train_y_extreme,\n",
    "          validation_data=(val_X_extreme, val_y_extreme),\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH,\n",
    "          verbose=2,\n",
    "          shuffle=True,\n",
    "          callbacks=[es, mc]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3c6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf5004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7c598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
