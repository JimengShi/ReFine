{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4843e104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 22:18:11.623394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from helper import series_to_supervised\n",
    "from model.mlp import mlp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "460ee40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c74a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# random.seed(10)\n",
    "# print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb30958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "      <th>NE</th>\n",
       "      <th>NW</th>\n",
       "      <th>SE</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press  wnd_spd  snow  rain  NE  \\\n",
       "date                                                                         \n",
       "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0     1.79     0     0   0   \n",
       "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0     2.68     0     0   0   \n",
       "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0     3.57     0     0   0   \n",
       "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0     5.36     1     0   0   \n",
       "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0     6.25     2     0   0   \n",
       "\n",
       "                     NW  SE  cv  \n",
       "date                             \n",
       "2010-01-02 00:00:00   0   1   0  \n",
       "2010-01-02 01:00:00   0   1   0  \n",
       "2010-01-02 02:00:00   0   1   0  \n",
       "2010-01-02 03:00:00   0   1   0  \n",
       "2010-01-02 04:00:00   0   1   0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/pollution.csv\", index_col=0)\n",
    "data.fillna(0, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3855fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pollution', 'dew', 'temp', 'press', 'wnd_spd', 'snow', 'rain', 'NE',\n",
       "       'NW', 'SE', 'cv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191f187",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33b340cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reframed.shape: (43717, 924)\n"
     ]
    }
   ],
   "source": [
    "values = data.values\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_hours = 24*3\n",
    "n_features = data.shape[-1]\n",
    "k = 12\n",
    "split1 = 0.7\n",
    "split2 = 0.85\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(values, n_hours, k)\n",
    "print(\"reframed.shape:\", reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e2084b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (30601, 792) (30601, 12) (6558, 792) (6558, 12) (6558, 792) (6558, 12)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "reframed_values = reframed.values\n",
    "n_train_hours = int(len(reframed_values)*split1)\n",
    "n_valid_hours = int(len(reframed_values)*split2)\n",
    "\n",
    "train = reframed_values[:n_train_hours, :]\n",
    "val = reframed_values[n_train_hours:n_valid_hours, :]\n",
    "test = reframed_values[n_valid_hours:, :]\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "feature_idx = 0\n",
    "train_X, train_y = train[:, :n_obs], train[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "val_X, val_y = val[:, :n_obs], val[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "test_X, test_y = test[:, :n_obs], test[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1653a1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (30601, 72, 11) (30601, 12) (6558, 72, 11) (6558, 12) (6558, 72, 11) (6558, 12)\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "train_y = scaler.fit_transform(train_y)\n",
    "\n",
    "val_X = scaler.fit_transform(val_X)\n",
    "val_y = scaler.fit_transform(val_y)\n",
    "\n",
    "test_X = scaler.fit_transform(test_X)\n",
    "test_y = scaler.fit_transform(test_y)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd896d5",
   "metadata": {},
   "source": [
    "### PM threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8885dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30601,)\n",
      "(6558,)\n",
      "(6558,)\n"
     ]
    }
   ],
   "source": [
    "train_X_pm = train_X[:, 0, feature_idx]\n",
    "print(train_X_pm.shape)\n",
    "\n",
    "val_X_pm = val_X[:, 0, feature_idx]\n",
    "print(val_X_pm.shape)\n",
    "\n",
    "test_X_pm = test_X[:, 0, feature_idx]\n",
    "print(test_X_pm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f154878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_nums = 20\n",
    "\n",
    "# Step 1: Calculate the histogram\n",
    "counts, bin_edges = np.histogram(train_X_pm, bins=bin_nums)\n",
    "\n",
    "# Step 2: Invert counts to assign lower weights to more frequent bins, avoid division by zero by adding a small number (epsilon)\n",
    "epsilon = 1e-8\n",
    "weights = np.sqrt(1.0 / (counts + epsilon))\n",
    "# weights = 1.0 / (counts + epsilon)\n",
    "\n",
    "# Step 3: Normalize the weights (optional)\n",
    "weights /= np.sum(weights) * len(counts)\n",
    "\n",
    "# Step 4: Assign weights to each sample based on the bin it falls into\n",
    "sample_weights = np.zeros(train_X_pm.shape[0])\n",
    "\n",
    "for i, value in enumerate(train_X_pm):\n",
    "    \n",
    "    # Find the index of the bin this sample falls into\n",
    "    bin_index = np.digitize(value, bin_edges) - 1\n",
    "    bin_index = min(bin_index, bin_nums - 1)\n",
    "    \n",
    "    # Assign the corresponding weight\n",
    "    sample_weights[i] = weights[bin_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba3913c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30601,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b70ef2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights /= np.max(sample_weights)\n",
    "# sample_weights /= np.sum(sample_weights)\n",
    "# sample_weights = (sample_weights - sample_weights.min()) / (sample_weights.max()-sample_weights.min()) + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69798e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.939e+04, 7.760e+02, 3.380e+02, 0.000e+00, 5.400e+01, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.700e+01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 5.000e+00, 0.000e+00, 1.200e+01,\n",
       "        0.000e+00, 9.000e+00]),\n",
       " array([0.0155118 , 0.06473621, 0.11396062, 0.16318503, 0.21240944,\n",
       "        0.26163385, 0.31085826, 0.36008267, 0.40930708, 0.45853149,\n",
       "        0.5077559 , 0.55698031, 0.60620472, 0.65542913, 0.70465354,\n",
       "        0.75387795, 0.80310236, 0.85232677, 0.90155118, 0.95077559,\n",
       "        1.        ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sample_weights, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85808ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sample_weights_pm_IPF.npy', sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa5ce3",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5435f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== model parameters ======\n",
    "mlp_unit1 = 128\n",
    "mlp_unit2 = 128\n",
    "mlp_unit3 = 64\n",
    "mlp_unit4 = 64\n",
    "mlp_unit5 = 32\n",
    "mlp_unit6 = 32\n",
    "mlp_unit7 = 16\n",
    "mlp_unit8 = 16\n",
    "dropout = 0.0\n",
    "kernel_size = 2\n",
    "pool_size = 2\n",
    "learning_rate = 1e-4\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.95\n",
    "PATIENCE = 100\n",
    "EPOCHS = 1000\n",
    "BATCH = 512\n",
    "opt_num = k\n",
    "input_shape = train_X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0605f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_layer(input_shape=input_shape,\n",
    "                   mlp_unit1=mlp_unit1,\n",
    "                   mlp_unit2=mlp_unit2,\n",
    "                   mlp_unit3=mlp_unit3,\n",
    "                   mlp_unit4=mlp_unit4,\n",
    "                   mlp_unit5=mlp_unit5,\n",
    "                   mlp_unit6=mlp_unit6,\n",
    "                   mlp_unit7=mlp_unit7,\n",
    "                   mlp_unit8=mlp_unit8,\n",
    "                   dropout=dropout,\n",
    "                   masked_value=-1,\n",
    "                   opt_num=opt_num\n",
    "                  )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43622a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60/60 - 2s - loss: 2.7829e-04 - mae: 0.0699 - val_loss: 0.0157 - val_mae: 0.0869\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.08687, saving model to ../../saved_models/pm_all_weighted_IPF_95.h5\n",
      "Epoch 2/1000\n",
      "60/60 - 1s - loss: 1.5803e-04 - mae: 0.0503 - val_loss: 0.0101 - val_mae: 0.0678\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.08687 to 0.06784, saving model to ../../saved_models/pm_all_weighted_IPF_95.h5\n",
      "Epoch 3/1000\n",
      "60/60 - 1s - loss: 1.3038e-04 - mae: 0.0442 - val_loss: 0.0092 - val_mae: 0.0647\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.06784 to 0.06471, saving model to ../../saved_models/pm_all_weighted_IPF_95.h5\n",
      "Epoch 4/1000\n",
      "60/60 - 1s - loss: 1.2452e-04 - mae: 0.0428 - val_loss: 0.0093 - val_mae: 0.0636\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.06471 to 0.06364, saving model to ../../saved_models/pm_all_weighted_IPF_95.h5\n",
      "Epoch 5/1000\n",
      "60/60 - 1s - loss: 1.2219e-04 - mae: 0.0426 - val_loss: 0.0089 - val_mae: 0.0627\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.06364 to 0.06266, saving model to ../../saved_models/pm_all_weighted_IPF_95.h5\n",
      "Epoch 6/1000\n",
      "60/60 - 1s - loss: 1.1719e-04 - mae: 0.0414 - val_loss: 0.0097 - val_mae: 0.0658\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 0.06266\n",
      "Epoch 7/1000\n",
      "60/60 - 1s - loss: 1.1702e-04 - mae: 0.0417 - val_loss: 0.0092 - val_mae: 0.0628\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 0.06266\n",
      "Epoch 8/1000\n",
      "60/60 - 1s - loss: 1.1295e-04 - mae: 0.0409 - val_loss: 0.0086 - val_mae: 0.0613\n",
      "\n",
      "Epoch 00008: val_mae improved from 0.06266 to 0.06135, saving model to ../../saved_models/pm_all_weighted_IPF_95.h5\n",
      "Epoch 9/1000\n",
      "60/60 - 1s - loss: 1.1064e-04 - mae: 0.0408 - val_loss: 0.0085 - val_mae: 0.0618\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 0.06135\n",
      "Epoch 10/1000\n",
      "60/60 - 1s - loss: 1.0963e-04 - mae: 0.0408 - val_loss: 0.0096 - val_mae: 0.0646\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 0.06135\n",
      "Epoch 11/1000\n",
      "60/60 - 1s - loss: 1.0665e-04 - mae: 0.0403 - val_loss: 0.0090 - val_mae: 0.0621\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 0.06135\n",
      "Epoch 12/1000\n",
      "60/60 - 1s - loss: 1.0366e-04 - mae: 0.0399 - val_loss: 0.0086 - val_mae: 0.0612\n",
      "\n",
      "Epoch 00012: val_mae improved from 0.06135 to 0.06116, saving model to ../../saved_models/pm_all_weighted_IPF_95.h5\n",
      "Epoch 13/1000\n",
      "60/60 - 1s - loss: 1.0219e-04 - mae: 0.0397 - val_loss: 0.0083 - val_mae: 0.0606\n",
      "\n",
      "Epoch 00013: val_mae improved from 0.06116 to 0.06061, saving model to ../../saved_models/pm_all_weighted_IPF_95.h5\n",
      "Epoch 14/1000\n",
      "60/60 - 1s - loss: 9.9982e-05 - mae: 0.0396 - val_loss: 0.0088 - val_mae: 0.0624\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 0.06061\n",
      "Epoch 15/1000\n",
      "60/60 - 1s - loss: 1.0057e-04 - mae: 0.0400 - val_loss: 0.0085 - val_mae: 0.0608\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.06061\n",
      "Epoch 16/1000\n",
      "60/60 - 1s - loss: 9.7572e-05 - mae: 0.0397 - val_loss: 0.0086 - val_mae: 0.0614\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 0.06061\n",
      "Epoch 17/1000\n",
      "60/60 - 1s - loss: 9.4668e-05 - mae: 0.0390 - val_loss: 0.0086 - val_mae: 0.0613\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.06061\n",
      "Epoch 18/1000\n",
      "60/60 - 1s - loss: 9.2171e-05 - mae: 0.0387 - val_loss: 0.0091 - val_mae: 0.0627\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 0.06061\n",
      "Epoch 19/1000\n",
      "60/60 - 1s - loss: 9.1586e-05 - mae: 0.0388 - val_loss: 0.0092 - val_mae: 0.0643\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 0.06061\n",
      "Epoch 20/1000\n",
      "60/60 - 1s - loss: 8.8283e-05 - mae: 0.0382 - val_loss: 0.0088 - val_mae: 0.0620\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 0.06061\n",
      "Epoch 21/1000\n",
      "60/60 - 1s - loss: 8.9063e-05 - mae: 0.0387 - val_loss: 0.0090 - val_mae: 0.0632\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.06061\n",
      "Epoch 22/1000\n",
      "60/60 - 1s - loss: 8.8115e-05 - mae: 0.0385 - val_loss: 0.0089 - val_mae: 0.0622\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 0.06061\n",
      "Epoch 23/1000\n",
      "60/60 - 1s - loss: 8.5070e-05 - mae: 0.0379 - val_loss: 0.0089 - val_mae: 0.0623\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.06061\n",
      "Epoch 24/1000\n",
      "60/60 - 1s - loss: 8.5717e-05 - mae: 0.0381 - val_loss: 0.0094 - val_mae: 0.0642\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.06061\n",
      "Epoch 25/1000\n",
      "60/60 - 1s - loss: 8.5619e-05 - mae: 0.0385 - val_loss: 0.0089 - val_mae: 0.0622\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.06061\n",
      "Epoch 26/1000\n",
      "60/60 - 1s - loss: 8.3017e-05 - mae: 0.0376 - val_loss: 0.0090 - val_mae: 0.0636\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.06061\n",
      "Epoch 27/1000\n",
      "60/60 - 1s - loss: 8.2806e-05 - mae: 0.0378 - val_loss: 0.0088 - val_mae: 0.0615\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 0.06061\n",
      "Epoch 28/1000\n",
      "60/60 - 1s - loss: 8.0948e-05 - mae: 0.0374 - val_loss: 0.0094 - val_mae: 0.0635\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.06061\n",
      "Epoch 29/1000\n",
      "60/60 - 1s - loss: 8.0497e-05 - mae: 0.0373 - val_loss: 0.0094 - val_mae: 0.0643\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.06061\n",
      "Epoch 30/1000\n",
      "60/60 - 1s - loss: 8.1256e-05 - mae: 0.0378 - val_loss: 0.0097 - val_mae: 0.0644\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.06061\n",
      "Epoch 31/1000\n",
      "60/60 - 1s - loss: 7.8887e-05 - mae: 0.0372 - val_loss: 0.0096 - val_mae: 0.0642\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.06061\n",
      "Epoch 32/1000\n",
      "60/60 - 1s - loss: 7.8027e-05 - mae: 0.0371 - val_loss: 0.0095 - val_mae: 0.0646\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 0.06061\n",
      "Epoch 33/1000\n",
      "60/60 - 1s - loss: 7.6440e-05 - mae: 0.0369 - val_loss: 0.0099 - val_mae: 0.0656\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.06061\n",
      "Epoch 34/1000\n",
      "60/60 - 1s - loss: 7.6823e-05 - mae: 0.0369 - val_loss: 0.0102 - val_mae: 0.0665\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.06061\n",
      "Epoch 35/1000\n",
      "60/60 - 1s - loss: 7.5967e-05 - mae: 0.0368 - val_loss: 0.0099 - val_mae: 0.0651\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.06061\n",
      "Epoch 36/1000\n",
      "60/60 - 1s - loss: 7.5824e-05 - mae: 0.0369 - val_loss: 0.0099 - val_mae: 0.0655\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.06061\n",
      "Epoch 37/1000\n",
      "60/60 - 1s - loss: 7.3913e-05 - mae: 0.0364 - val_loss: 0.0104 - val_mae: 0.0667\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.06061\n",
      "Epoch 38/1000\n",
      "60/60 - 1s - loss: 7.2818e-05 - mae: 0.0363 - val_loss: 0.0096 - val_mae: 0.0650\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.06061\n",
      "Epoch 39/1000\n",
      "60/60 - 1s - loss: 7.3046e-05 - mae: 0.0364 - val_loss: 0.0101 - val_mae: 0.0665\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.06061\n",
      "Epoch 40/1000\n",
      "60/60 - 1s - loss: 7.2893e-05 - mae: 0.0364 - val_loss: 0.0104 - val_mae: 0.0679\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.06061\n",
      "Epoch 41/1000\n",
      "60/60 - 1s - loss: 7.0751e-05 - mae: 0.0358 - val_loss: 0.0104 - val_mae: 0.0668\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.06061\n",
      "Epoch 42/1000\n",
      "60/60 - 1s - loss: 7.0370e-05 - mae: 0.0359 - val_loss: 0.0108 - val_mae: 0.0682\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 0.06061\n",
      "Epoch 43/1000\n",
      "60/60 - 1s - loss: 6.8716e-05 - mae: 0.0356 - val_loss: 0.0104 - val_mae: 0.0667\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.06061\n",
      "Epoch 44/1000\n",
      "60/60 - 1s - loss: 7.0036e-05 - mae: 0.0360 - val_loss: 0.0107 - val_mae: 0.0682\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.06061\n",
      "Epoch 45/1000\n",
      "60/60 - 1s - loss: 6.6587e-05 - mae: 0.0351 - val_loss: 0.0109 - val_mae: 0.0684\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.06061\n",
      "Epoch 46/1000\n",
      "60/60 - 1s - loss: 6.7888e-05 - mae: 0.0355 - val_loss: 0.0102 - val_mae: 0.0663\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.06061\n",
      "Epoch 47/1000\n",
      "60/60 - 1s - loss: 6.7163e-05 - mae: 0.0355 - val_loss: 0.0104 - val_mae: 0.0676\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.06061\n",
      "Epoch 48/1000\n",
      "60/60 - 1s - loss: 6.7636e-05 - mae: 0.0355 - val_loss: 0.0110 - val_mae: 0.0687\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.06061\n",
      "Epoch 49/1000\n",
      "60/60 - 1s - loss: 6.4989e-05 - mae: 0.0350 - val_loss: 0.0112 - val_mae: 0.0693\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.06061\n",
      "Epoch 50/1000\n",
      "60/60 - 1s - loss: 6.4124e-05 - mae: 0.0349 - val_loss: 0.0114 - val_mae: 0.0696\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.06061\n",
      "Epoch 51/1000\n",
      "60/60 - 1s - loss: 6.7639e-05 - mae: 0.0358 - val_loss: 0.0105 - val_mae: 0.0673\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.06061\n",
      "Epoch 52/1000\n",
      "60/60 - 1s - loss: 6.3447e-05 - mae: 0.0347 - val_loss: 0.0110 - val_mae: 0.0690\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.06061\n",
      "Epoch 53/1000\n",
      "60/60 - 1s - loss: 6.2774e-05 - mae: 0.0345 - val_loss: 0.0112 - val_mae: 0.0698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00053: val_mae did not improve from 0.06061\n",
      "Epoch 54/1000\n",
      "60/60 - 1s - loss: 6.2514e-05 - mae: 0.0346 - val_loss: 0.0115 - val_mae: 0.0706\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.06061\n",
      "Epoch 55/1000\n",
      "60/60 - 1s - loss: 6.0679e-05 - mae: 0.0342 - val_loss: 0.0116 - val_mae: 0.0707\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.06061\n",
      "Epoch 56/1000\n",
      "60/60 - 1s - loss: 5.9930e-05 - mae: 0.0341 - val_loss: 0.0114 - val_mae: 0.0704\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 0.06061\n",
      "Epoch 57/1000\n",
      "60/60 - 1s - loss: 6.0758e-05 - mae: 0.0343 - val_loss: 0.0111 - val_mae: 0.0691\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.06061\n",
      "Epoch 58/1000\n",
      "60/60 - 1s - loss: 6.0070e-05 - mae: 0.0341 - val_loss: 0.0118 - val_mae: 0.0718\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.06061\n",
      "Epoch 59/1000\n",
      "60/60 - 1s - loss: 5.9537e-05 - mae: 0.0340 - val_loss: 0.0118 - val_mae: 0.0715\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.06061\n",
      "Epoch 60/1000\n",
      "60/60 - 1s - loss: 5.6946e-05 - mae: 0.0334 - val_loss: 0.0115 - val_mae: 0.0709\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.06061\n",
      "Epoch 61/1000\n",
      "60/60 - 1s - loss: 5.6531e-05 - mae: 0.0333 - val_loss: 0.0123 - val_mae: 0.0734\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.06061\n",
      "Epoch 62/1000\n",
      "60/60 - 1s - loss: 5.5803e-05 - mae: 0.0332 - val_loss: 0.0119 - val_mae: 0.0718\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.06061\n",
      "Epoch 63/1000\n",
      "60/60 - 1s - loss: 5.8093e-05 - mae: 0.0337 - val_loss: 0.0127 - val_mae: 0.0735\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.06061\n",
      "Epoch 64/1000\n",
      "60/60 - 1s - loss: 6.1784e-05 - mae: 0.0344 - val_loss: 0.0118 - val_mae: 0.0709\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.06061\n",
      "Epoch 65/1000\n",
      "60/60 - 1s - loss: 5.6635e-05 - mae: 0.0335 - val_loss: 0.0125 - val_mae: 0.0735\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.06061\n",
      "Epoch 66/1000\n",
      "60/60 - 1s - loss: 5.6288e-05 - mae: 0.0334 - val_loss: 0.0117 - val_mae: 0.0719\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.06061\n",
      "Epoch 67/1000\n",
      "60/60 - 1s - loss: 5.4474e-05 - mae: 0.0327 - val_loss: 0.0123 - val_mae: 0.0734\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.06061\n",
      "Epoch 68/1000\n",
      "60/60 - 1s - loss: 5.2877e-05 - mae: 0.0325 - val_loss: 0.0126 - val_mae: 0.0737\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.06061\n",
      "Epoch 69/1000\n",
      "60/60 - 1s - loss: 5.2632e-05 - mae: 0.0324 - val_loss: 0.0119 - val_mae: 0.0728\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.06061\n",
      "Epoch 70/1000\n",
      "60/60 - 1s - loss: 5.2944e-05 - mae: 0.0326 - val_loss: 0.0123 - val_mae: 0.0731\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.06061\n",
      "Epoch 71/1000\n",
      "60/60 - 1s - loss: 5.2005e-05 - mae: 0.0322 - val_loss: 0.0124 - val_mae: 0.0737\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.06061\n",
      "Epoch 72/1000\n",
      "60/60 - 1s - loss: 5.1254e-05 - mae: 0.0320 - val_loss: 0.0133 - val_mae: 0.0763\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.06061\n",
      "Epoch 73/1000\n",
      "60/60 - 1s - loss: 5.2002e-05 - mae: 0.0322 - val_loss: 0.0131 - val_mae: 0.0762\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.06061\n",
      "Epoch 74/1000\n",
      "60/60 - 1s - loss: 5.1191e-05 - mae: 0.0321 - val_loss: 0.0130 - val_mae: 0.0752\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.06061\n",
      "Epoch 75/1000\n",
      "60/60 - 1s - loss: 4.8847e-05 - mae: 0.0314 - val_loss: 0.0130 - val_mae: 0.0756\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.06061\n",
      "Epoch 76/1000\n",
      "60/60 - 1s - loss: 4.9590e-05 - mae: 0.0317 - val_loss: 0.0128 - val_mae: 0.0750\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.06061\n",
      "Epoch 77/1000\n",
      "60/60 - 1s - loss: 5.1082e-05 - mae: 0.0320 - val_loss: 0.0136 - val_mae: 0.0773\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.06061\n",
      "Epoch 78/1000\n",
      "60/60 - 1s - loss: 4.9755e-05 - mae: 0.0316 - val_loss: 0.0130 - val_mae: 0.0761\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.06061\n",
      "Epoch 79/1000\n",
      "60/60 - 1s - loss: 4.8471e-05 - mae: 0.0314 - val_loss: 0.0132 - val_mae: 0.0771\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.06061\n",
      "Epoch 80/1000\n",
      "60/60 - 1s - loss: 4.8442e-05 - mae: 0.0313 - val_loss: 0.0137 - val_mae: 0.0776\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.06061\n",
      "Epoch 81/1000\n",
      "60/60 - 1s - loss: 4.9141e-05 - mae: 0.0317 - val_loss: 0.0139 - val_mae: 0.0782\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.06061\n",
      "Epoch 82/1000\n",
      "60/60 - 1s - loss: 4.6864e-05 - mae: 0.0308 - val_loss: 0.0138 - val_mae: 0.0778\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.06061\n",
      "Epoch 83/1000\n",
      "60/60 - 1s - loss: 5.0893e-05 - mae: 0.0320 - val_loss: 0.0131 - val_mae: 0.0764\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.06061\n",
      "Epoch 84/1000\n",
      "60/60 - 1s - loss: 4.7961e-05 - mae: 0.0311 - val_loss: 0.0135 - val_mae: 0.0778\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.06061\n",
      "Epoch 85/1000\n",
      "60/60 - 1s - loss: 4.6819e-05 - mae: 0.0309 - val_loss: 0.0133 - val_mae: 0.0768\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.06061\n",
      "Epoch 86/1000\n",
      "60/60 - 1s - loss: 4.4904e-05 - mae: 0.0304 - val_loss: 0.0136 - val_mae: 0.0780\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.06061\n",
      "Epoch 87/1000\n",
      "60/60 - 1s - loss: 4.4115e-05 - mae: 0.0301 - val_loss: 0.0141 - val_mae: 0.0787\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.06061\n",
      "Epoch 88/1000\n",
      "60/60 - 1s - loss: 4.4627e-05 - mae: 0.0303 - val_loss: 0.0140 - val_mae: 0.0787\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.06061\n",
      "Epoch 89/1000\n",
      "60/60 - 1s - loss: 4.3941e-05 - mae: 0.0300 - val_loss: 0.0134 - val_mae: 0.0772\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.06061\n",
      "Epoch 90/1000\n",
      "60/60 - 1s - loss: 4.4028e-05 - mae: 0.0301 - val_loss: 0.0136 - val_mae: 0.0784\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.06061\n",
      "Epoch 91/1000\n",
      "60/60 - 1s - loss: 4.3478e-05 - mae: 0.0300 - val_loss: 0.0142 - val_mae: 0.0798\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.06061\n",
      "Epoch 92/1000\n",
      "60/60 - 1s - loss: 4.2378e-05 - mae: 0.0296 - val_loss: 0.0143 - val_mae: 0.0805\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.06061\n",
      "Epoch 93/1000\n",
      "60/60 - 1s - loss: 4.1282e-05 - mae: 0.0292 - val_loss: 0.0140 - val_mae: 0.0792\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.06061\n",
      "Epoch 94/1000\n",
      "60/60 - 1s - loss: 4.1295e-05 - mae: 0.0293 - val_loss: 0.0147 - val_mae: 0.0812\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.06061\n",
      "Epoch 95/1000\n",
      "60/60 - 1s - loss: 4.3761e-05 - mae: 0.0298 - val_loss: 0.0136 - val_mae: 0.0783\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.06061\n",
      "Epoch 96/1000\n",
      "60/60 - 1s - loss: 4.4152e-05 - mae: 0.0301 - val_loss: 0.0141 - val_mae: 0.0798\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.06061\n",
      "Epoch 97/1000\n",
      "60/60 - 1s - loss: 4.1157e-05 - mae: 0.0292 - val_loss: 0.0134 - val_mae: 0.0786\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.06061\n",
      "Epoch 98/1000\n",
      "60/60 - 1s - loss: 4.2979e-05 - mae: 0.0297 - val_loss: 0.0140 - val_mae: 0.0794\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.06061\n",
      "Epoch 99/1000\n",
      "60/60 - 1s - loss: 4.2834e-05 - mae: 0.0296 - val_loss: 0.0145 - val_mae: 0.0806\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.06061\n",
      "Epoch 100/1000\n",
      "60/60 - 1s - loss: 4.0222e-05 - mae: 0.0288 - val_loss: 0.0145 - val_mae: 0.0808\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.06061\n",
      "Epoch 101/1000\n",
      "60/60 - 1s - loss: 3.8678e-05 - mae: 0.0284 - val_loss: 0.0148 - val_mae: 0.0817\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.06061\n",
      "Epoch 102/1000\n",
      "60/60 - 1s - loss: 3.8782e-05 - mae: 0.0284 - val_loss: 0.0152 - val_mae: 0.0836\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.06061\n",
      "Epoch 103/1000\n",
      "60/60 - 1s - loss: 4.2774e-05 - mae: 0.0295 - val_loss: 0.0147 - val_mae: 0.0822\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.06061\n",
      "Epoch 104/1000\n",
      "60/60 - 1s - loss: 4.1219e-05 - mae: 0.0291 - val_loss: 0.0149 - val_mae: 0.0825\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.06061\n",
      "Epoch 105/1000\n",
      "60/60 - 1s - loss: 3.9236e-05 - mae: 0.0285 - val_loss: 0.0156 - val_mae: 0.0845\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.06061\n",
      "Epoch 106/1000\n",
      "60/60 - 1s - loss: 3.9844e-05 - mae: 0.0287 - val_loss: 0.0151 - val_mae: 0.0827\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.06061\n",
      "Epoch 107/1000\n",
      "60/60 - 1s - loss: 3.8341e-05 - mae: 0.0283 - val_loss: 0.0146 - val_mae: 0.0822\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.06061\n",
      "Epoch 108/1000\n",
      "60/60 - 1s - loss: 3.8065e-05 - mae: 0.0282 - val_loss: 0.0154 - val_mae: 0.0839\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.06061\n",
      "Epoch 109/1000\n",
      "60/60 - 1s - loss: 3.7546e-05 - mae: 0.0280 - val_loss: 0.0147 - val_mae: 0.0824\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.06061\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 - 1s - loss: 3.7151e-05 - mae: 0.0279 - val_loss: 0.0151 - val_mae: 0.0831\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.06061\n",
      "Epoch 111/1000\n",
      "60/60 - 1s - loss: 3.7426e-05 - mae: 0.0280 - val_loss: 0.0150 - val_mae: 0.0831\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.06061\n",
      "Epoch 112/1000\n",
      "60/60 - 1s - loss: 4.0559e-05 - mae: 0.0289 - val_loss: 0.0152 - val_mae: 0.0827\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.06061\n",
      "Epoch 113/1000\n",
      "60/60 - 1s - loss: 3.6479e-05 - mae: 0.0276 - val_loss: 0.0152 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.06061\n",
      "Epoch 114/1000\n",
      "60/60 - 1s - loss: 3.6551e-05 - mae: 0.0276 - val_loss: 0.0147 - val_mae: 0.0824\n",
      "\n",
      "Epoch 00114: val_mae did not improve from 0.06061\n",
      "Epoch 115/1000\n",
      "60/60 - 1s - loss: 3.4772e-05 - mae: 0.0270 - val_loss: 0.0149 - val_mae: 0.0829\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.06061\n",
      "Epoch 116/1000\n",
      "60/60 - 1s - loss: 3.5583e-05 - mae: 0.0273 - val_loss: 0.0155 - val_mae: 0.0851\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.06061\n",
      "Epoch 117/1000\n",
      "60/60 - 1s - loss: 3.6310e-05 - mae: 0.0275 - val_loss: 0.0147 - val_mae: 0.0825\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.06061\n",
      "Epoch 118/1000\n",
      "60/60 - 1s - loss: 3.6293e-05 - mae: 0.0275 - val_loss: 0.0158 - val_mae: 0.0851\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.06061\n",
      "Epoch 119/1000\n",
      "60/60 - 1s - loss: 3.3097e-05 - mae: 0.0264 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.06061\n",
      "Epoch 120/1000\n",
      "60/60 - 1s - loss: 3.3489e-05 - mae: 0.0265 - val_loss: 0.0155 - val_mae: 0.0847\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.06061\n",
      "Epoch 121/1000\n",
      "60/60 - 1s - loss: 3.4846e-05 - mae: 0.0270 - val_loss: 0.0158 - val_mae: 0.0860\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.06061\n",
      "Epoch 122/1000\n",
      "60/60 - 1s - loss: 3.3855e-05 - mae: 0.0267 - val_loss: 0.0154 - val_mae: 0.0851\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.06061\n",
      "Epoch 123/1000\n",
      "60/60 - 1s - loss: 3.3477e-05 - mae: 0.0265 - val_loss: 0.0155 - val_mae: 0.0852\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.06061\n",
      "Epoch 124/1000\n",
      "60/60 - 1s - loss: 3.6457e-05 - mae: 0.0276 - val_loss: 0.0152 - val_mae: 0.0846\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.06061\n",
      "Epoch 125/1000\n",
      "60/60 - 1s - loss: 3.2693e-05 - mae: 0.0262 - val_loss: 0.0159 - val_mae: 0.0864\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.06061\n",
      "Epoch 126/1000\n",
      "60/60 - 1s - loss: 3.3792e-05 - mae: 0.0266 - val_loss: 0.0155 - val_mae: 0.0857\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.06061\n",
      "Epoch 127/1000\n",
      "60/60 - 1s - loss: 3.3395e-05 - mae: 0.0266 - val_loss: 0.0160 - val_mae: 0.0864\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.06061\n",
      "Epoch 128/1000\n",
      "60/60 - 1s - loss: 3.4093e-05 - mae: 0.0266 - val_loss: 0.0160 - val_mae: 0.0862\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.06061\n",
      "Epoch 129/1000\n",
      "60/60 - 1s - loss: 3.3811e-05 - mae: 0.0266 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.06061\n",
      "Epoch 130/1000\n",
      "60/60 - 1s - loss: 3.2951e-05 - mae: 0.0263 - val_loss: 0.0157 - val_mae: 0.0865\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.06061\n",
      "Epoch 131/1000\n",
      "60/60 - 1s - loss: 3.5657e-05 - mae: 0.0272 - val_loss: 0.0158 - val_mae: 0.0862\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.06061\n",
      "Epoch 132/1000\n",
      "60/60 - 1s - loss: 3.4241e-05 - mae: 0.0267 - val_loss: 0.0156 - val_mae: 0.0857\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.06061\n",
      "Epoch 133/1000\n",
      "60/60 - 1s - loss: 3.2115e-05 - mae: 0.0260 - val_loss: 0.0164 - val_mae: 0.0876\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.06061\n",
      "Epoch 134/1000\n",
      "60/60 - 1s - loss: 3.2077e-05 - mae: 0.0259 - val_loss: 0.0154 - val_mae: 0.0849\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.06061\n",
      "Epoch 135/1000\n",
      "60/60 - 1s - loss: 3.1926e-05 - mae: 0.0260 - val_loss: 0.0158 - val_mae: 0.0867\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.06061\n",
      "Epoch 136/1000\n",
      "60/60 - 1s - loss: 3.1511e-05 - mae: 0.0257 - val_loss: 0.0160 - val_mae: 0.0870\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.06061\n",
      "Epoch 137/1000\n",
      "60/60 - 1s - loss: 3.0149e-05 - mae: 0.0253 - val_loss: 0.0160 - val_mae: 0.0868\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.06061\n",
      "Epoch 138/1000\n",
      "60/60 - 1s - loss: 3.2992e-05 - mae: 0.0262 - val_loss: 0.0164 - val_mae: 0.0881\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.06061\n",
      "Epoch 139/1000\n",
      "60/60 - 1s - loss: 3.4889e-05 - mae: 0.0268 - val_loss: 0.0158 - val_mae: 0.0859\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.06061\n",
      "Epoch 140/1000\n",
      "60/60 - 1s - loss: 3.5254e-05 - mae: 0.0269 - val_loss: 0.0163 - val_mae: 0.0870\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.06061\n",
      "Epoch 141/1000\n",
      "60/60 - 1s - loss: 3.1881e-05 - mae: 0.0258 - val_loss: 0.0163 - val_mae: 0.0877\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.06061\n",
      "Epoch 142/1000\n",
      "60/60 - 1s - loss: 3.1468e-05 - mae: 0.0257 - val_loss: 0.0159 - val_mae: 0.0863\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.06061\n",
      "Epoch 143/1000\n",
      "60/60 - 1s - loss: 3.0154e-05 - mae: 0.0252 - val_loss: 0.0160 - val_mae: 0.0870\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.06061\n",
      "Epoch 144/1000\n",
      "60/60 - 1s - loss: 2.9328e-05 - mae: 0.0249 - val_loss: 0.0163 - val_mae: 0.0877\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.06061\n",
      "Epoch 145/1000\n",
      "60/60 - 1s - loss: 2.9481e-05 - mae: 0.0249 - val_loss: 0.0165 - val_mae: 0.0887\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.06061\n",
      "Epoch 146/1000\n",
      "60/60 - 1s - loss: 3.0534e-05 - mae: 0.0253 - val_loss: 0.0167 - val_mae: 0.0887\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.06061\n",
      "Epoch 147/1000\n",
      "60/60 - 1s - loss: 3.0429e-05 - mae: 0.0253 - val_loss: 0.0167 - val_mae: 0.0893\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.06061\n",
      "Epoch 148/1000\n",
      "60/60 - 1s - loss: 2.9088e-05 - mae: 0.0248 - val_loss: 0.0167 - val_mae: 0.0889\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.06061\n",
      "Epoch 149/1000\n",
      "60/60 - 1s - loss: 2.9471e-05 - mae: 0.0249 - val_loss: 0.0163 - val_mae: 0.0876\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.06061\n",
      "Epoch 150/1000\n",
      "60/60 - 1s - loss: 2.9381e-05 - mae: 0.0249 - val_loss: 0.0169 - val_mae: 0.0905\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.06061\n",
      "Epoch 151/1000\n",
      "60/60 - 1s - loss: 3.0429e-05 - mae: 0.0253 - val_loss: 0.0168 - val_mae: 0.0894\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.06061\n",
      "Epoch 152/1000\n",
      "60/60 - 1s - loss: 3.1158e-05 - mae: 0.0254 - val_loss: 0.0164 - val_mae: 0.0881\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.06061\n",
      "Epoch 153/1000\n",
      "60/60 - 1s - loss: 2.8860e-05 - mae: 0.0247 - val_loss: 0.0159 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.06061\n",
      "Epoch 154/1000\n",
      "60/60 - 1s - loss: 2.8376e-05 - mae: 0.0244 - val_loss: 0.0170 - val_mae: 0.0901\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.06061\n",
      "Epoch 155/1000\n",
      "60/60 - 1s - loss: 2.7499e-05 - mae: 0.0240 - val_loss: 0.0170 - val_mae: 0.0896\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.06061\n",
      "Epoch 156/1000\n",
      "60/60 - 1s - loss: 2.7855e-05 - mae: 0.0243 - val_loss: 0.0174 - val_mae: 0.0914\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.06061\n",
      "Epoch 157/1000\n",
      "60/60 - 1s - loss: 2.7795e-05 - mae: 0.0242 - val_loss: 0.0170 - val_mae: 0.0908\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.06061\n",
      "Epoch 158/1000\n",
      "60/60 - 1s - loss: 3.0314e-05 - mae: 0.0251 - val_loss: 0.0174 - val_mae: 0.0915\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.06061\n",
      "Epoch 159/1000\n",
      "60/60 - 1s - loss: 2.8980e-05 - mae: 0.0246 - val_loss: 0.0170 - val_mae: 0.0903\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.06061\n",
      "Epoch 160/1000\n",
      "60/60 - 1s - loss: 2.9594e-05 - mae: 0.0249 - val_loss: 0.0171 - val_mae: 0.0903\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.06061\n",
      "Epoch 161/1000\n",
      "60/60 - 1s - loss: 3.1729e-05 - mae: 0.0254 - val_loss: 0.0166 - val_mae: 0.0899\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.06061\n",
      "Epoch 162/1000\n",
      "60/60 - 1s - loss: 2.8976e-05 - mae: 0.0245 - val_loss: 0.0163 - val_mae: 0.0886\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.06061\n",
      "Epoch 163/1000\n",
      "60/60 - 1s - loss: 2.7323e-05 - mae: 0.0240 - val_loss: 0.0173 - val_mae: 0.0912\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.06061\n",
      "Epoch 164/1000\n",
      "60/60 - 1s - loss: 2.6516e-05 - mae: 0.0236 - val_loss: 0.0169 - val_mae: 0.0902\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.06061\n",
      "Epoch 165/1000\n",
      "60/60 - 1s - loss: 2.5481e-05 - mae: 0.0232 - val_loss: 0.0177 - val_mae: 0.0922\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.06061\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 - 1s - loss: 2.6130e-05 - mae: 0.0235 - val_loss: 0.0171 - val_mae: 0.0909\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.06061\n",
      "Epoch 167/1000\n",
      "60/60 - 1s - loss: 2.7117e-05 - mae: 0.0239 - val_loss: 0.0174 - val_mae: 0.0913\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.06061\n",
      "Epoch 168/1000\n",
      "60/60 - 1s - loss: 2.6085e-05 - mae: 0.0234 - val_loss: 0.0176 - val_mae: 0.0917\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.06061\n",
      "Epoch 169/1000\n",
      "60/60 - 1s - loss: 2.6481e-05 - mae: 0.0236 - val_loss: 0.0169 - val_mae: 0.0910\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.06061\n",
      "Epoch 170/1000\n",
      "60/60 - 1s - loss: 2.6317e-05 - mae: 0.0236 - val_loss: 0.0176 - val_mae: 0.0923\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.06061\n",
      "Epoch 171/1000\n",
      "60/60 - 1s - loss: 2.5772e-05 - mae: 0.0233 - val_loss: 0.0178 - val_mae: 0.0930\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.06061\n",
      "Epoch 172/1000\n",
      "60/60 - 1s - loss: 2.5828e-05 - mae: 0.0233 - val_loss: 0.0182 - val_mae: 0.0932\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.06061\n",
      "Epoch 173/1000\n",
      "60/60 - 1s - loss: 2.5830e-05 - mae: 0.0234 - val_loss: 0.0176 - val_mae: 0.0923\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.06061\n",
      "Epoch 174/1000\n",
      "60/60 - 1s - loss: 2.5669e-05 - mae: 0.0232 - val_loss: 0.0180 - val_mae: 0.0938\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.06061\n",
      "Epoch 175/1000\n",
      "60/60 - 1s - loss: 2.6905e-05 - mae: 0.0238 - val_loss: 0.0176 - val_mae: 0.0924\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.06061\n",
      "Epoch 176/1000\n",
      "60/60 - 1s - loss: 2.5005e-05 - mae: 0.0230 - val_loss: 0.0178 - val_mae: 0.0929\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.06061\n",
      "Epoch 177/1000\n",
      "60/60 - 1s - loss: 2.7018e-05 - mae: 0.0239 - val_loss: 0.0178 - val_mae: 0.0932\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.06061\n",
      "Epoch 178/1000\n",
      "60/60 - 1s - loss: 3.0001e-05 - mae: 0.0252 - val_loss: 0.0165 - val_mae: 0.0902\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.06061\n",
      "Epoch 179/1000\n",
      "60/60 - 1s - loss: 2.6720e-05 - mae: 0.0238 - val_loss: 0.0176 - val_mae: 0.0924\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.06061\n",
      "Epoch 180/1000\n",
      "60/60 - 1s - loss: 2.5368e-05 - mae: 0.0230 - val_loss: 0.0174 - val_mae: 0.0917\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.06061\n",
      "Epoch 181/1000\n",
      "60/60 - 1s - loss: 2.6345e-05 - mae: 0.0235 - val_loss: 0.0177 - val_mae: 0.0930\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.06061\n",
      "Epoch 182/1000\n",
      "60/60 - 1s - loss: 2.5811e-05 - mae: 0.0232 - val_loss: 0.0175 - val_mae: 0.0921\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.06061\n",
      "Epoch 183/1000\n",
      "60/60 - 1s - loss: 2.5417e-05 - mae: 0.0232 - val_loss: 0.0178 - val_mae: 0.0929\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.06061\n",
      "Epoch 184/1000\n",
      "60/60 - 1s - loss: 2.4765e-05 - mae: 0.0228 - val_loss: 0.0177 - val_mae: 0.0931\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.06061\n",
      "Epoch 185/1000\n",
      "60/60 - 1s - loss: 2.5363e-05 - mae: 0.0230 - val_loss: 0.0178 - val_mae: 0.0930\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.06061\n",
      "Epoch 186/1000\n",
      "60/60 - 1s - loss: 2.6503e-05 - mae: 0.0234 - val_loss: 0.0175 - val_mae: 0.0922\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.06061\n",
      "Epoch 187/1000\n",
      "60/60 - 1s - loss: 2.5096e-05 - mae: 0.0230 - val_loss: 0.0176 - val_mae: 0.0924\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.06061\n",
      "Epoch 188/1000\n",
      "60/60 - 1s - loss: 2.5056e-05 - mae: 0.0230 - val_loss: 0.0176 - val_mae: 0.0931\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.06061\n",
      "Epoch 189/1000\n",
      "60/60 - 1s - loss: 2.4547e-05 - mae: 0.0227 - val_loss: 0.0177 - val_mae: 0.0935\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.06061\n",
      "Epoch 190/1000\n",
      "60/60 - 1s - loss: 2.4188e-05 - mae: 0.0225 - val_loss: 0.0184 - val_mae: 0.0949\n",
      "\n",
      "Epoch 00190: val_mae did not improve from 0.06061\n",
      "Epoch 191/1000\n",
      "60/60 - 1s - loss: 2.4687e-05 - mae: 0.0228 - val_loss: 0.0179 - val_mae: 0.0932\n",
      "\n",
      "Epoch 00191: val_mae did not improve from 0.06061\n",
      "Epoch 192/1000\n",
      "60/60 - 1s - loss: 2.3845e-05 - mae: 0.0225 - val_loss: 0.0176 - val_mae: 0.0926\n",
      "\n",
      "Epoch 00192: val_mae did not improve from 0.06061\n",
      "Epoch 193/1000\n",
      "60/60 - 1s - loss: 2.4106e-05 - mae: 0.0224 - val_loss: 0.0183 - val_mae: 0.0945\n",
      "\n",
      "Epoch 00193: val_mae did not improve from 0.06061\n",
      "Epoch 194/1000\n",
      "60/60 - 1s - loss: 2.4234e-05 - mae: 0.0226 - val_loss: 0.0183 - val_mae: 0.0947\n",
      "\n",
      "Epoch 00194: val_mae did not improve from 0.06061\n",
      "Epoch 195/1000\n",
      "60/60 - 1s - loss: 2.4886e-05 - mae: 0.0229 - val_loss: 0.0180 - val_mae: 0.0939\n",
      "\n",
      "Epoch 00195: val_mae did not improve from 0.06061\n",
      "Epoch 196/1000\n",
      "60/60 - 1s - loss: 2.3745e-05 - mae: 0.0223 - val_loss: 0.0180 - val_mae: 0.0942\n",
      "\n",
      "Epoch 00196: val_mae did not improve from 0.06061\n",
      "Epoch 197/1000\n",
      "60/60 - 1s - loss: 2.6585e-05 - mae: 0.0236 - val_loss: 0.0172 - val_mae: 0.0919\n",
      "\n",
      "Epoch 00197: val_mae did not improve from 0.06061\n",
      "Epoch 198/1000\n",
      "60/60 - 1s - loss: 2.4350e-05 - mae: 0.0226 - val_loss: 0.0178 - val_mae: 0.0932\n",
      "\n",
      "Epoch 00198: val_mae did not improve from 0.06061\n",
      "Epoch 199/1000\n",
      "60/60 - 1s - loss: 2.2578e-05 - mae: 0.0218 - val_loss: 0.0185 - val_mae: 0.0949\n",
      "\n",
      "Epoch 00199: val_mae did not improve from 0.06061\n",
      "Epoch 200/1000\n",
      "60/60 - 1s - loss: 2.2467e-05 - mae: 0.0217 - val_loss: 0.0179 - val_mae: 0.0939\n",
      "\n",
      "Epoch 00200: val_mae did not improve from 0.06061\n",
      "Epoch 201/1000\n",
      "60/60 - 1s - loss: 2.3756e-05 - mae: 0.0224 - val_loss: 0.0176 - val_mae: 0.0933\n",
      "\n",
      "Epoch 00201: val_mae did not improve from 0.06061\n",
      "Epoch 202/1000\n",
      "60/60 - 1s - loss: 2.3234e-05 - mae: 0.0222 - val_loss: 0.0180 - val_mae: 0.0943\n",
      "\n",
      "Epoch 00202: val_mae did not improve from 0.06061\n",
      "Epoch 203/1000\n",
      "60/60 - 1s - loss: 2.3659e-05 - mae: 0.0223 - val_loss: 0.0180 - val_mae: 0.0942\n",
      "\n",
      "Epoch 00203: val_mae did not improve from 0.06061\n",
      "Epoch 204/1000\n",
      "60/60 - 1s - loss: 2.4487e-05 - mae: 0.0227 - val_loss: 0.0180 - val_mae: 0.0944\n",
      "\n",
      "Epoch 00204: val_mae did not improve from 0.06061\n",
      "Epoch 205/1000\n",
      "60/60 - 1s - loss: 2.9091e-05 - mae: 0.0246 - val_loss: 0.0174 - val_mae: 0.0926\n",
      "\n",
      "Epoch 00205: val_mae did not improve from 0.06061\n",
      "Epoch 206/1000\n",
      "60/60 - 1s - loss: 2.5322e-05 - mae: 0.0230 - val_loss: 0.0174 - val_mae: 0.0920\n",
      "\n",
      "Epoch 00206: val_mae did not improve from 0.06061\n",
      "Epoch 207/1000\n",
      "60/60 - 1s - loss: 2.4106e-05 - mae: 0.0225 - val_loss: 0.0180 - val_mae: 0.0938\n",
      "\n",
      "Epoch 00207: val_mae did not improve from 0.06061\n",
      "Epoch 208/1000\n",
      "60/60 - 1s - loss: 2.2543e-05 - mae: 0.0218 - val_loss: 0.0180 - val_mae: 0.0941\n",
      "\n",
      "Epoch 00208: val_mae did not improve from 0.06061\n",
      "Epoch 209/1000\n",
      "60/60 - 1s - loss: 2.1923e-05 - mae: 0.0215 - val_loss: 0.0183 - val_mae: 0.0947\n",
      "\n",
      "Epoch 00209: val_mae did not improve from 0.06061\n",
      "Epoch 210/1000\n",
      "60/60 - 1s - loss: 2.1714e-05 - mae: 0.0214 - val_loss: 0.0181 - val_mae: 0.0943\n",
      "\n",
      "Epoch 00210: val_mae did not improve from 0.06061\n",
      "Epoch 211/1000\n",
      "60/60 - 1s - loss: 2.2138e-05 - mae: 0.0215 - val_loss: 0.0179 - val_mae: 0.0937\n",
      "\n",
      "Epoch 00211: val_mae did not improve from 0.06061\n",
      "Epoch 212/1000\n",
      "60/60 - 1s - loss: 2.3639e-05 - mae: 0.0223 - val_loss: 0.0182 - val_mae: 0.0947\n",
      "\n",
      "Epoch 00212: val_mae did not improve from 0.06061\n",
      "Epoch 213/1000\n",
      "60/60 - 1s - loss: 2.2652e-05 - mae: 0.0218 - val_loss: 0.0179 - val_mae: 0.0936\n",
      "\n",
      "Epoch 00213: val_mae did not improve from 0.06061\n",
      "Epoch 00213: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f13ac484310>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae']\n",
    "             )\n",
    "\n",
    "es = EarlyStopping(monitor='val_mae', mode='min', verbose=2, patience=PATIENCE)\n",
    "mc = ModelCheckpoint('../../saved_models/pm_all_weighted_IPF_95.h5', \n",
    "                     monitor='val_mae', \n",
    "                     mode='min', \n",
    "                     verbose=2, \n",
    "                     save_best_only=True,\n",
    "                    )\n",
    "\n",
    "\n",
    "model.fit(train_X, train_y,\n",
    "          validation_data=(val_X, val_y),\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH,\n",
    "          verbose=2,\n",
    "          shuffle=True,\n",
    "          callbacks=[es, mc],\n",
    "          sample_weight=sample_weights\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b313809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95854ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
