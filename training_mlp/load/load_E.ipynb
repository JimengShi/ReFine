{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25441506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 14:31:39.358477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from helper import series_to_supervised\n",
    "from model.mlp import mlp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2af1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eefef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# random.seed(10)\n",
    "# print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537a30dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_dayahead</th>\n",
       "      <th>gen_coal</th>\n",
       "      <th>gen_gas</th>\n",
       "      <th>load_actual</th>\n",
       "      <th>gen_lig</th>\n",
       "      <th>gen_oil</th>\n",
       "      <th>gen_oth_renew</th>\n",
       "      <th>pressure_Barcelona</th>\n",
       "      <th>pressure_Bilbao</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_deg_Bilbao</th>\n",
       "      <th>clouds_all_Bilbao</th>\n",
       "      <th>gen_hyd_river</th>\n",
       "      <th>wind_deg_Seville</th>\n",
       "      <th>wind_speed_Barcelona</th>\n",
       "      <th>wind_speed_Valencia</th>\n",
       "      <th>wind_speed_Bilbao</th>\n",
       "      <th>gen_wind</th>\n",
       "      <th>wind_speed_Madrid</th>\n",
       "      <th>gen_hyd_pump</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00+00:00</th>\n",
       "      <td>64.92</td>\n",
       "      <td>48.10</td>\n",
       "      <td>4755.0</td>\n",
       "      <td>5196.0</td>\n",
       "      <td>24382.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>...</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5890.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00+00:00</th>\n",
       "      <td>64.48</td>\n",
       "      <td>47.33</td>\n",
       "      <td>4581.0</td>\n",
       "      <td>4857.0</td>\n",
       "      <td>22734.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>...</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5461.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00+00:00</th>\n",
       "      <td>59.32</td>\n",
       "      <td>42.27</td>\n",
       "      <td>4131.0</td>\n",
       "      <td>4314.0</td>\n",
       "      <td>21286.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>...</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00+00:00</th>\n",
       "      <td>56.04</td>\n",
       "      <td>38.41</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>4130.0</td>\n",
       "      <td>20264.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>...</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1826.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00+00:00</th>\n",
       "      <td>53.63</td>\n",
       "      <td>35.72</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>4038.0</td>\n",
       "      <td>19905.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>...</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4618.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 18:00:00+00:00</th>\n",
       "      <td>77.02</td>\n",
       "      <td>68.85</td>\n",
       "      <td>2628.0</td>\n",
       "      <td>7634.0</td>\n",
       "      <td>30653.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3113.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 19:00:00+00:00</th>\n",
       "      <td>76.16</td>\n",
       "      <td>68.40</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>7241.0</td>\n",
       "      <td>29735.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3288.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 20:00:00+00:00</th>\n",
       "      <td>74.30</td>\n",
       "      <td>66.88</td>\n",
       "      <td>2422.0</td>\n",
       "      <td>7025.0</td>\n",
       "      <td>28071.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3503.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:00:00+00:00</th>\n",
       "      <td>69.89</td>\n",
       "      <td>63.93</td>\n",
       "      <td>2293.0</td>\n",
       "      <td>6562.0</td>\n",
       "      <td>25801.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3586.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 22:00:00+00:00</th>\n",
       "      <td>69.88</td>\n",
       "      <td>64.27</td>\n",
       "      <td>2166.0</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>24455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3651.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           price  price_dayahead  gen_coal  gen_gas  \\\n",
       "time                                                                  \n",
       "2015-01-01 00:00:00+00:00  64.92           48.10    4755.0   5196.0   \n",
       "2015-01-01 01:00:00+00:00  64.48           47.33    4581.0   4857.0   \n",
       "2015-01-01 02:00:00+00:00  59.32           42.27    4131.0   4314.0   \n",
       "2015-01-01 03:00:00+00:00  56.04           38.41    3840.0   4130.0   \n",
       "2015-01-01 04:00:00+00:00  53.63           35.72    3590.0   4038.0   \n",
       "...                          ...             ...       ...      ...   \n",
       "2018-12-31 18:00:00+00:00  77.02           68.85    2628.0   7634.0   \n",
       "2018-12-31 19:00:00+00:00  76.16           68.40    2566.0   7241.0   \n",
       "2018-12-31 20:00:00+00:00  74.30           66.88    2422.0   7025.0   \n",
       "2018-12-31 21:00:00+00:00  69.89           63.93    2293.0   6562.0   \n",
       "2018-12-31 22:00:00+00:00  69.88           64.27    2166.0   6926.0   \n",
       "\n",
       "                           load_actual  gen_lig  gen_oil  gen_oth_renew  \\\n",
       "time                                                                      \n",
       "2015-01-01 00:00:00+00:00      24382.0    328.0    158.0           71.0   \n",
       "2015-01-01 01:00:00+00:00      22734.0    323.0    157.0           73.0   \n",
       "2015-01-01 02:00:00+00:00      21286.0    254.0    160.0           75.0   \n",
       "2015-01-01 03:00:00+00:00      20264.0    187.0    156.0           74.0   \n",
       "2015-01-01 04:00:00+00:00      19905.0    178.0    156.0           74.0   \n",
       "...                                ...      ...      ...            ...   \n",
       "2018-12-31 18:00:00+00:00      30653.0      0.0    178.0           95.0   \n",
       "2018-12-31 19:00:00+00:00      29735.0      0.0    174.0           95.0   \n",
       "2018-12-31 20:00:00+00:00      28071.0      0.0    168.0           94.0   \n",
       "2018-12-31 21:00:00+00:00      25801.0      0.0    163.0           93.0   \n",
       "2018-12-31 22:00:00+00:00      24455.0      0.0    163.0           92.0   \n",
       "\n",
       "                           pressure_Barcelona  pressure_Bilbao  ...  \\\n",
       "time                                                            ...   \n",
       "2015-01-01 00:00:00+00:00              1035.0           1035.0  ...   \n",
       "2015-01-01 01:00:00+00:00              1036.0           1036.0  ...   \n",
       "2015-01-01 02:00:00+00:00              1036.0           1035.0  ...   \n",
       "2015-01-01 03:00:00+00:00              1036.0           1035.0  ...   \n",
       "2015-01-01 04:00:00+00:00              1037.0           1035.0  ...   \n",
       "...                                       ...              ...  ...   \n",
       "2018-12-31 18:00:00+00:00              1027.0           1033.0  ...   \n",
       "2018-12-31 19:00:00+00:00              1027.0           1034.0  ...   \n",
       "2018-12-31 20:00:00+00:00              1028.0           1034.0  ...   \n",
       "2018-12-31 21:00:00+00:00              1028.0           1034.0  ...   \n",
       "2018-12-31 22:00:00+00:00              1028.0           1034.0  ...   \n",
       "\n",
       "                           wind_deg_Bilbao  clouds_all_Bilbao  gen_hyd_river  \\\n",
       "time                                                                           \n",
       "2015-01-01 00:00:00+00:00            229.0                0.0         1009.0   \n",
       "2015-01-01 01:00:00+00:00            224.0                0.0          973.0   \n",
       "2015-01-01 02:00:00+00:00            225.0                0.0          949.0   \n",
       "2015-01-01 03:00:00+00:00            221.0                0.0          953.0   \n",
       "2015-01-01 04:00:00+00:00            224.0                0.0          952.0   \n",
       "...                                    ...                ...            ...   \n",
       "2018-12-31 18:00:00+00:00             57.0                0.0         1135.0   \n",
       "2018-12-31 19:00:00+00:00              0.0                0.0         1172.0   \n",
       "2018-12-31 20:00:00+00:00            140.0                0.0         1148.0   \n",
       "2018-12-31 21:00:00+00:00            120.0                0.0         1128.0   \n",
       "2018-12-31 22:00:00+00:00            100.0                0.0         1069.0   \n",
       "\n",
       "                           wind_deg_Seville  wind_speed_Barcelona  \\\n",
       "time                                                                \n",
       "2015-01-01 00:00:00+00:00              21.0                   7.0   \n",
       "2015-01-01 01:00:00+00:00              27.0                   7.0   \n",
       "2015-01-01 02:00:00+00:00              27.0                   7.0   \n",
       "2015-01-01 03:00:00+00:00              27.0                   7.0   \n",
       "2015-01-01 04:00:00+00:00              57.0                   5.0   \n",
       "...                                     ...                   ...   \n",
       "2018-12-31 18:00:00+00:00              30.0                   1.0   \n",
       "2018-12-31 19:00:00+00:00              30.0                   3.0   \n",
       "2018-12-31 20:00:00+00:00              50.0                   4.0   \n",
       "2018-12-31 21:00:00+00:00              60.0                   5.0   \n",
       "2018-12-31 22:00:00+00:00              50.0                   5.0   \n",
       "\n",
       "                           wind_speed_Valencia  wind_speed_Bilbao  gen_wind  \\\n",
       "time                                                                          \n",
       "2015-01-01 00:00:00+00:00                  1.0                0.0    5890.0   \n",
       "2015-01-01 01:00:00+00:00                  0.0                1.0    5461.0   \n",
       "2015-01-01 02:00:00+00:00                  0.0                1.0    5238.0   \n",
       "2015-01-01 03:00:00+00:00                  0.0                1.0    4935.0   \n",
       "2015-01-01 04:00:00+00:00                  2.0                1.0    4618.0   \n",
       "...                                        ...                ...       ...   \n",
       "2018-12-31 18:00:00+00:00                  2.0                0.0    3113.0   \n",
       "2018-12-31 19:00:00+00:00                  1.0                1.0    3288.0   \n",
       "2018-12-31 20:00:00+00:00                  3.0                1.0    3503.0   \n",
       "2018-12-31 21:00:00+00:00                  2.0                1.0    3586.0   \n",
       "2018-12-31 22:00:00+00:00                  2.0                2.0    3651.0   \n",
       "\n",
       "                           wind_speed_Madrid  gen_hyd_pump  \n",
       "time                                                        \n",
       "2015-01-01 00:00:00+00:00                1.0         920.0  \n",
       "2015-01-01 01:00:00+00:00                1.0        1164.0  \n",
       "2015-01-01 02:00:00+00:00                1.0        1503.0  \n",
       "2015-01-01 03:00:00+00:00                1.0        1826.0  \n",
       "2015-01-01 04:00:00+00:00                0.0        2109.0  \n",
       "...                                      ...           ...  \n",
       "2018-12-31 18:00:00+00:00                1.0           1.0  \n",
       "2018-12-31 19:00:00+00:00                1.0           1.0  \n",
       "2018-12-31 20:00:00+00:00                1.0          50.0  \n",
       "2018-12-31 21:00:00+00:00                2.0         108.0  \n",
       "2018-12-31 22:00:00+00:00                1.0         108.0  \n",
       "\n",
       "[35063 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../../data/energy_weather.csv', index_col=0)\n",
    "# https://www.kaggle.com/datasets/nicholasjhana/energy-consumption-generation-prices-and-weather\n",
    "\n",
    "dataset.fillna(0, inplace=True)\n",
    "data = dataset\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f495cc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'price_dayahead', 'gen_coal', 'gen_gas', 'load_actual',\n",
       "       'gen_lig', 'gen_oil', 'gen_oth_renew', 'pressure_Barcelona',\n",
       "       'pressure_Bilbao', 'gen_waste', 'gen_bio', 'temp_min_Valencia',\n",
       "       'pressure_Valencia', 'temp_min_Barcelona', 'humidity_Seville',\n",
       "       'wind_deg_Bilbao', 'clouds_all_Bilbao', 'gen_hyd_river',\n",
       "       'wind_deg_Seville', 'wind_speed_Barcelona', 'wind_speed_Valencia',\n",
       "       'wind_speed_Bilbao', 'gen_wind', 'wind_speed_Madrid', 'gen_hyd_pump'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52b1443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18041.0\n",
      "41015.0\n"
     ]
    }
   ],
   "source": [
    "print(data['load_actual'].min())\n",
    "print(data['load_actual'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f927e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'price_dayahead', 'gen_coal', 'gen_gas', 'load_actual',\n",
       "       'gen_lig', 'gen_oil', 'gen_oth_renew', 'pressure_Barcelona',\n",
       "       'pressure_Bilbao', 'gen_waste', 'gen_bio', 'temp_min_Valencia',\n",
       "       'pressure_Valencia', 'temp_min_Barcelona', 'humidity_Seville',\n",
       "       'wind_deg_Bilbao', 'clouds_all_Bilbao', 'gen_hyd_river',\n",
       "       'wind_deg_Seville', 'wind_speed_Barcelona', 'wind_speed_Valencia',\n",
       "       'wind_speed_Bilbao', 'gen_wind', 'wind_speed_Madrid', 'gen_hyd_pump'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b01c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for col in data.columns:\n",
    "#     plt.hist(data[col], bins=20)\n",
    "#     plt.title(col)\n",
    "#     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf49194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10259.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data['gen_gas'], 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee4ab3",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f75f7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reframed.shape: (34980, 2184)\n"
     ]
    }
   ],
   "source": [
    "values = data.values\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_hours = 24*3\n",
    "n_features = data.shape[-1]\n",
    "k = 12\n",
    "split1 = 0.7\n",
    "split2 = 0.85\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(values, n_hours, k)\n",
    "print(\"reframed.shape:\", reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94f6e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (24486, 1872) (24486, 12) (5247, 1872) (5247, 12) (5247, 1872) (5247, 12)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "reframed_values = reframed.values\n",
    "n_train_hours = int(len(reframed_values)*split1)\n",
    "n_valid_hours = int(len(reframed_values)*split2)\n",
    "\n",
    "train = reframed_values[:n_train_hours, :]\n",
    "val = reframed_values[n_train_hours:n_valid_hours, :]\n",
    "test = reframed_values[n_valid_hours:, :]\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "feature_idx = 4\n",
    "train_X, train_y = train[:, :n_obs], train[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "val_X, val_y = val[:, :n_obs], val[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "test_X, test_y = test[:, :n_obs], test[:, [n_obs + feature_idx + n_features * i for i in range(k)]]\n",
    "\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9de0c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape (24486, 72, 26) (24486, 12) (5247, 72, 26) (5247, 12) (5247, 72, 26) (5247, 12)\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "train_y = scaler.fit_transform(train_y)\n",
    "\n",
    "val_X = scaler.fit_transform(val_X)\n",
    "val_y = scaler.fit_transform(val_y)\n",
    "\n",
    "test_X = scaler.fit_transform(test_X)\n",
    "test_y = scaler.fit_transform(test_y)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "\n",
    "print(\"train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\", \n",
    "      train_X.shape, train_y.shape, val_X.shape, val_y.shape, test_X.shape, test_y.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca1ea0",
   "metadata": {},
   "source": [
    "### Load threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8b5bf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24486,)\n",
      "(5247,)\n",
      "(5247,)\n"
     ]
    }
   ],
   "source": [
    "train_X_pm = train_X[:, 0, feature_idx]\n",
    "print(train_X_pm.shape)\n",
    "\n",
    "val_X_pm = val_X[:, 0, feature_idx]\n",
    "print(val_X_pm.shape)\n",
    "\n",
    "test_X_pm = test_X[:, 0, feature_idx]\n",
    "print(test_X_pm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ada71ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95th Percentile of Daily Rain: 0.793594933402977\n"
     ]
    }
   ],
   "source": [
    "percentile = 95\n",
    "\n",
    "merged_array = np.concatenate((train_X_pm, val_X_pm, test_X_pm))\n",
    "\n",
    "percentile_pm = np.percentile(merged_array, percentile)\n",
    "\n",
    "print(\"{}th Percentile of Daily Rain:\".format(percentile), percentile_pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db22b7",
   "metadata": {},
   "source": [
    "### train_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad1202cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(976, 72, 26)\n",
      "(976, 12)\n"
     ]
    }
   ],
   "source": [
    "train_X_extreme = train_X[train_X_pm > percentile_pm]\n",
    "print(train_X_extreme.shape)\n",
    "\n",
    "train_y_extreme = train_y[train_X_pm > percentile_pm]\n",
    "print(train_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63f77aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23510, 72, 26)\n",
      "(23510, 12)\n"
     ]
    }
   ],
   "source": [
    "train_X_normal = train_X[train_X_pm <= percentile_pm]\n",
    "print(train_X_normal.shape)\n",
    "\n",
    "train_y_normal = train_y[train_X_pm <= percentile_pm]\n",
    "print(train_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e35917",
   "metadata": {},
   "source": [
    "### val_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8750cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501, 72, 26)\n",
      "(501, 12)\n"
     ]
    }
   ],
   "source": [
    "val_X_extreme = val_X[val_X_pm > percentile_pm]\n",
    "print(val_X_extreme.shape)\n",
    "\n",
    "val_y_extreme = val_y[val_X_pm > percentile_pm]\n",
    "print(val_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5eb865cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4746, 72, 26)\n",
      "(4746, 12)\n"
     ]
    }
   ],
   "source": [
    "val_X_normal = val_X[val_X_pm <= percentile_pm]\n",
    "print(val_X_normal.shape)\n",
    "\n",
    "val_y_normal = val_y[val_X_pm <= percentile_pm]\n",
    "print(val_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9f43b",
   "metadata": {},
   "source": [
    "### test_X_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04a633e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 72, 26)\n",
      "(272, 12)\n"
     ]
    }
   ],
   "source": [
    "test_X_extreme = test_X[test_X_pm > percentile_pm]\n",
    "print(test_X_extreme.shape)\n",
    "\n",
    "test_y_extreme = test_y[test_X_pm > percentile_pm]\n",
    "print(test_y_extreme.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44d0ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4975, 72, 26)\n",
      "(4975, 12)\n"
     ]
    }
   ],
   "source": [
    "test_X_normal = test_X[test_X_pm <= percentile_pm]\n",
    "print(test_X_normal.shape)\n",
    "\n",
    "test_y_normal = test_y[test_X_pm <= percentile_pm]\n",
    "print(test_y_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c626353",
   "metadata": {},
   "source": [
    "### Model & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "148af597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(train_y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4d95d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== model parameters ======\n",
    "mlp_unit1 = 128\n",
    "mlp_unit2 = 128\n",
    "mlp_unit3 = 64\n",
    "mlp_unit4 = 64\n",
    "mlp_unit5 = 32\n",
    "mlp_unit6 = 32\n",
    "mlp_unit7 = 16\n",
    "mlp_unit8 = 16\n",
    "dropout = 0.0  # 0.1\n",
    "kernel_size = 2\n",
    "pool_size = 2\n",
    "learning_rate = 1e-4\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.95\n",
    "PATIENCE = 100\n",
    "EPOCHS = 1000\n",
    "BATCH = 512\n",
    "opt_num = k\n",
    "input_shape = train_X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71f96438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_layer(input_shape=input_shape,\n",
    "                   mlp_unit1=mlp_unit1,\n",
    "                   mlp_unit2=mlp_unit2,\n",
    "                   mlp_unit3=mlp_unit3,\n",
    "                   mlp_unit4=mlp_unit4,\n",
    "                   mlp_unit5=mlp_unit5,\n",
    "                   mlp_unit6=mlp_unit6,\n",
    "                   mlp_unit7=mlp_unit7,\n",
    "                   mlp_unit8=mlp_unit8,\n",
    "                   dropout=dropout,\n",
    "                   masked_value=-1,\n",
    "                   opt_num=opt_num\n",
    "                  )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f1e0318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 14:36:19.173358: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-02-02 14:36:19.174237: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1700105000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 14:36:20.611937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 3s - loss: 0.3087 - mae: 0.5183 - val_loss: 0.2795 - val_mae: 0.4869\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.48686, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 2/1000\n",
      "2/2 - 0s - loss: 0.2796 - mae: 0.4893 - val_loss: 0.2192 - val_mae: 0.4196\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.48686 to 0.41964, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 3/1000\n",
      "2/2 - 0s - loss: 0.1952 - mae: 0.3918 - val_loss: 0.0975 - val_mae: 0.2549\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.41964 to 0.25487, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 4/1000\n",
      "2/2 - 0s - loss: 0.0802 - mae: 0.2272 - val_loss: 0.0751 - val_mae: 0.2269\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.25487 to 0.22685, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 5/1000\n",
      "2/2 - 0s - loss: 0.0751 - mae: 0.2285 - val_loss: 0.0957 - val_mae: 0.2615\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 0.22685\n",
      "Epoch 6/1000\n",
      "2/2 - 0s - loss: 0.0619 - mae: 0.2081 - val_loss: 0.0432 - val_mae: 0.1752\n",
      "\n",
      "Epoch 00006: val_mae improved from 0.22685 to 0.17522, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 7/1000\n",
      "2/2 - 0s - loss: 0.0339 - mae: 0.1516 - val_loss: 0.0438 - val_mae: 0.1704\n",
      "\n",
      "Epoch 00007: val_mae improved from 0.17522 to 0.17036, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 8/1000\n",
      "2/2 - 0s - loss: 0.0466 - mae: 0.1717 - val_loss: 0.0501 - val_mae: 0.1796\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 0.17036\n",
      "Epoch 9/1000\n",
      "2/2 - 0s - loss: 0.0497 - mae: 0.1772 - val_loss: 0.0470 - val_mae: 0.1755\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 0.17036\n",
      "Epoch 10/1000\n",
      "2/2 - 0s - loss: 0.0431 - mae: 0.1656 - val_loss: 0.0482 - val_mae: 0.1796\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 0.17036\n",
      "Epoch 11/1000\n",
      "2/2 - 0s - loss: 0.0405 - mae: 0.1626 - val_loss: 0.0513 - val_mae: 0.1871\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 0.17036\n",
      "Epoch 12/1000\n",
      "2/2 - 0s - loss: 0.0397 - mae: 0.1632 - val_loss: 0.0443 - val_mae: 0.1757\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 0.17036\n",
      "Epoch 13/1000\n",
      "2/2 - 0s - loss: 0.0340 - mae: 0.1522 - val_loss: 0.0376 - val_mae: 0.1629\n",
      "\n",
      "Epoch 00013: val_mae improved from 0.17036 to 0.16289, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 14/1000\n",
      "2/2 - 0s - loss: 0.0318 - mae: 0.1469 - val_loss: 0.0371 - val_mae: 0.1610\n",
      "\n",
      "Epoch 00014: val_mae improved from 0.16289 to 0.16098, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 15/1000\n",
      "2/2 - 0s - loss: 0.0335 - mae: 0.1496 - val_loss: 0.0378 - val_mae: 0.1624\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.16098\n",
      "Epoch 16/1000\n",
      "2/2 - 0s - loss: 0.0338 - mae: 0.1508 - val_loss: 0.0382 - val_mae: 0.1637\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 0.16098\n",
      "Epoch 17/1000\n",
      "2/2 - 0s - loss: 0.0330 - mae: 0.1502 - val_loss: 0.0392 - val_mae: 0.1665\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.16098\n",
      "Epoch 18/1000\n",
      "2/2 - 0s - loss: 0.0326 - mae: 0.1504 - val_loss: 0.0393 - val_mae: 0.1668\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 0.16098\n",
      "Epoch 19/1000\n",
      "2/2 - 0s - loss: 0.0317 - mae: 0.1488 - val_loss: 0.0375 - val_mae: 0.1630\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 0.16098\n",
      "Epoch 20/1000\n",
      "2/2 - 0s - loss: 0.0304 - mae: 0.1451 - val_loss: 0.0362 - val_mae: 0.1598\n",
      "\n",
      "Epoch 00020: val_mae improved from 0.16098 to 0.15981, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 21/1000\n",
      "2/2 - 0s - loss: 0.0299 - mae: 0.1431 - val_loss: 0.0361 - val_mae: 0.1589\n",
      "\n",
      "Epoch 00021: val_mae improved from 0.15981 to 0.15889, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 22/1000\n",
      "2/2 - 0s - loss: 0.0297 - mae: 0.1424 - val_loss: 0.0360 - val_mae: 0.1582\n",
      "\n",
      "Epoch 00022: val_mae improved from 0.15889 to 0.15823, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 23/1000\n",
      "2/2 - 0s - loss: 0.0293 - mae: 0.1416 - val_loss: 0.0361 - val_mae: 0.1583\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.15823\n",
      "Epoch 24/1000\n",
      "2/2 - 0s - loss: 0.0289 - mae: 0.1412 - val_loss: 0.0358 - val_mae: 0.1575\n",
      "\n",
      "Epoch 00024: val_mae improved from 0.15823 to 0.15751, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 25/1000\n",
      "2/2 - 0s - loss: 0.0285 - mae: 0.1401 - val_loss: 0.0350 - val_mae: 0.1556\n",
      "\n",
      "Epoch 00025: val_mae improved from 0.15751 to 0.15555, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 26/1000\n",
      "2/2 - 0s - loss: 0.0279 - mae: 0.1382 - val_loss: 0.0347 - val_mae: 0.1547\n",
      "\n",
      "Epoch 00026: val_mae improved from 0.15555 to 0.15468, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 27/1000\n",
      "2/2 - 0s - loss: 0.0275 - mae: 0.1372 - val_loss: 0.0343 - val_mae: 0.1538\n",
      "\n",
      "Epoch 00027: val_mae improved from 0.15468 to 0.15376, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 28/1000\n",
      "2/2 - 0s - loss: 0.0269 - mae: 0.1360 - val_loss: 0.0340 - val_mae: 0.1530\n",
      "\n",
      "Epoch 00028: val_mae improved from 0.15376 to 0.15303, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 29/1000\n",
      "2/2 - 0s - loss: 0.0266 - mae: 0.1357 - val_loss: 0.0337 - val_mae: 0.1523\n",
      "\n",
      "Epoch 00029: val_mae improved from 0.15303 to 0.15227, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 30/1000\n",
      "2/2 - 0s - loss: 0.0260 - mae: 0.1340 - val_loss: 0.0337 - val_mae: 0.1519\n",
      "\n",
      "Epoch 00030: val_mae improved from 0.15227 to 0.15191, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 31/1000\n",
      "2/2 - 0s - loss: 0.0255 - mae: 0.1325 - val_loss: 0.0331 - val_mae: 0.1504\n",
      "\n",
      "Epoch 00031: val_mae improved from 0.15191 to 0.15043, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 32/1000\n",
      "2/2 - 0s - loss: 0.0248 - mae: 0.1310 - val_loss: 0.0325 - val_mae: 0.1489\n",
      "\n",
      "Epoch 00032: val_mae improved from 0.15043 to 0.14893, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 33/1000\n",
      "2/2 - 0s - loss: 0.0244 - mae: 0.1300 - val_loss: 0.0319 - val_mae: 0.1472\n",
      "\n",
      "Epoch 00033: val_mae improved from 0.14893 to 0.14715, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 34/1000\n",
      "2/2 - 0s - loss: 0.0235 - mae: 0.1273 - val_loss: 0.0316 - val_mae: 0.1459\n",
      "\n",
      "Epoch 00034: val_mae improved from 0.14715 to 0.14590, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 35/1000\n",
      "2/2 - 0s - loss: 0.0229 - mae: 0.1251 - val_loss: 0.0304 - val_mae: 0.1430\n",
      "\n",
      "Epoch 00035: val_mae improved from 0.14590 to 0.14303, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 36/1000\n",
      "2/2 - 0s - loss: 0.0221 - mae: 0.1233 - val_loss: 0.0296 - val_mae: 0.1407\n",
      "\n",
      "Epoch 00036: val_mae improved from 0.14303 to 0.14069, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 37/1000\n",
      "2/2 - 0s - loss: 0.0212 - mae: 0.1202 - val_loss: 0.0290 - val_mae: 0.1385\n",
      "\n",
      "Epoch 00037: val_mae improved from 0.14069 to 0.13850, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 38/1000\n",
      "2/2 - 0s - loss: 0.0203 - mae: 0.1174 - val_loss: 0.0278 - val_mae: 0.1356\n",
      "\n",
      "Epoch 00038: val_mae improved from 0.13850 to 0.13560, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 39/1000\n",
      "2/2 - 0s - loss: 0.0196 - mae: 0.1152 - val_loss: 0.0269 - val_mae: 0.1323\n",
      "\n",
      "Epoch 00039: val_mae improved from 0.13560 to 0.13228, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 40/1000\n",
      "2/2 - 0s - loss: 0.0186 - mae: 0.1115 - val_loss: 0.0258 - val_mae: 0.1294\n",
      "\n",
      "Epoch 00040: val_mae improved from 0.13228 to 0.12937, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 41/1000\n",
      "2/2 - 0s - loss: 0.0181 - mae: 0.1102 - val_loss: 0.0252 - val_mae: 0.1263\n",
      "\n",
      "Epoch 00041: val_mae improved from 0.12937 to 0.12626, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 42/1000\n",
      "2/2 - 0s - loss: 0.0174 - mae: 0.1057 - val_loss: 0.0241 - val_mae: 0.1239\n",
      "\n",
      "Epoch 00042: val_mae improved from 0.12626 to 0.12394, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 43/1000\n",
      "2/2 - 0s - loss: 0.0163 - mae: 0.1034 - val_loss: 0.0228 - val_mae: 0.1199\n",
      "\n",
      "Epoch 00043: val_mae improved from 0.12394 to 0.11988, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 44/1000\n",
      "2/2 - 0s - loss: 0.0162 - mae: 0.1015 - val_loss: 0.0223 - val_mae: 0.1183\n",
      "\n",
      "Epoch 00044: val_mae improved from 0.11988 to 0.11832, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 45/1000\n",
      "2/2 - 0s - loss: 0.0151 - mae: 0.0988 - val_loss: 0.0217 - val_mae: 0.1165\n",
      "\n",
      "Epoch 00045: val_mae improved from 0.11832 to 0.11646, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 46/1000\n",
      "2/2 - 0s - loss: 0.0147 - mae: 0.0964 - val_loss: 0.0204 - val_mae: 0.1119\n",
      "\n",
      "Epoch 00046: val_mae improved from 0.11646 to 0.11191, saving model to ../../saved_models_mlp/load_N.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "2/2 - 0s - loss: 0.0139 - mae: 0.0936 - val_loss: 0.0215 - val_mae: 0.1155\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.11191\n",
      "Epoch 48/1000\n",
      "2/2 - 0s - loss: 0.0133 - mae: 0.0920 - val_loss: 0.0193 - val_mae: 0.1081\n",
      "\n",
      "Epoch 00048: val_mae improved from 0.11191 to 0.10805, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 49/1000\n",
      "2/2 - 0s - loss: 0.0131 - mae: 0.0904 - val_loss: 0.0195 - val_mae: 0.1088\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.10805\n",
      "Epoch 50/1000\n",
      "2/2 - 0s - loss: 0.0127 - mae: 0.0892 - val_loss: 0.0187 - val_mae: 0.1063\n",
      "\n",
      "Epoch 00050: val_mae improved from 0.10805 to 0.10632, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 51/1000\n",
      "2/2 - 0s - loss: 0.0120 - mae: 0.0864 - val_loss: 0.0179 - val_mae: 0.1039\n",
      "\n",
      "Epoch 00051: val_mae improved from 0.10632 to 0.10391, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 52/1000\n",
      "2/2 - 0s - loss: 0.0116 - mae: 0.0850 - val_loss: 0.0185 - val_mae: 0.1058\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.10391\n",
      "Epoch 53/1000\n",
      "2/2 - 0s - loss: 0.0113 - mae: 0.0839 - val_loss: 0.0171 - val_mae: 0.1017\n",
      "\n",
      "Epoch 00053: val_mae improved from 0.10391 to 0.10169, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 54/1000\n",
      "2/2 - 0s - loss: 0.0108 - mae: 0.0816 - val_loss: 0.0167 - val_mae: 0.1005\n",
      "\n",
      "Epoch 00054: val_mae improved from 0.10169 to 0.10046, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 55/1000\n",
      "2/2 - 0s - loss: 0.0104 - mae: 0.0801 - val_loss: 0.0167 - val_mae: 0.1006\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.10046\n",
      "Epoch 56/1000\n",
      "2/2 - 0s - loss: 0.0099 - mae: 0.0782 - val_loss: 0.0161 - val_mae: 0.0986\n",
      "\n",
      "Epoch 00056: val_mae improved from 0.10046 to 0.09857, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 57/1000\n",
      "2/2 - 0s - loss: 0.0095 - mae: 0.0764 - val_loss: 0.0158 - val_mae: 0.0975\n",
      "\n",
      "Epoch 00057: val_mae improved from 0.09857 to 0.09746, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 58/1000\n",
      "2/2 - 0s - loss: 0.0091 - mae: 0.0749 - val_loss: 0.0155 - val_mae: 0.0965\n",
      "\n",
      "Epoch 00058: val_mae improved from 0.09746 to 0.09648, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 59/1000\n",
      "2/2 - 0s - loss: 0.0088 - mae: 0.0735 - val_loss: 0.0152 - val_mae: 0.0955\n",
      "\n",
      "Epoch 00059: val_mae improved from 0.09648 to 0.09550, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 60/1000\n",
      "2/2 - 0s - loss: 0.0083 - mae: 0.0715 - val_loss: 0.0148 - val_mae: 0.0942\n",
      "\n",
      "Epoch 00060: val_mae improved from 0.09550 to 0.09423, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 61/1000\n",
      "2/2 - 0s - loss: 0.0080 - mae: 0.0704 - val_loss: 0.0148 - val_mae: 0.0944\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.09423\n",
      "Epoch 62/1000\n",
      "2/2 - 0s - loss: 0.0076 - mae: 0.0686 - val_loss: 0.0142 - val_mae: 0.0922\n",
      "\n",
      "Epoch 00062: val_mae improved from 0.09423 to 0.09220, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 63/1000\n",
      "2/2 - 0s - loss: 0.0073 - mae: 0.0673 - val_loss: 0.0145 - val_mae: 0.0935\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.09220\n",
      "Epoch 64/1000\n",
      "2/2 - 0s - loss: 0.0072 - mae: 0.0667 - val_loss: 0.0137 - val_mae: 0.0908\n",
      "\n",
      "Epoch 00064: val_mae improved from 0.09220 to 0.09083, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 65/1000\n",
      "2/2 - 0s - loss: 0.0068 - mae: 0.0650 - val_loss: 0.0135 - val_mae: 0.0898\n",
      "\n",
      "Epoch 00065: val_mae improved from 0.09083 to 0.08976, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 66/1000\n",
      "2/2 - 0s - loss: 0.0065 - mae: 0.0636 - val_loss: 0.0134 - val_mae: 0.0899\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.08976\n",
      "Epoch 67/1000\n",
      "2/2 - 0s - loss: 0.0062 - mae: 0.0618 - val_loss: 0.0131 - val_mae: 0.0889\n",
      "\n",
      "Epoch 00067: val_mae improved from 0.08976 to 0.08894, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 68/1000\n",
      "2/2 - 0s - loss: 0.0061 - mae: 0.0615 - val_loss: 0.0132 - val_mae: 0.0893\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.08894\n",
      "Epoch 69/1000\n",
      "2/2 - 0s - loss: 0.0058 - mae: 0.0595 - val_loss: 0.0129 - val_mae: 0.0878\n",
      "\n",
      "Epoch 00069: val_mae improved from 0.08894 to 0.08785, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 70/1000\n",
      "2/2 - 0s - loss: 0.0055 - mae: 0.0583 - val_loss: 0.0129 - val_mae: 0.0880\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.08785\n",
      "Epoch 71/1000\n",
      "2/2 - 0s - loss: 0.0054 - mae: 0.0571 - val_loss: 0.0132 - val_mae: 0.0896\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.08785\n",
      "Epoch 72/1000\n",
      "2/2 - 0s - loss: 0.0052 - mae: 0.0564 - val_loss: 0.0126 - val_mae: 0.0868\n",
      "\n",
      "Epoch 00072: val_mae improved from 0.08785 to 0.08678, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 73/1000\n",
      "2/2 - 0s - loss: 0.0051 - mae: 0.0556 - val_loss: 0.0137 - val_mae: 0.0922\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.08678\n",
      "Epoch 74/1000\n",
      "2/2 - 0s - loss: 0.0050 - mae: 0.0553 - val_loss: 0.0124 - val_mae: 0.0856\n",
      "\n",
      "Epoch 00074: val_mae improved from 0.08678 to 0.08558, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 75/1000\n",
      "2/2 - 0s - loss: 0.0049 - mae: 0.0546 - val_loss: 0.0137 - val_mae: 0.0920\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.08558\n",
      "Epoch 76/1000\n",
      "2/2 - 0s - loss: 0.0048 - mae: 0.0544 - val_loss: 0.0127 - val_mae: 0.0872\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.08558\n",
      "Epoch 77/1000\n",
      "2/2 - 0s - loss: 0.0045 - mae: 0.0524 - val_loss: 0.0131 - val_mae: 0.0895\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.08558\n",
      "Epoch 78/1000\n",
      "2/2 - 0s - loss: 0.0045 - mae: 0.0521 - val_loss: 0.0126 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.08558\n",
      "Epoch 79/1000\n",
      "2/2 - 0s - loss: 0.0045 - mae: 0.0521 - val_loss: 0.0119 - val_mae: 0.0835\n",
      "\n",
      "Epoch 00079: val_mae improved from 0.08558 to 0.08349, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 80/1000\n",
      "2/2 - 0s - loss: 0.0044 - mae: 0.0515 - val_loss: 0.0136 - val_mae: 0.0919\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.08349\n",
      "Epoch 81/1000\n",
      "2/2 - 0s - loss: 0.0043 - mae: 0.0511 - val_loss: 0.0118 - val_mae: 0.0837\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.08349\n",
      "Epoch 82/1000\n",
      "2/2 - 0s - loss: 0.0042 - mae: 0.0503 - val_loss: 0.0122 - val_mae: 0.0855\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.08349\n",
      "Epoch 83/1000\n",
      "2/2 - 0s - loss: 0.0041 - mae: 0.0495 - val_loss: 0.0129 - val_mae: 0.0893\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.08349\n",
      "Epoch 84/1000\n",
      "2/2 - 0s - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0116 - val_mae: 0.0831\n",
      "\n",
      "Epoch 00084: val_mae improved from 0.08349 to 0.08307, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 85/1000\n",
      "2/2 - 0s - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0126 - val_mae: 0.0879\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.08307\n",
      "Epoch 86/1000\n",
      "2/2 - 0s - loss: 0.0038 - mae: 0.0476 - val_loss: 0.0116 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.08307\n",
      "Epoch 87/1000\n",
      "2/2 - 0s - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0115 - val_mae: 0.0826\n",
      "\n",
      "Epoch 00087: val_mae improved from 0.08307 to 0.08264, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 88/1000\n",
      "2/2 - 0s - loss: 0.0036 - mae: 0.0464 - val_loss: 0.0122 - val_mae: 0.0863\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.08264\n",
      "Epoch 89/1000\n",
      "2/2 - 0s - loss: 0.0036 - mae: 0.0462 - val_loss: 0.0109 - val_mae: 0.0799\n",
      "\n",
      "Epoch 00089: val_mae improved from 0.08264 to 0.07989, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 90/1000\n",
      "2/2 - 0s - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0123 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.07989\n",
      "Epoch 91/1000\n",
      "2/2 - 0s - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0121 - val_mae: 0.0864\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.07989\n",
      "Epoch 92/1000\n",
      "2/2 - 0s - loss: 0.0034 - mae: 0.0452 - val_loss: 0.0110 - val_mae: 0.0811\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.07989\n",
      "Epoch 93/1000\n",
      "2/2 - 0s - loss: 0.0033 - mae: 0.0448 - val_loss: 0.0126 - val_mae: 0.0885\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.07989\n",
      "Epoch 94/1000\n",
      "2/2 - 0s - loss: 0.0033 - mae: 0.0445 - val_loss: 0.0109 - val_mae: 0.0803\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.07989\n",
      "Epoch 95/1000\n",
      "2/2 - 0s - loss: 0.0033 - mae: 0.0448 - val_loss: 0.0121 - val_mae: 0.0862\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.07989\n",
      "Epoch 96/1000\n",
      "2/2 - 0s - loss: 0.0033 - mae: 0.0441 - val_loss: 0.0117 - val_mae: 0.0844\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.07989\n",
      "Epoch 97/1000\n",
      "2/2 - 0s - loss: 0.0032 - mae: 0.0434 - val_loss: 0.0109 - val_mae: 0.0808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00097: val_mae did not improve from 0.07989\n",
      "Epoch 98/1000\n",
      "2/2 - 0s - loss: 0.0031 - mae: 0.0432 - val_loss: 0.0120 - val_mae: 0.0862\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.07989\n",
      "Epoch 99/1000\n",
      "2/2 - 0s - loss: 0.0030 - mae: 0.0425 - val_loss: 0.0111 - val_mae: 0.0819\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.07989\n",
      "Epoch 100/1000\n",
      "2/2 - 0s - loss: 0.0030 - mae: 0.0423 - val_loss: 0.0116 - val_mae: 0.0841\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.07989\n",
      "Epoch 101/1000\n",
      "2/2 - 0s - loss: 0.0029 - mae: 0.0418 - val_loss: 0.0116 - val_mae: 0.0842\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.07989\n",
      "Epoch 102/1000\n",
      "2/2 - 0s - loss: 0.0029 - mae: 0.0415 - val_loss: 0.0116 - val_mae: 0.0843\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.07989\n",
      "Epoch 103/1000\n",
      "2/2 - 0s - loss: 0.0029 - mae: 0.0411 - val_loss: 0.0115 - val_mae: 0.0839\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.07989\n",
      "Epoch 104/1000\n",
      "2/2 - 0s - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0118 - val_mae: 0.0849\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.07989\n",
      "Epoch 105/1000\n",
      "2/2 - 0s - loss: 0.0028 - mae: 0.0407 - val_loss: 0.0123 - val_mae: 0.0872\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.07989\n",
      "Epoch 106/1000\n",
      "2/2 - 0s - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0126 - val_mae: 0.0886\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.07989\n",
      "Epoch 107/1000\n",
      "2/2 - 0s - loss: 0.0028 - mae: 0.0411 - val_loss: 0.0126 - val_mae: 0.0888\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.07989\n",
      "Epoch 108/1000\n",
      "2/2 - 0s - loss: 0.0027 - mae: 0.0402 - val_loss: 0.0107 - val_mae: 0.0798\n",
      "\n",
      "Epoch 00108: val_mae improved from 0.07989 to 0.07975, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 109/1000\n",
      "2/2 - 0s - loss: 0.0029 - mae: 0.0414 - val_loss: 0.0115 - val_mae: 0.0838\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.07975\n",
      "Epoch 110/1000\n",
      "2/2 - 0s - loss: 0.0027 - mae: 0.0399 - val_loss: 0.0129 - val_mae: 0.0905\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.07975\n",
      "Epoch 111/1000\n",
      "2/2 - 0s - loss: 0.0027 - mae: 0.0398 - val_loss: 0.0104 - val_mae: 0.0788\n",
      "\n",
      "Epoch 00111: val_mae improved from 0.07975 to 0.07879, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 112/1000\n",
      "2/2 - 0s - loss: 0.0028 - mae: 0.0405 - val_loss: 0.0119 - val_mae: 0.0858\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.07879\n",
      "Epoch 113/1000\n",
      "2/2 - 0s - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0137 - val_mae: 0.0936\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.07879\n",
      "Epoch 114/1000\n",
      "2/2 - 0s - loss: 0.0027 - mae: 0.0400 - val_loss: 0.0104 - val_mae: 0.0785\n",
      "\n",
      "Epoch 00114: val_mae improved from 0.07879 to 0.07855, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 115/1000\n",
      "2/2 - 0s - loss: 0.0026 - mae: 0.0394 - val_loss: 0.0129 - val_mae: 0.0904\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.07855\n",
      "Epoch 116/1000\n",
      "2/2 - 0s - loss: 0.0029 - mae: 0.0414 - val_loss: 0.0126 - val_mae: 0.0889\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.07855\n",
      "Epoch 117/1000\n",
      "2/2 - 0s - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0100 - val_mae: 0.0764\n",
      "\n",
      "Epoch 00117: val_mae improved from 0.07855 to 0.07641, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 118/1000\n",
      "2/2 - 0s - loss: 0.0028 - mae: 0.0410 - val_loss: 0.0117 - val_mae: 0.0853\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.07641\n",
      "Epoch 119/1000\n",
      "2/2 - 0s - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0121 - val_mae: 0.0867\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.07641\n",
      "Epoch 120/1000\n",
      "2/2 - 0s - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0103 - val_mae: 0.0778\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.07641\n",
      "Epoch 121/1000\n",
      "2/2 - 0s - loss: 0.0025 - mae: 0.0386 - val_loss: 0.0125 - val_mae: 0.0888\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.07641\n",
      "Epoch 122/1000\n",
      "2/2 - 0s - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0113 - val_mae: 0.0835\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.07641\n",
      "Epoch 123/1000\n",
      "2/2 - 0s - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0100 - val_mae: 0.0767\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.07641\n",
      "Epoch 124/1000\n",
      "2/2 - 0s - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0126 - val_mae: 0.0891\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.07641\n",
      "Epoch 125/1000\n",
      "2/2 - 0s - loss: 0.0024 - mae: 0.0378 - val_loss: 0.0108 - val_mae: 0.0809\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.07641\n",
      "Epoch 126/1000\n",
      "2/2 - 0s - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0108 - val_mae: 0.0808\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.07641\n",
      "Epoch 127/1000\n",
      "2/2 - 0s - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0122 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.07641\n",
      "Epoch 128/1000\n",
      "2/2 - 0s - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0107 - val_mae: 0.0804\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.07641\n",
      "Epoch 129/1000\n",
      "2/2 - 0s - loss: 0.0023 - mae: 0.0366 - val_loss: 0.0107 - val_mae: 0.0802\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.07641\n",
      "Epoch 130/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0359 - val_loss: 0.0118 - val_mae: 0.0855\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.07641\n",
      "Epoch 131/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0358 - val_loss: 0.0111 - val_mae: 0.0824\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.07641\n",
      "Epoch 132/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0109 - val_mae: 0.0813\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.07641\n",
      "Epoch 133/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0116 - val_mae: 0.0847\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.07641\n",
      "Epoch 134/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0352 - val_loss: 0.0114 - val_mae: 0.0838\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.07641\n",
      "Epoch 135/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0349 - val_loss: 0.0112 - val_mae: 0.0827\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.07641\n",
      "Epoch 136/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0350 - val_loss: 0.0105 - val_mae: 0.0794\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.07641\n",
      "Epoch 137/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0354 - val_loss: 0.0111 - val_mae: 0.0819\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.07641\n",
      "Epoch 138/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0345 - val_loss: 0.0124 - val_mae: 0.0882\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.07641\n",
      "Epoch 139/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0351 - val_loss: 0.0117 - val_mae: 0.0848\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.07641\n",
      "Epoch 140/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0108 - val_mae: 0.0809\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.07641\n",
      "Epoch 141/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0118 - val_mae: 0.0856\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.07641\n",
      "Epoch 142/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0345 - val_loss: 0.0122 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.07641\n",
      "Epoch 143/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0341 - val_loss: 0.0109 - val_mae: 0.0811\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.07641\n",
      "Epoch 144/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0107 - val_mae: 0.0800\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.07641\n",
      "Epoch 145/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0339 - val_loss: 0.0111 - val_mae: 0.0820\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.07641\n",
      "Epoch 146/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0334 - val_loss: 0.0133 - val_mae: 0.0920\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.07641\n",
      "Epoch 147/1000\n",
      "2/2 - 0s - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0128 - val_mae: 0.0896\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.07641\n",
      "Epoch 148/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0118 - val_mae: 0.0853\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.07641\n",
      "Epoch 149/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0329 - val_loss: 0.0107 - val_mae: 0.0801\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.07641\n",
      "Epoch 150/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0330 - val_loss: 0.0113 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.07641\n",
      "Epoch 151/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0329 - val_loss: 0.0130 - val_mae: 0.0907\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.07641\n",
      "Epoch 152/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0335 - val_loss: 0.0108 - val_mae: 0.0806\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.07641\n",
      "Epoch 153/1000\n",
      "2/2 - 0s - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0099 - val_mae: 0.0763\n",
      "\n",
      "Epoch 00153: val_mae improved from 0.07641 to 0.07629, saving model to ../../saved_models_mlp/load_N.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/1000\n",
      "2/2 - 0s - loss: 0.0021 - mae: 0.0347 - val_loss: 0.0110 - val_mae: 0.0813\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.07629\n",
      "Epoch 155/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0323 - val_loss: 0.0121 - val_mae: 0.0866\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.07629\n",
      "Epoch 156/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0121 - val_mae: 0.0863\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.07629\n",
      "Epoch 157/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0322 - val_loss: 0.0117 - val_mae: 0.0845\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.07629\n",
      "Epoch 158/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0317 - val_loss: 0.0114 - val_mae: 0.0834\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.07629\n",
      "Epoch 159/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0315 - val_loss: 0.0110 - val_mae: 0.0818\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.07629\n",
      "Epoch 160/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0315 - val_loss: 0.0111 - val_mae: 0.0819\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.07629\n",
      "Epoch 161/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0314 - val_loss: 0.0116 - val_mae: 0.0840\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.07629\n",
      "Epoch 162/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0313 - val_loss: 0.0125 - val_mae: 0.0883\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.07629\n",
      "Epoch 163/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0320 - val_loss: 0.0120 - val_mae: 0.0862\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.07629\n",
      "Epoch 164/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0108 - val_mae: 0.0803\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.07629\n",
      "Epoch 165/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0313 - val_loss: 0.0111 - val_mae: 0.0818\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.07629\n",
      "Epoch 166/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0123 - val_mae: 0.0869\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.07629\n",
      "Epoch 167/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0312 - val_loss: 0.0130 - val_mae: 0.0901\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.07629\n",
      "Epoch 168/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0320 - val_loss: 0.0127 - val_mae: 0.0894\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.07629\n",
      "Epoch 169/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0322 - val_loss: 0.0131 - val_mae: 0.0907\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.07629\n",
      "Epoch 170/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0130 - val_mae: 0.0900\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.07629\n",
      "Epoch 171/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0315 - val_loss: 0.0115 - val_mae: 0.0839\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.07629\n",
      "Epoch 172/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0303 - val_loss: 0.0104 - val_mae: 0.0780\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.07629\n",
      "Epoch 173/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0319 - val_loss: 0.0102 - val_mae: 0.0774\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.07629\n",
      "Epoch 174/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0121 - val_mae: 0.0861\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.07629\n",
      "Epoch 175/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0134 - val_mae: 0.0917\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.07629\n",
      "Epoch 176/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0328 - val_loss: 0.0130 - val_mae: 0.0900\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.07629\n",
      "Epoch 177/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0306 - val_loss: 0.0105 - val_mae: 0.0789\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.07629\n",
      "Epoch 178/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0315 - val_loss: 0.0101 - val_mae: 0.0760\n",
      "\n",
      "Epoch 00178: val_mae improved from 0.07629 to 0.07602, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 179/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0315 - val_loss: 0.0118 - val_mae: 0.0844\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.07602\n",
      "Epoch 180/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0304 - val_loss: 0.0134 - val_mae: 0.0915\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.07602\n",
      "Epoch 181/1000\n",
      "2/2 - 0s - loss: 0.0018 - mae: 0.0320 - val_loss: 0.0122 - val_mae: 0.0859\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.07602\n",
      "Epoch 182/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0105 - val_mae: 0.0786\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.07602\n",
      "Epoch 183/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0111 - val_mae: 0.0817\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.07602\n",
      "Epoch 184/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0119 - val_mae: 0.0845\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.07602\n",
      "Epoch 185/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0119 - val_mae: 0.0848\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.07602\n",
      "Epoch 186/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0118 - val_mae: 0.0843\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.07602\n",
      "Epoch 187/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0113 - val_mae: 0.0822\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.07602\n",
      "Epoch 188/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0115 - val_mae: 0.0831\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.07602\n",
      "Epoch 189/1000\n",
      "2/2 - 0s - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0118 - val_mae: 0.0840\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.07602\n",
      "Epoch 190/1000\n",
      "2/2 - 0s - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0121 - val_mae: 0.0854\n",
      "\n",
      "Epoch 00190: val_mae did not improve from 0.07602\n",
      "Epoch 191/1000\n",
      "2/2 - 0s - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0126 - val_mae: 0.0878\n",
      "\n",
      "Epoch 00191: val_mae did not improve from 0.07602\n",
      "Epoch 192/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0125 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00192: val_mae did not improve from 0.07602\n",
      "Epoch 193/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0130 - val_mae: 0.0897\n",
      "\n",
      "Epoch 00193: val_mae did not improve from 0.07602\n",
      "Epoch 194/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0129 - val_mae: 0.0890\n",
      "\n",
      "Epoch 00194: val_mae did not improve from 0.07602\n",
      "Epoch 195/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0115 - val_mae: 0.0828\n",
      "\n",
      "Epoch 00195: val_mae did not improve from 0.07602\n",
      "Epoch 196/1000\n",
      "2/2 - 0s - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0108 - val_mae: 0.0791\n",
      "\n",
      "Epoch 00196: val_mae did not improve from 0.07602\n",
      "Epoch 197/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0104 - val_mae: 0.0776\n",
      "\n",
      "Epoch 00197: val_mae did not improve from 0.07602\n",
      "Epoch 198/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0103 - val_mae: 0.0765\n",
      "\n",
      "Epoch 00198: val_mae did not improve from 0.07602\n",
      "Epoch 199/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0309 - val_loss: 0.0099 - val_mae: 0.0746\n",
      "\n",
      "Epoch 00199: val_mae improved from 0.07602 to 0.07456, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 200/1000\n",
      "2/2 - 0s - loss: 0.0017 - mae: 0.0316 - val_loss: 0.0106 - val_mae: 0.0785\n",
      "\n",
      "Epoch 00200: val_mae did not improve from 0.07456\n",
      "Epoch 201/1000\n",
      "2/2 - 0s - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0126 - val_mae: 0.0877\n",
      "\n",
      "Epoch 00201: val_mae did not improve from 0.07456\n",
      "Epoch 202/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0127 - val_mae: 0.0884\n",
      "\n",
      "Epoch 00202: val_mae did not improve from 0.07456\n",
      "Epoch 203/1000\n",
      "2/2 - 0s - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0107 - val_mae: 0.0785\n",
      "\n",
      "Epoch 00203: val_mae did not improve from 0.07456\n",
      "Epoch 204/1000\n",
      "2/2 - 0s - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0107 - val_mae: 0.0785\n",
      "\n",
      "Epoch 00204: val_mae did not improve from 0.07456\n",
      "Epoch 205/1000\n",
      "2/2 - 0s - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0140 - val_mae: 0.0937\n",
      "\n",
      "Epoch 00205: val_mae did not improve from 0.07456\n",
      "Epoch 206/1000\n",
      "2/2 - 0s - loss: 0.0019 - mae: 0.0342 - val_loss: 0.0133 - val_mae: 0.0913\n",
      "\n",
      "Epoch 00206: val_mae did not improve from 0.07456\n",
      "Epoch 207/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0298 - val_loss: 0.0101 - val_mae: 0.0754\n",
      "\n",
      "Epoch 00207: val_mae did not improve from 0.07456\n",
      "Epoch 208/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0304 - val_loss: 0.0102 - val_mae: 0.0761\n",
      "\n",
      "Epoch 00208: val_mae did not improve from 0.07456\n",
      "Epoch 209/1000\n",
      "2/2 - 0s - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0127 - val_mae: 0.0877\n",
      "\n",
      "Epoch 00209: val_mae did not improve from 0.07456\n",
      "Epoch 210/1000\n",
      "2/2 - 0s - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0117 - val_mae: 0.0829\n",
      "\n",
      "Epoch 00210: val_mae did not improve from 0.07456\n",
      "Epoch 211/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0096 - val_mae: 0.0728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00211: val_mae improved from 0.07456 to 0.07285, saving model to ../../saved_models_mlp/load_N.h5\n",
      "Epoch 212/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0309 - val_loss: 0.0104 - val_mae: 0.0771\n",
      "\n",
      "Epoch 00212: val_mae did not improve from 0.07285\n",
      "Epoch 213/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0127 - val_mae: 0.0879\n",
      "\n",
      "Epoch 00213: val_mae did not improve from 0.07285\n",
      "Epoch 214/1000\n",
      "2/2 - 0s - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0109 - val_mae: 0.0797\n",
      "\n",
      "Epoch 00214: val_mae did not improve from 0.07285\n",
      "Epoch 215/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0101 - val_mae: 0.0755\n",
      "\n",
      "Epoch 00215: val_mae did not improve from 0.07285\n",
      "Epoch 216/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0278 - val_loss: 0.0117 - val_mae: 0.0830\n",
      "\n",
      "Epoch 00216: val_mae did not improve from 0.07285\n",
      "Epoch 217/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0278 - val_loss: 0.0126 - val_mae: 0.0873\n",
      "\n",
      "Epoch 00217: val_mae did not improve from 0.07285\n",
      "Epoch 218/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0108 - val_mae: 0.0783\n",
      "\n",
      "Epoch 00218: val_mae did not improve from 0.07285\n",
      "Epoch 219/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0275 - val_loss: 0.0105 - val_mae: 0.0773\n",
      "\n",
      "Epoch 00219: val_mae did not improve from 0.07285\n",
      "Epoch 220/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0115 - val_mae: 0.0819\n",
      "\n",
      "Epoch 00220: val_mae did not improve from 0.07285\n",
      "Epoch 221/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0117 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00221: val_mae did not improve from 0.07285\n",
      "Epoch 222/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0268 - val_loss: 0.0119 - val_mae: 0.0837\n",
      "\n",
      "Epoch 00222: val_mae did not improve from 0.07285\n",
      "Epoch 223/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0263 - val_loss: 0.0112 - val_mae: 0.0803\n",
      "\n",
      "Epoch 00223: val_mae did not improve from 0.07285\n",
      "Epoch 224/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0259 - val_loss: 0.0109 - val_mae: 0.0792\n",
      "\n",
      "Epoch 00224: val_mae did not improve from 0.07285\n",
      "Epoch 225/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0257 - val_loss: 0.0117 - val_mae: 0.0828\n",
      "\n",
      "Epoch 00225: val_mae did not improve from 0.07285\n",
      "Epoch 226/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0121 - val_mae: 0.0846\n",
      "\n",
      "Epoch 00226: val_mae did not improve from 0.07285\n",
      "Epoch 227/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0111 - val_mae: 0.0801\n",
      "\n",
      "Epoch 00227: val_mae did not improve from 0.07285\n",
      "Epoch 228/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0107 - val_mae: 0.0782\n",
      "\n",
      "Epoch 00228: val_mae did not improve from 0.07285\n",
      "Epoch 229/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0257 - val_loss: 0.0111 - val_mae: 0.0798\n",
      "\n",
      "Epoch 00229: val_mae did not improve from 0.07285\n",
      "Epoch 230/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0254 - val_loss: 0.0114 - val_mae: 0.0815\n",
      "\n",
      "Epoch 00230: val_mae did not improve from 0.07285\n",
      "Epoch 231/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0254 - val_loss: 0.0118 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00231: val_mae did not improve from 0.07285\n",
      "Epoch 232/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0122 - val_mae: 0.0851\n",
      "\n",
      "Epoch 00232: val_mae did not improve from 0.07285\n",
      "Epoch 233/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0115 - val_mae: 0.0816\n",
      "\n",
      "Epoch 00233: val_mae did not improve from 0.07285\n",
      "Epoch 234/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0104 - val_mae: 0.0764\n",
      "\n",
      "Epoch 00234: val_mae did not improve from 0.07285\n",
      "Epoch 235/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0101 - val_mae: 0.0753\n",
      "\n",
      "Epoch 00235: val_mae did not improve from 0.07285\n",
      "Epoch 236/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0106 - val_mae: 0.0774\n",
      "\n",
      "Epoch 00236: val_mae did not improve from 0.07285\n",
      "Epoch 237/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0252 - val_loss: 0.0115 - val_mae: 0.0816\n",
      "\n",
      "Epoch 00237: val_mae did not improve from 0.07285\n",
      "Epoch 238/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0118 - val_mae: 0.0830\n",
      "\n",
      "Epoch 00238: val_mae did not improve from 0.07285\n",
      "Epoch 239/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0117 - val_mae: 0.0824\n",
      "\n",
      "Epoch 00239: val_mae did not improve from 0.07285\n",
      "Epoch 240/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0250 - val_loss: 0.0115 - val_mae: 0.0822\n",
      "\n",
      "Epoch 00240: val_mae did not improve from 0.07285\n",
      "Epoch 241/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0110 - val_mae: 0.0787\n",
      "\n",
      "Epoch 00241: val_mae did not improve from 0.07285\n",
      "Epoch 242/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0102 - val_mae: 0.0755\n",
      "\n",
      "Epoch 00242: val_mae did not improve from 0.07285\n",
      "Epoch 243/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0266 - val_loss: 0.0103 - val_mae: 0.0758\n",
      "\n",
      "Epoch 00243: val_mae did not improve from 0.07285\n",
      "Epoch 244/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0118 - val_mae: 0.0830\n",
      "\n",
      "Epoch 00244: val_mae did not improve from 0.07285\n",
      "Epoch 245/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0138 - val_mae: 0.0922\n",
      "\n",
      "Epoch 00245: val_mae did not improve from 0.07285\n",
      "Epoch 246/1000\n",
      "2/2 - 0s - loss: 0.0016 - mae: 0.0319 - val_loss: 0.0134 - val_mae: 0.0900\n",
      "\n",
      "Epoch 00246: val_mae did not improve from 0.07285\n",
      "Epoch 247/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0278 - val_loss: 0.0104 - val_mae: 0.0764\n",
      "\n",
      "Epoch 00247: val_mae did not improve from 0.07285\n",
      "Epoch 248/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0263 - val_loss: 0.0103 - val_mae: 0.0751\n",
      "\n",
      "Epoch 00248: val_mae did not improve from 0.07285\n",
      "Epoch 249/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0119 - val_mae: 0.0834\n",
      "\n",
      "Epoch 00249: val_mae did not improve from 0.07285\n",
      "Epoch 250/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0259 - val_loss: 0.0121 - val_mae: 0.0838\n",
      "\n",
      "Epoch 00250: val_mae did not improve from 0.07285\n",
      "Epoch 251/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0250 - val_loss: 0.0105 - val_mae: 0.0773\n",
      "\n",
      "Epoch 00251: val_mae did not improve from 0.07285\n",
      "Epoch 252/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0251 - val_loss: 0.0105 - val_mae: 0.0759\n",
      "\n",
      "Epoch 00252: val_mae did not improve from 0.07285\n",
      "Epoch 253/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0106 - val_mae: 0.0772\n",
      "\n",
      "Epoch 00253: val_mae did not improve from 0.07285\n",
      "Epoch 254/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0242 - val_loss: 0.0113 - val_mae: 0.0801\n",
      "\n",
      "Epoch 00254: val_mae did not improve from 0.07285\n",
      "Epoch 255/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0244 - val_loss: 0.0125 - val_mae: 0.0856\n",
      "\n",
      "Epoch 00255: val_mae did not improve from 0.07285\n",
      "Epoch 256/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0114 - val_mae: 0.0810\n",
      "\n",
      "Epoch 00256: val_mae did not improve from 0.07285\n",
      "Epoch 257/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0241 - val_loss: 0.0107 - val_mae: 0.0772\n",
      "\n",
      "Epoch 00257: val_mae did not improve from 0.07285\n",
      "Epoch 258/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0105 - val_mae: 0.0764\n",
      "\n",
      "Epoch 00258: val_mae did not improve from 0.07285\n",
      "Epoch 259/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0246 - val_loss: 0.0109 - val_mae: 0.0781\n",
      "\n",
      "Epoch 00259: val_mae did not improve from 0.07285\n",
      "Epoch 260/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0237 - val_loss: 0.0115 - val_mae: 0.0816\n",
      "\n",
      "Epoch 00260: val_mae did not improve from 0.07285\n",
      "Epoch 261/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0123 - val_mae: 0.0849\n",
      "\n",
      "Epoch 00261: val_mae did not improve from 0.07285\n",
      "Epoch 262/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0112 - val_mae: 0.0794\n",
      "\n",
      "Epoch 00262: val_mae did not improve from 0.07285\n",
      "Epoch 263/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0237 - val_loss: 0.0103 - val_mae: 0.0753\n",
      "\n",
      "Epoch 00263: val_mae did not improve from 0.07285\n",
      "Epoch 264/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0108 - val_mae: 0.0775\n",
      "\n",
      "Epoch 00264: val_mae did not improve from 0.07285\n",
      "Epoch 265/1000\n",
      "2/2 - 0s - loss: 9.8923e-04 - mae: 0.0235 - val_loss: 0.0118 - val_mae: 0.0826\n",
      "\n",
      "Epoch 00265: val_mae did not improve from 0.07285\n",
      "Epoch 266/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0244 - val_loss: 0.0125 - val_mae: 0.0854\n",
      "\n",
      "Epoch 00266: val_mae did not improve from 0.07285\n",
      "Epoch 267/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0114 - val_mae: 0.0805\n",
      "\n",
      "Epoch 00267: val_mae did not improve from 0.07285\n",
      "Epoch 268/1000\n",
      "2/2 - 0s - loss: 9.7069e-04 - mae: 0.0232 - val_loss: 0.0106 - val_mae: 0.0767\n",
      "\n",
      "Epoch 00268: val_mae did not improve from 0.07285\n",
      "Epoch 269/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0242 - val_loss: 0.0102 - val_mae: 0.0749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00269: val_mae did not improve from 0.07285\n",
      "Epoch 270/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0106 - val_mae: 0.0766\n",
      "\n",
      "Epoch 00270: val_mae did not improve from 0.07285\n",
      "Epoch 271/1000\n",
      "2/2 - 0s - loss: 9.6923e-04 - mae: 0.0233 - val_loss: 0.0121 - val_mae: 0.0833\n",
      "\n",
      "Epoch 00271: val_mae did not improve from 0.07285\n",
      "Epoch 272/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0243 - val_loss: 0.0123 - val_mae: 0.0842\n",
      "\n",
      "Epoch 00272: val_mae did not improve from 0.07285\n",
      "Epoch 273/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0238 - val_loss: 0.0113 - val_mae: 0.0797\n",
      "\n",
      "Epoch 00273: val_mae did not improve from 0.07285\n",
      "Epoch 274/1000\n",
      "2/2 - 0s - loss: 9.6353e-04 - mae: 0.0232 - val_loss: 0.0103 - val_mae: 0.0750\n",
      "\n",
      "Epoch 00274: val_mae did not improve from 0.07285\n",
      "Epoch 275/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0103 - val_mae: 0.0753\n",
      "\n",
      "Epoch 00275: val_mae did not improve from 0.07285\n",
      "Epoch 276/1000\n",
      "2/2 - 0s - loss: 9.7747e-04 - mae: 0.0235 - val_loss: 0.0114 - val_mae: 0.0803\n",
      "\n",
      "Epoch 00276: val_mae did not improve from 0.07285\n",
      "Epoch 277/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0240 - val_loss: 0.0129 - val_mae: 0.0876\n",
      "\n",
      "Epoch 00277: val_mae did not improve from 0.07285\n",
      "Epoch 278/1000\n",
      "2/2 - 0s - loss: 0.0012 - mae: 0.0271 - val_loss: 0.0125 - val_mae: 0.0849\n",
      "\n",
      "Epoch 00278: val_mae did not improve from 0.07285\n",
      "Epoch 279/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0239 - val_loss: 0.0105 - val_mae: 0.0763\n",
      "\n",
      "Epoch 00279: val_mae did not improve from 0.07285\n",
      "Epoch 280/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0243 - val_loss: 0.0101 - val_mae: 0.0736\n",
      "\n",
      "Epoch 00280: val_mae did not improve from 0.07285\n",
      "Epoch 281/1000\n",
      "2/2 - 0s - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0110 - val_mae: 0.0787\n",
      "\n",
      "Epoch 00281: val_mae did not improve from 0.07285\n",
      "Epoch 282/1000\n",
      "2/2 - 0s - loss: 9.7880e-04 - mae: 0.0235 - val_loss: 0.0134 - val_mae: 0.0887\n",
      "\n",
      "Epoch 00282: val_mae did not improve from 0.07285\n",
      "Epoch 283/1000\n",
      "2/2 - 0s - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0125 - val_mae: 0.0857\n",
      "\n",
      "Epoch 00283: val_mae did not improve from 0.07285\n",
      "Epoch 284/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0245 - val_loss: 0.0108 - val_mae: 0.0767\n",
      "\n",
      "Epoch 00284: val_mae did not improve from 0.07285\n",
      "Epoch 285/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0240 - val_loss: 0.0102 - val_mae: 0.0747\n",
      "\n",
      "Epoch 00285: val_mae did not improve from 0.07285\n",
      "Epoch 286/1000\n",
      "2/2 - 0s - loss: 9.8036e-04 - mae: 0.0236 - val_loss: 0.0115 - val_mae: 0.0805\n",
      "\n",
      "Epoch 00286: val_mae did not improve from 0.07285\n",
      "Epoch 287/1000\n",
      "2/2 - 0s - loss: 9.7338e-04 - mae: 0.0236 - val_loss: 0.0121 - val_mae: 0.0837\n",
      "\n",
      "Epoch 00287: val_mae did not improve from 0.07285\n",
      "Epoch 288/1000\n",
      "2/2 - 0s - loss: 0.0010 - mae: 0.0245 - val_loss: 0.0113 - val_mae: 0.0792\n",
      "\n",
      "Epoch 00288: val_mae did not improve from 0.07285\n",
      "Epoch 289/1000\n",
      "2/2 - 0s - loss: 9.0532e-04 - mae: 0.0226 - val_loss: 0.0103 - val_mae: 0.0750\n",
      "\n",
      "Epoch 00289: val_mae did not improve from 0.07285\n",
      "Epoch 290/1000\n",
      "2/2 - 0s - loss: 9.8731e-04 - mae: 0.0239 - val_loss: 0.0108 - val_mae: 0.0770\n",
      "\n",
      "Epoch 00290: val_mae did not improve from 0.07285\n",
      "Epoch 291/1000\n",
      "2/2 - 0s - loss: 9.0172e-04 - mae: 0.0225 - val_loss: 0.0118 - val_mae: 0.0819\n",
      "\n",
      "Epoch 00291: val_mae did not improve from 0.07285\n",
      "Epoch 292/1000\n",
      "2/2 - 0s - loss: 9.3837e-04 - mae: 0.0232 - val_loss: 0.0118 - val_mae: 0.0816\n",
      "\n",
      "Epoch 00292: val_mae did not improve from 0.07285\n",
      "Epoch 293/1000\n",
      "2/2 - 0s - loss: 9.0670e-04 - mae: 0.0226 - val_loss: 0.0107 - val_mae: 0.0771\n",
      "\n",
      "Epoch 00293: val_mae did not improve from 0.07285\n",
      "Epoch 294/1000\n",
      "2/2 - 0s - loss: 8.8831e-04 - mae: 0.0223 - val_loss: 0.0110 - val_mae: 0.0777\n",
      "\n",
      "Epoch 00294: val_mae did not improve from 0.07285\n",
      "Epoch 295/1000\n",
      "2/2 - 0s - loss: 8.7124e-04 - mae: 0.0221 - val_loss: 0.0115 - val_mae: 0.0806\n",
      "\n",
      "Epoch 00295: val_mae did not improve from 0.07285\n",
      "Epoch 296/1000\n",
      "2/2 - 0s - loss: 8.9147e-04 - mae: 0.0224 - val_loss: 0.0116 - val_mae: 0.0810\n",
      "\n",
      "Epoch 00296: val_mae did not improve from 0.07285\n",
      "Epoch 297/1000\n",
      "2/2 - 0s - loss: 8.9171e-04 - mae: 0.0224 - val_loss: 0.0115 - val_mae: 0.0801\n",
      "\n",
      "Epoch 00297: val_mae did not improve from 0.07285\n",
      "Epoch 298/1000\n",
      "2/2 - 0s - loss: 8.6097e-04 - mae: 0.0219 - val_loss: 0.0107 - val_mae: 0.0765\n",
      "\n",
      "Epoch 00298: val_mae did not improve from 0.07285\n",
      "Epoch 299/1000\n",
      "2/2 - 0s - loss: 8.8515e-04 - mae: 0.0224 - val_loss: 0.0106 - val_mae: 0.0764\n",
      "\n",
      "Epoch 00299: val_mae did not improve from 0.07285\n",
      "Epoch 300/1000\n",
      "2/2 - 0s - loss: 8.6990e-04 - mae: 0.0220 - val_loss: 0.0112 - val_mae: 0.0786\n",
      "\n",
      "Epoch 00300: val_mae did not improve from 0.07285\n",
      "Epoch 301/1000\n",
      "2/2 - 0s - loss: 8.5972e-04 - mae: 0.0219 - val_loss: 0.0117 - val_mae: 0.0816\n",
      "\n",
      "Epoch 00301: val_mae did not improve from 0.07285\n",
      "Epoch 302/1000\n",
      "2/2 - 0s - loss: 9.3508e-04 - mae: 0.0231 - val_loss: 0.0123 - val_mae: 0.0840\n",
      "\n",
      "Epoch 00302: val_mae did not improve from 0.07285\n",
      "Epoch 303/1000\n",
      "2/2 - 0s - loss: 9.5795e-04 - mae: 0.0236 - val_loss: 0.0114 - val_mae: 0.0799\n",
      "\n",
      "Epoch 00303: val_mae did not improve from 0.07285\n",
      "Epoch 304/1000\n",
      "2/2 - 0s - loss: 8.5060e-04 - mae: 0.0218 - val_loss: 0.0104 - val_mae: 0.0750\n",
      "\n",
      "Epoch 00304: val_mae did not improve from 0.07285\n",
      "Epoch 305/1000\n",
      "2/2 - 0s - loss: 9.4448e-04 - mae: 0.0234 - val_loss: 0.0105 - val_mae: 0.0752\n",
      "\n",
      "Epoch 00305: val_mae did not improve from 0.07285\n",
      "Epoch 306/1000\n",
      "2/2 - 0s - loss: 8.7070e-04 - mae: 0.0222 - val_loss: 0.0114 - val_mae: 0.0802\n",
      "\n",
      "Epoch 00306: val_mae did not improve from 0.07285\n",
      "Epoch 307/1000\n",
      "2/2 - 0s - loss: 8.7920e-04 - mae: 0.0224 - val_loss: 0.0121 - val_mae: 0.0827\n",
      "\n",
      "Epoch 00307: val_mae did not improve from 0.07285\n",
      "Epoch 308/1000\n",
      "2/2 - 0s - loss: 9.0984e-04 - mae: 0.0229 - val_loss: 0.0115 - val_mae: 0.0803\n",
      "\n",
      "Epoch 00308: val_mae did not improve from 0.07285\n",
      "Epoch 309/1000\n",
      "2/2 - 0s - loss: 8.3505e-04 - mae: 0.0217 - val_loss: 0.0110 - val_mae: 0.0775\n",
      "\n",
      "Epoch 00309: val_mae did not improve from 0.07285\n",
      "Epoch 310/1000\n",
      "2/2 - 0s - loss: 8.3426e-04 - mae: 0.0217 - val_loss: 0.0104 - val_mae: 0.0752\n",
      "\n",
      "Epoch 00310: val_mae did not improve from 0.07285\n",
      "Epoch 311/1000\n",
      "2/2 - 0s - loss: 8.5401e-04 - mae: 0.0220 - val_loss: 0.0110 - val_mae: 0.0774\n",
      "\n",
      "Epoch 00311: val_mae did not improve from 0.07285\n",
      "Epoch 00311: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb0571b1520>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate, \n",
    "#                                                           decay_steps=decay_steps,\n",
    "#                                                           decay_rate=decay_rate)\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "#               loss='mse',\n",
    "#               metrics=['mae']\n",
    "#              )\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae']\n",
    "             )\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_mae', mode='min', verbose=2, patience=PATIENCE)\n",
    "mc = ModelCheckpoint('../../saved_models_mlp/load_E.h5', \n",
    "                     monitor='val_mae', \n",
    "                     mode='min', \n",
    "                     verbose=2, \n",
    "                     save_best_only=True\n",
    "                    )\n",
    "\n",
    "\n",
    "model.fit(train_X_extreme, train_y_extreme,\n",
    "          validation_data=(val_X_extreme, val_y_extreme),\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH,\n",
    "          verbose=2,\n",
    "          shuffle=True,\n",
    "          callbacks=[es, mc]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3c6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf5004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7c598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
